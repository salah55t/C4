import os
import logging
import pickle
import time
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Any

import numpy as np
import pandas as pd
import psycopg2
from binance.client import Client
from decouple import config
from psycopg2.extras import RealDictCursor
from tqdm import tqdm

# ==============================================================================
# --------------------------- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ù„ÙÙŠ ----------------------------
# ==============================================================================
# Ø§Ù„ÙØªØ±Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ø§Ù„Ø§ÙŠØ§Ù…
BACKTEST_PERIOD_DAYS: int = 180
# Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ Ù„Ù„Ø´Ù…ÙˆØ¹ (ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ·Ø§Ø¨Ù‚ Ø¥Ø·Ø§Ø± ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬)
TIMEFRAME: str = '15m'
# Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ø§Ù„Ø°ÙŠ Ø³ÙŠØªÙ… Ø§Ø®ØªØ¨Ø§Ø±Ù‡
BASE_ML_MODEL_NAME: str = 'LightGBM_Scalping_V4'

# --- Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© (ÙŠØ¬Ø¨ Ø£Ù† ØªØ·Ø§Ø¨Ù‚ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ÙˆØª c4.py) ---
MODEL_PREDICTION_THRESHOLD: float = 0.70
ATR_SL_MULTIPLIER: float = 2.0
ATR_TP_MULTIPLIER: float = 3.0
USE_TRAILING_STOP: bool = True
TRAILING_STOP_ACTIVATE_PERCENT: float = 0.75
TRAILING_STOP_DISTANCE_PERCENT: float = 1.0

# Ù…Ø¨Ù„Øº Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù„ÙƒÙ„ ØµÙÙ‚Ø© Ø¨Ø§Ù„Ø¯ÙˆÙ„Ø§Ø± Ù„Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ø±Ø¨Ø­
INITIAL_TRADE_AMOUNT_USDT: float = 100.0

# ==============================================================================
# ---------------------------- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… ÙˆØ§Ù„Ø§ØªØµØ§Ù„ -------------------------
# ==============================================================================

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (Logging)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('backtester.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('Backtester')

# ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
try:
    API_KEY: str = config('BINANCE_API_KEY')
    API_SECRET: str = config('BINANCE_API_SECRET')
    DB_URL: str = config('DATABASE_URL')
except Exception as e:
    logger.critical(f"âŒ ÙØ´Ù„ Ø­Ø§Ø³Ù… ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©: {e}")
    exit(1)

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø¹Ù…ÙŠÙ„ Binance
try:
    client = Client(API_KEY, API_SECRET)
    logger.info("âœ… [Binance] ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª Binance Ø¨Ù†Ø¬Ø§Ø­.")
except Exception as e:
    logger.critical(f"âŒ [Binance] ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
    exit(1)

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
conn: Optional[psycopg2.extensions.connection] = None
try:
    conn = psycopg2.connect(DB_URL, cursor_factory=RealDictCursor)
    logger.info("âœ… [DB] ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­.")
except Exception as e:
    logger.critical(f"âŒ [DB] ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
    exit(1)

# ==============================================================================
# ------------------- Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© (Ù…Ù†Ø³ÙˆØ®Ø© ÙˆÙ…Ø¹Ø¯Ù„Ø© Ù…Ù† Ù…Ù„ÙØ§ØªÙƒ) --------------------
# ==============================================================================

def get_validated_symbols(filename: str = 'crypto_list.txt') -> List[str]:
    """
    ØªÙ‚Ø±Ø£ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Øª ÙˆØªØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯Ù‡Ø§ ÙˆØµÙ„Ø§Ø­ÙŠØªÙ‡Ø§ Ù„Ù„ØªØ¯Ø§ÙˆÙ„ Ø¹Ù„Ù‰ Binance.
    """
    logger.info(f"â„¹ï¸ [Validation] Reading symbols from '{filename}'...")
    try:
        script_dir = os.path.dirname(__file__)
        file_path = os.path.join(script_dir, filename)
        with open(file_path, 'r', encoding='utf-8') as f:
            raw_symbols = {s.strip().upper() for s in f if s.strip() and not s.startswith('#')}
        formatted = {f"{s}USDT" if not s.endswith('USDT') else s for s in raw_symbols}
        
        exchange_info = client.get_exchange_info()
        active_symbols = {s['symbol'] for s in exchange_info['symbols'] if s['status'] == 'TRADING'}
        
        validated = sorted(list(formatted.intersection(active_symbols)))
        logger.info(f"âœ… [Validation] Found {len(validated)} symbols to backtest.")
        return validated
    except Exception as e:
        logger.error(f"âŒ [Validation] Error: {e}", exc_info=True)
        return []

def fetch_historical_data(symbol: str, interval: str, days: int) -> Optional[pd.DataFrame]:
    """
    ØªØ¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù…Ù† Binance.
    """
    try:
        start_str = (datetime.utcnow() - timedelta(days=days)).strftime("%Y-%m-%d %H:%M:%S")
        klines = client.get_historical_klines(symbol, interval, start_str)
        if not klines:
            logger.warning(f"âš ï¸ No historical data found for {symbol} for the given period.")
            return None
            
        df = pd.DataFrame(klines, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_volume', 'trades', 'taker_buy_base', 'taker_buy_quote', 'ignore'])
        numeric_cols = ['open', 'high', 'low', 'close', 'volume']
        for col in numeric_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('timestamp', inplace=True)
        return df[['open', 'high', 'low', 'close', 'volume']].dropna()
    except Exception as e:
        logger.error(f"âŒ [Data] Error fetching data for {symbol}: {e}")
        return None

def calculate_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    ØªØ­Ø³Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª ÙˆØ§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ (Ù†Ø³Ø®Ø© Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù…Ø§ ÙÙŠ Ù…Ù„Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©).
    """
    df_calc = df.copy()
    # Parameters from your scripts
    RSI_PERIOD, MACD_FAST, MACD_SLOW, MACD_SIGNAL, BBANDS_PERIOD, ATR_PERIOD = 14, 12, 26, 9, 20, 14
    BBANDS_STD_DEV = 2.0
    
    # ATR
    high_low = df_calc['high'] - df_calc['low']
    high_close = (df_calc['high'] - df_calc['close'].shift()).abs()
    low_close = (df_calc['low'] - df_calc['close'].shift()).abs()
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    df_calc['atr'] = tr.ewm(span=ATR_PERIOD, adjust=False).mean()

    # RSI
    delta = df_calc['close'].diff()
    gain = delta.clip(lower=0).ewm(com=RSI_PERIOD - 1, adjust=False).mean()
    loss = -delta.clip(upper=0).ewm(com=RSI_PERIOD - 1, adjust=False).mean()
    rs = gain / loss.replace(0, np.nan)
    df_calc['rsi'] = 100 - (100 / (1 + rs))

    # MACD & MACD Cross
    ema_fast = df_calc['close'].ewm(span=MACD_FAST, adjust=False).mean()
    ema_slow = df_calc['close'].ewm(span=MACD_SLOW, adjust=False).mean()
    df_calc['macd'] = ema_fast - ema_slow
    df_calc['macd_signal'] = df_calc['macd'].ewm(span=MACD_SIGNAL, adjust=False).mean()
    df_calc['macd_hist'] = df_calc['macd'] - df_calc['macd_signal']
    macd_above = df_calc['macd'] > df_calc['macd_signal']
    macd_below = df_calc['macd'] < df_calc['macd_signal']
    df_calc['macd_cross'] = 0
    df_calc.loc[macd_above & macd_below.shift(1), 'macd_cross'] = 1
    df_calc.loc[macd_below & macd_above.shift(1), 'macd_cross'] = -1

    # Bollinger Bands
    sma = df_calc['close'].rolling(window=BBANDS_PERIOD).mean()
    std = df_calc['close'].rolling(window=BBANDS_PERIOD).std()
    df_calc['bb_pos'] = (df_calc['close'] - sma) / std.replace(0, np.nan)

    # Time-based Features
    df_calc['day_of_week'] = df_calc.index.dayofweek
    df_calc['hour_of_day'] = df_calc.index.hour
    
    # Candlestick features
    df_calc['candle_body_size'] = (df_calc['close'] - df_calc['open']).abs()
    df_calc['upper_wick'] = df_calc['high'] - df_calc[['open', 'close']].max(axis=1)
    df_calc['lower_wick'] = df_calc[['open', 'close']].min(axis=1) - df_calc['low']
    df_calc['relative_volume'] = df_calc['volume'] / (df_calc['volume'].rolling(window=30, min_periods=1).mean() + 1e-9)

    return df_calc.dropna()

def load_ml_model_bundle_from_db(symbol: str) -> Optional[Dict[str, Any]]:
    """
    ØªØ­Ù…Ù„ Ø­Ø²Ù…Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ + Ø§Ù„Ù…Ø¹Ø§ÙŠØ± + Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ÙŠØ²Ø§Øª) Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.
    """
    model_name = f"{BASE_ML_MODEL_NAME}_{symbol}"
    if not conn: return None
    try:
        with conn.cursor() as db_cur:
            db_cur.execute("SELECT model_data FROM ml_models WHERE model_name = %s LIMIT 1;", (model_name,))
            result = db_cur.fetchone()
            if result and result.get('model_data'):
                model_bundle = pickle.loads(result['model_data'])
                logger.info(f"âœ… [Model] Successfully loaded model '{model_name}' for {symbol}.")
                return model_bundle
            logger.warning(f"âš ï¸ [Model] Model '{model_name}' not found in DB for {symbol}.")
            return None
    except Exception as e:
        logger.error(f"âŒ [Model] Error loading model for {symbol}: {e}", exc_info=True)
        return None

# ==============================================================================
# ----------------------------- Ù…Ø­Ø±Ùƒ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ù„ÙÙŠ ----------------------------
# ==============================================================================

def run_backtest_for_symbol(symbol: str, data: pd.DataFrame, model_bundle: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    ØªÙ‚ÙˆÙ… Ø¨ØªÙ†ÙÙŠØ° Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„Ø¹Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø©.
    """
    trades = []
    
    model = model_bundle['model']
    scaler = model_bundle['scaler']
    feature_names = model_bundle['feature_names']
    
    # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    df_featured = calculate_features(data)
    
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…ÙˆØ¬ÙˆØ¯Ø©
    for col in feature_names:
        if col not in df_featured.columns:
            logger.error(f"Missing feature '{col}' in data for {symbol}. Skipping backtest for this symbol.")
            return []

    features_scaled = scaler.transform(df_featured[feature_names])
    predictions = model.predict_proba(features_scaled)[:, 1]
    
    df_featured['prediction'] = predictions
    
    in_trade = False
    trade_details = {}

    # Ø§Ù„Ù…Ø±ÙˆØ± Ø¹Ù„Ù‰ ÙƒÙ„ Ø´Ù…Ø¹Ø© Ù„Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„
    for i in range(len(df_featured)):
        current_candle = df_featured.iloc[i]
        
        # --- Ù…Ù†Ø·Ù‚ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØµÙÙ‚Ø© Ø§Ù„Ù…ÙØªÙˆØ­Ø© ---
        if in_trade:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØµÙˆÙ„ Ø§Ù„Ø³Ø¹Ø± Ù„Ù„Ù‡Ø¯Ù Ø£Ùˆ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©
            if current_candle['high'] >= trade_details['tp']:
                trade_details['exit_price'] = trade_details['tp']
                trade_details['exit_reason'] = 'TP Hit'
            elif current_candle['low'] <= trade_details['sl']:
                trade_details['exit_price'] = trade_details['sl']
                trade_details['exit_reason'] = 'SL Hit'
            
            # Ù…Ù†Ø·Ù‚ Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ
            elif USE_TRAILING_STOP:
                activation_price = trade_details['entry_price'] * (1 + (TRAILING_STOP_ACTIVATE_PERCENT / 100))
                # Ø¥Ø°Ø§ ØªÙ… ØªÙØ¹ÙŠÙ„ Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ
                if not trade_details.get('tsl_active') and current_candle['high'] >= activation_price:
                    trade_details['tsl_active'] = True
                
                if trade_details.get('tsl_active'):
                    new_tsl = current_candle['close'] * (1 - (TRAILING_STOP_DISTANCE_PERCENT / 100))
                    # ØªØ­Ø¯ÙŠØ« ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø£Ø¹Ù„Ù‰
                    if new_tsl > trade_details['sl']:
                        trade_details['sl'] = new_tsl
            
            # Ø¥Ø°Ø§ ØªÙ… Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„ØµÙÙ‚Ø©
            if trade_details.get('exit_price'):
                trade_details['exit_time'] = current_candle.name
                trade_details['duration_candles'] = i - trade_details['entry_index']
                trades.append(trade_details)
                in_trade = False
                trade_details = {}
            continue

        # --- Ù…Ù†Ø·Ù‚ ÙØªØ­ ØµÙÙ‚Ø© Ø¬Ø¯ÙŠØ¯Ø© ---
        if not in_trade and current_candle['prediction'] >= MODEL_PREDICTION_THRESHOLD:
            in_trade = True
            entry_price = current_candle['close']
            atr_value = current_candle['atr']
            
            stop_loss = entry_price - (atr_value * ATR_SL_MULTIPLIER)
            take_profit = entry_price + (atr_value * ATR_TP_MULTIPLIER)
            
            trade_details = {
                'symbol': symbol,
                'entry_time': current_candle.name,
                'entry_price': entry_price,
                'entry_index': i,
                'tp': take_profit,
                'sl': stop_loss,
                'initial_sl': stop_loss, # Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠ
            }

    return trades

def generate_report(all_trades: List[Dict[str, Any]]):
    """
    ØªÙ†Ø´Ø¦ ÙˆØªØ¹Ø±Ø¶ ØªÙ‚Ø±ÙŠØ±Ù‹Ø§ Ù…ÙØµÙ„Ø§Ù‹ Ø¨Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ù„ÙÙŠ.
    """
    if not all_trades:
        logger.warning("No trades were executed during the backtest.")
        return

    df_trades = pd.DataFrame(all_trades)
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø±Ø¨Ø­ ÙˆØ§Ù„Ø®Ø³Ø§Ø±Ø© Ù„ÙƒÙ„ ØµÙÙ‚Ø©
    df_trades['pnl_pct'] = ((df_trades['exit_price'] / df_trades['entry_price']) - 1) * 100
    df_trades['pnl_usdt'] = df_trades['pnl_pct'] / 100 * INITIAL_TRADE_AMOUNT_USDT

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù…Ø©
    total_trades = len(df_trades)
    winning_trades = df_trades[df_trades['pnl_usdt'] > 0]
    losing_trades = df_trades[df_trades['pnl_usdt'] <= 0]
    
    win_rate = (len(winning_trades) / total_trades) * 100 if total_trades > 0 else 0
    total_pnl = df_trades['pnl_usdt'].sum()
    
    gross_profit = winning_trades['pnl_usdt'].sum()
    gross_loss = abs(losing_trades['pnl_usdt'].sum())
    profit_factor = gross_profit / gross_loss if gross_loss > 0 else float('inf')
    
    avg_win = winning_trades['pnl_usdt'].mean() if len(winning_trades) > 0 else 0
    avg_loss = losing_trades['pnl_usdt'].mean() if len(losing_trades) > 0 else 0
    risk_reward_ratio = abs(avg_win / avg_loss) if avg_loss != 0 else float('inf')

    # Ø¹Ø±Ø¶ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
    print("\n" + "="*80)
    print(f"ğŸ“ˆ BACKTESTING REPORT: {BASE_ML_MODEL_NAME}")
    print(f"Period: Last {BACKTEST_PERIOD_DAYS} days ({TIMEFRAME} timeframe)")
    print("="*80)
    print("\n--- General Performance ---")
    print(f"Total Trades: {total_trades}")
    print(f"Win Rate: {win_rate:.2f}%")
    print(f"Total Net PnL: ${total_pnl:,.2f}")
    print(f"Profit Factor: {profit_factor:.2f}")

    print("\n--- Averages ---")
    print(f"Average Winning Trade: ${avg_win:,.2f}")
    print(f"Average Losing Trade: ${avg_loss:,.2f}")
    print(f"Average Risk/Reward Ratio: {risk_reward_ratio:.2f}:1")
    
    print("\n--- Totals ---")
    print(f"Gross Profit: ${gross_profit:,.2f} ({len(winning_trades)} trades)")
    print(f"Gross Loss: ${gross_loss:,.2f} ({len(losing_trades)} trades)")
    
    # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ Ù…Ù„Ù CSV
    try:
        report_filename = f"backtest_report_{BASE_ML_MODEL_NAME}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        df_trades.to_csv(report_filename)
        print("\n" + "="*80)
        print(f"âœ… Full trade log saved to: {report_filename}")
        print("="*80 + "\n")
    except Exception as e:
        logger.error(f"Could not save report to CSV: {e}")

# ==============================================================================
# --------------------------------- Ø§Ù„ØªÙ†ÙÙŠØ° -----------------------------------
# ==============================================================================

if __name__ == "__main__":
    logger.info("ğŸš€ Starting backtester...")
    symbols_to_test = get_validated_symbols()
    
    if not symbols_to_test:
        logger.critical("âŒ No valid symbols to test. Exiting.")
        exit(1)
        
    all_trades = []
    
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… tqdm Ù„Ø¥Ø¸Ù‡Ø§Ø± Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù…
    for symbol in tqdm(symbols_to_test, desc="Backtesting Symbols"):
        # 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        model_bundle = load_ml_model_bundle_from_db(symbol)
        if not model_bundle:
            continue
            
        # 2. Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©
        # Ù†Ø¶ÙŠÙ 30 ÙŠÙˆÙ…Ù‹Ø§ Ø¥Ø¶Ø§ÙÙŠØ© Ù„ØªÙƒÙˆÙ† ÙƒØ§ÙÙŠØ© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø¯ÙˆÙ† ÙÙ‚Ø¯Ø§Ù† Ø¨ÙŠØ§Ù†Ø§Øª
        df_hist = fetch_historical_data(symbol, TIMEFRAME, BACKTEST_PERIOD_DAYS + 30)
        if df_hist is None or df_hist.empty:
            continue
            
        # 3. ØªÙ†ÙÙŠØ° Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
        trades = run_backtest_for_symbol(symbol, df_hist, model_bundle)
        if trades:
            all_trades.extend(trades)
        
        time.sleep(1) # Ù„ØªØ¬Ù†Ø¨ Ø¥ØºØ±Ø§Ù‚ ÙˆØ§Ø¬Ù‡Ø© Binance Ø¨Ø§Ù„Ø·Ù„Ø¨Ø§Øª

    # 4. Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
    generate_report(all_trades)
    
    # Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    if conn:
        conn.close()
        
    logger.info("ğŸ‘‹ Backtester finished.")
