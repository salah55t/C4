import time
import os
import json
import logging
import requests
import numpy as np
import pandas as pd
import pandas_ta as ta
import psycopg2
import pickle
import lightgbm as lgb
from psycopg2.extras import RealDictCursor
from binance.client import Client
from datetime import datetime, timedelta
from decouple import config
from typing import List, Dict, Optional, Any, Tuple
from sklearn.preprocessing import StandardScaler
from tqdm import tqdm
from flask import Flask
from threading import Thread
from multiprocessing import Pool, cpu_count, Manager
from sklearn.metrics import accuracy_score, precision_score


# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (Logging) ----------------------
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ml_trainer_optimized.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('OptimizedCryptoMLTrainer')

# ---------------------- ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© ----------------------
try:
    API_KEY: str = config('BINANCE_API_KEY')
    API_SECRET: str = config('BINANCE_API_SECRET')
    DB_URL: str = config('DATABASE_URL')
    TELEGRAM_TOKEN: Optional[str] = config('TELEGRAM_BOT_TOKEN', default=None)
    CHAT_ID: Optional[str] = config('TELEGRAM_CHAT_ID', default=None)
except Exception as e:
     logger.critical(f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©: {e}")
     exit(1)

# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø«ÙˆØ§Ø¨Øª (Ù…Ø¹Ø¯Ù„Ø© Ù„Ù„Ø³Ø±Ø¹Ø©) ----------------------
BASE_ML_MODEL_NAME: str = 'LightGBM_Crypto_Predictor_V9_Optimized'
SIGNAL_TIMEFRAME: str = '15m'
DATA_LOOKBACK_DAYS: int = 180 
BTC_SYMBOL = 'BTCUSDT'

# --- Ù…Ø¹Ù„Ù…Ø§Øª Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø­Ø§Ø¬Ø² Ø§Ù„Ø«Ù„Ø§Ø«ÙŠ ---
TP_ATR_MULTIPLIER: float = 1.8
SL_ATR_MULTIPLIER: float = 1.2
MAX_HOLD_PERIOD: int = 24

# --- Ù…ØªØºÙŠØ±Ø§Øª Ø¹Ø§Ù„Ù…ÙŠØ© Ù…Ø´ØªØ±ÙƒØ© Ø¨ÙŠÙ† Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª ---
manager = Manager()
btc_data_cache = manager.dict()

# --- Ø¯ÙˆØ§Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ ---
def get_db_connection():
    """Ø¥Ù†Ø´Ø§Ø¡ Ø§ØªØµØ§Ù„ Ø¬Ø¯ÙŠØ¯ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ÙƒÙ„ Ø¹Ù…Ù„ÙŠØ©."""
    return psycopg2.connect(DB_URL, cursor_factory=RealDictCursor)

def get_binance_client():
    """Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù…ÙŠÙ„ Binance Ø¬Ø¯ÙŠØ¯ Ù„ÙƒÙ„ Ø¹Ù…Ù„ÙŠØ©."""
    return Client(API_KEY, API_SECRET)


# --- Ø¯ÙˆØ§Ù„ Ø¬Ù„Ø¨ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
def fetch_historical_data(client, symbol: str, interval: str, days: int) -> Optional[pd.DataFrame]:
    """Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù…Ù† Binance."""
    try:
        start_str = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d %H:%M:%S")
        klines = client.get_historical_klines(symbol, interval, start_str)
        if not klines: return None
        
        cols = ['timestamp', 'open', 'high', 'low', 'close', 'volume']
        df = pd.DataFrame(klines, columns=cols + ['_'] * 6)
        
        for col in cols[1:]: df[col] = pd.to_numeric(df[col], errors='coerce')
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('timestamp', inplace=True)
        return df[cols[1:]].dropna()
    except Exception as e:
        logger.error(f"âŒ [Data Fetch] Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª {symbol}: {e}")
        return None

def fetch_and_cache_btc_data_global():
    """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª BTC Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ÙˆØªØ®Ø²ÙŠÙ†Ù‡Ø§ ÙÙŠ Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ù…Ø´ØªØ±Ùƒ."""
    logger.info("â„¹ï¸ [BTC Data] Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ† ÙˆØªØ®Ø²ÙŠÙ†Ù‡Ø§...")
    client = get_binance_client()
    btc_df = fetch_historical_data(client, BTC_SYMBOL, SIGNAL_TIMEFRAME, DATA_LOOKBACK_DAYS)
    if btc_df is None:
        logger.critical("âŒ [BTC Data] ÙØ´Ù„ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ†."); exit(1)
        
    btc_df['btc_log_return'] = np.log(btc_df['close'] / btc_df['close'].shift(1))
    btc_data_cache['df'] = btc_df.dropna()
    logger.info("âœ… [BTC Data] ØªÙ… ØªØ®Ø²ÙŠÙ† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ† Ø¨Ù†Ø¬Ø§Ø­.")

def engineer_features(df: pd.DataFrame, btc_df: pd.DataFrame) -> pd.DataFrame:
    """
    Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pandas-ta Ù„Ù„Ø³Ø±Ø¹Ø©.
    """
    df.ta.atr(length=14, append=True) 
    df.ta.rsi(length=14, append=True) 
    df.ta.macd(fast=12, slow=26, signal=9, append=True)
    
    df['log_return'] = np.log(df['close'] / df['close'].shift(1))
    df['relative_volume'] = df['volume'] / (df['volume'].rolling(window=30, min_periods=1).mean() + 1e-9)
    
    merged = df.join(btc_df['btc_log_return'], how='left')
    df['btc_correlation'] = merged['log_return'].rolling(window=50).corr(merged['btc_log_return']).fillna(0)

    df['hour'] = df.index.hour
    df['day_of_week'] = df.index.dayofweek
    
    df.rename(columns={'ATRr_14': 'atr', 'RSI_14': 'rsi', 'MACDh_12_26_9': 'macd_hist'}, inplace=True)
    
    return df.replace([np.inf, -np.inf], np.nan).dropna()


def get_vectorized_labels(prices: pd.Series, atr: pd.Series) -> pd.Series:
    """
    Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…ÙˆØ¬Ù‡Ø© (Vectorized) ÙˆØ§Ù„Ø£Ø³Ø±Ø¹ Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù.
    """
    upper_barrier = prices + (atr * TP_ATR_MULTIPLIER)
    lower_barrier = prices - (atr * SL_ATR_MULTIPLIER)
    
    future_highs = prices.shift(-1).rolling(window=MAX_HOLD_PERIOD, min_periods=1).max()
    future_lows = prices.shift(-1).rolling(window=MAX_HOLD_PERIOD, min_periods=1).min()
    
    profit_hit = future_highs >= upper_barrier
    loss_hit = future_lows <= lower_barrier
    
    labels = pd.Series(0, index=prices.index, dtype=int)
    labels.loc[profit_hit & ~loss_hit] = 1
    labels.loc[~profit_hit & loss_hit] = -1
    
    both_hit = profit_hit & loss_hit
    labels.loc[both_hit] = -1 
    
    return labels

def train_model(X: pd.DataFrame, y: pd.Series) -> Tuple[Optional[Any], Optional[Any], Optional[Dict[str, Any]]]:
    """ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù…Ø¹Ù„Ù…Ø§Øª Ø®ÙÙŠÙØ© Ù„Ù„Ø³Ø±Ø¹Ø©."""
    lgbm_params = {
        'objective': 'multiclass', 'num_class': 3, 'metric': 'multi_logloss',
        'boosting_type': 'gbdt', 
        'n_estimators': 500,
        'learning_rate': 0.05,
        'num_leaves': 31,
        'seed': 42, 'n_jobs': 1,
        'verbose': -1,
    }

    model = lgb.LGBMClassifier(**lgbm_params)
    
    numerical_features = X.select_dtypes(include=np.number).columns.tolist()
    scaler = StandardScaler()
    X.loc[:, numerical_features] = scaler.fit_transform(X[numerical_features])
    
    categorical_features = ['hour', 'day_of_week']
    for col in categorical_features:
        if col in X.columns: X[col] = X[col].astype('category')
            
    model.fit(X, y, categorical_feature=categorical_features)
    
    y_pred = model.predict(X)
    accuracy = accuracy_score(y, y_pred)
    precision_profit = precision_score(y, y_pred, labels=[2], average='macro', zero_division=0)
    
    metrics = {
        'in_sample_accuracy': accuracy,
        'precision_for_profit_class': precision_profit,
        'num_samples': len(X)
    }
    
    return model, scaler, metrics

# --- Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„ØªÙŠ Ø³ÙŠØªÙ… ØªØ´ØºÙŠÙ„Ù‡Ø§ Ù„ÙƒÙ„ Ø¹Ù…Ù„ÙŠØ© ---
def process_symbol(symbol: str):
    """
    Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙŠ ØªÙ‚ÙˆÙ… Ø¨ÙƒØ§Ù…Ù„ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù„Ø±Ù…Ø² ÙˆØ§Ø­Ø¯.
    """
    try:
        logger.info(f"âš™ï¸ [Process] Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© {symbol}...")
        client = get_binance_client()
        conn = get_db_connection()
        
        hist_data = fetch_historical_data(client, symbol, SIGNAL_TIMEFRAME, DATA_LOOKBACK_DAYS)
        if hist_data is None or hist_data.empty:
            logger.warning(f"âš ï¸ [{symbol}] Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ§Ø±ÙŠØ®ÙŠØ©.")
            return (symbol, 'No Data', None)

        btc_df_from_cache = btc_data_cache.get('df')
        if btc_df_from_cache is None:
             logger.error(f"âŒ [{symbol}] Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª BTC ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©.")
             return (symbol, 'BTC Data Missing', None)
             
        df_featured = engineer_features(hist_data, btc_df_from_cache)
        
        df_featured['target'] = get_vectorized_labels(df_featured['close'], df_featured['atr'])
        df_featured['target_mapped'] = df_featured['target'].map({-1: 0, 0: 1, 1: 2})
        
        feature_columns = [col for col in df_featured.columns if col in ['atr', 'rsi', 'macd_hist', 'log_return', 'relative_volume', 'btc_correlation', 'hour', 'day_of_week']]
        
        df_cleaned = df_featured.dropna(subset=feature_columns + ['target_mapped'])
        if df_cleaned.empty or df_cleaned['target_mapped'].nunique() < 3:
            logger.warning(f"âš ï¸ [{symbol}] Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ.")
            return (symbol, 'Insufficient Data', None)

        X = df_cleaned[feature_columns]
        y = df_cleaned['target_mapped']

        model, scaler, metrics = train_model(X, y)
        
        if model and metrics and metrics.get('precision_for_profit_class', 0) > 0.50:
            model_bundle = {'model': model, 'scaler': scaler, 'feature_names': list(X.columns)}
            model_name = f"{BASE_ML_MODEL_NAME}_{symbol}"
            
            model_binary = pickle.dumps(model_bundle)
            metrics_json = json.dumps(metrics)
            with conn.cursor() as cur:
                cur.execute("""
                    INSERT INTO ml_models (model_name, model_data, metrics) VALUES (%s, %s, %s)
                    ON CONFLICT (model_name) DO UPDATE SET model_data = EXCLUDED.model_data,
                    trained_at = NOW(), metrics = EXCLUDED.metrics;
                """, (model_name, model_binary, metrics_json))
            conn.commit()
            
            logger.info(f"âœ… [{symbol}] ØªÙ… ØªØ¯Ø±ÙŠØ¨ ÙˆØ­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­.")
            return (symbol, 'Success', metrics)
        else:
            logger.warning(f"âš ï¸ [{symbol}] Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù… ÙŠØ­Ù‚Ù‚ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨.")
            return (symbol, 'Low Performance', metrics)
            
    except Exception as e:
        logger.critical(f"âŒ [{symbol}] Ø®Ø·Ø£ ÙØ§Ø¯Ø­ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ù…Ø²: {e}", exc_info=True)
        return (symbol, 'Error', None)
    finally:
        if 'conn' in locals() and conn:
            conn.close()

def send_telegram_notification(text: str):
    """Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø¹Ø§Ø± Ø¥Ù„Ù‰ ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…."""
    if not TELEGRAM_TOKEN or not CHAT_ID: return
    try:
        requests.post(f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage",
                      json={'chat_id': CHAT_ID, 'text': text, 'parse_mode': 'Markdown'}, timeout=10)
    except Exception as e:
        logger.error(f"âŒ [Telegram] ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±: {e}")

# ==============================================================================
# âœ¨ Ø¯Ø§Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© âœ¨
# ==============================================================================
def filter_tradable_symbols(client: Client, symbols_to_check: List[str]) -> List[str]:
    """
    ØªÙ‚ÙˆÙ… Ø¨ØªØµÙÙŠØ© Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ù‡Ø§ Ù…ØªØ§Ø­Ø© ÙˆÙ‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¯Ø§ÙˆÙ„ Ø¹Ù„Ù‰ Binance.
    """
    logger.info("â„¹ï¸ [Validation] Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ø¹Ù„Ù‰ Binance...")
    try:
        exchange_info = client.get_exchange_info()
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© (set) Ù…Ù† Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ù„Ù„ØªØ¯Ø§ÙˆÙ„ Ù…Ø¹ USDT Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø³Ø±ÙŠØ¹
        available_symbols = {
            s['symbol'] 
            for s in exchange_info['symbols'] 
            if s['quoteAsset'] == 'USDT' and s['status'] == 'TRADING'
        }
        
        # ØªØ­ÙˆÙŠÙ„ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø¥Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù„Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
        symbols_set = set(symbols_to_check)
        
        # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¯Ø§ÙˆÙ„
        tradable = list(symbols_set.intersection(available_symbols))
        
        # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù…Ù„Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØªØ§Ø­Ø©
        untradable = list(symbols_set.difference(available_symbols))
        
        if untradable:
            logger.warning(f"âš ï¸ [Validation] Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© ØªÙ… ØªØ®Ø·ÙŠÙ‡Ø§ Ù„Ø£Ù†Ù‡Ø§ ØºÙŠØ± Ù…ØªØ§Ø­Ø© Ù„Ù„ØªØ¯Ø§ÙˆÙ„: {', '.join(untradable)}")
        
        logger.info(f"âœ… [Validation] ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(tradable)} Ø¹Ù…Ù„Ø© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¯Ø§ÙˆÙ„ Ù…Ù† Ø£ØµÙ„ {len(symbols_to_check)}.")
        return tradable
        
    except Exception as e:
        logger.error(f"âŒ [Validation] Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¹Ù…Ù„Ø© Ù…Ù† Binance: {e}. Ø³ÙŠØªÙ… ØªØ®Ø·ÙŠ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­Ù‚Ù‚.")
        # ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„ØŒ Ù‚Ù… Ø¨Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù„ØªØ¬Ù†Ø¨ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§
        return symbols_to_check

# --- Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„ØªÙŠ ØªØ¯ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠØ© ---
def parallel_training_job():
    logger.info(f"ğŸš€ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø­Ø³Ù†Ø© ({BASE_ML_MODEL_NAME})...")
    
    fetch_and_cache_btc_data_global()
    
    try:
        with open('crypto_list.txt', 'r', encoding='utf-8') as f:
            symbols_from_file = {s.strip().upper() + 'USDT' for s in f if s.strip()}
    except FileNotFoundError:
        logger.critical("âŒ [Main] Ù…Ù„Ù 'crypto_list.txt' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯."); return

    # --- âœ¨ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡ âœ¨ ---
    client = get_binance_client() 
    if not client:
        logger.critical("âŒ [Main] ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ù…ÙŠÙ„ Binance Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¹Ù…Ù„Ø§Øª."); return

    tradable_symbols = filter_tradable_symbols(client, list(symbols_from_file))
    if not tradable_symbols:
        logger.warning("âš ï¸ [Main] Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ø¹Ù…Ù„Ø§Øª Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¯Ø§ÙˆÙ„ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©.")
        return
    # --- Ù†Ù‡Ø§ÙŠØ© Ù‚Ø³Ù… Ø§Ù„ØªØ­Ù‚Ù‚ ---

    send_telegram_notification(f"ğŸš€ *Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ù…Ø­Ø³Ù† Ù„Ù€ {len(tradable_symbols)} Ø¹Ù…Ù„Ø©*...")
    
    num_processes = cpu_count()
    logger.info(f"ğŸ–¥ï¸ Ø§Ø³ØªØ®Ø¯Ø§Ù… {num_processes} Ø¹Ù…Ù„ÙŠØ§Øª Ù…ØªÙˆØ§Ø²ÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨.")
    
    results = []
    with Pool(processes=num_processes) as pool:
        with tqdm(total=len(tradable_symbols), desc="Training Symbols") as pbar:
            for result in pool.imap_unordered(process_symbol, tradable_symbols):
                results.append(result)
                pbar.update()

    successful = sum(1 for r in results if r[1] == 'Success')
    failed = len(tradable_symbols) - successful
    
    summary_msg = (f"ğŸ *Ø§ÙƒØªÙ…Ù„Øª Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø­Ø³Ù†Ø©*\n"
                   f"- Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù†Ø§Ø¬Ø­Ø©: {successful}\n"
                   f"- Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ÙØ§Ø´Ù„Ø©/Ø§Ù„Ù…ØªØ¬Ø§Ù‡ÙÙ„Ø©: {failed}")
    send_telegram_notification(summary_msg)
    logger.info(summary_msg)

# --- Ø®Ø§Ø¯Ù… Flask Ù„Ù„Ø¨Ù‚Ø§Ø¡ Ù†Ø´Ø·Ù‹Ø§ Ø¹Ù„Ù‰ Render ---
app = Flask(__name__)
@app.route('/')
def health_check():
    return "Ø®Ø¯Ù…Ø© ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø­Ø³Ù†Ø© ØªØ¹Ù…Ù„.", 200

if __name__ == "__main__":
    train_thread = Thread(target=parallel_training_job)
    train_thread.daemon = True
    train_thread.start()
    
    port = int(os.environ.get("PORT", 10000))
    logger.info(f"ğŸŒ ØªØ´ØºÙŠÙ„ Ø®Ø§Ø¯Ù… Ø§Ù„ÙˆÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†ÙØ° {port}...")
    app.run(host='0.0.0.0', port=port)
