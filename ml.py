import time
import os
import json
import logging
import requests
import numpy as np
import pandas as pd
import psycopg2
import pickle
import lightgbm as lgb
import optuna
import warnings
from psycopg2 import sql
from psycopg2.extras import RealDictCursor
from binance.client import Client
from datetime import datetime, timedelta
from decouple import config
from typing import List, Dict, Optional, Any, Tuple
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import StandardScaler
from tqdm import tqdm
from flask import Flask
from threading import Thread, Event

# ---------------------- ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ© Ù…Ù† Pandas ----------------------
warnings.simplefilter(action='ignore', category=FutureWarning)

# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (Logging) ----------------------
optuna.logging.set_verbosity(optuna.logging.WARNING)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ml_model_trainer_v5.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('MLTrainer_V5')

# ---------------------- ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© ----------------------
try:
    API_KEY: str = config('BINANCE_API_KEY')
    API_SECRET: str = config('BINANCE_API_SECRET')
    DB_URL: str = config('DATABASE_URL')
    TELEGRAM_TOKEN: Optional[str] = config('TELEGRAM_BOT_TOKEN', default=None)
    CHAT_ID: Optional[str] = config('TELEGRAM_CHAT_ID', default=None)
except Exception as e:
    logger.critical(f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©: {e}")
    exit(1)

# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø«ÙˆØ§Ø¨Øª ÙˆØ§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© ----------------------
BASE_ML_MODEL_NAME: str = 'LightGBM_Scalping_V5'
SIGNAL_GENERATION_TIMEFRAME: str = '15m'
HIGHER_TIMEFRAME: str = '4h'
DATA_LOOKBACK_DAYS_FOR_TRAINING: int = 120
HYPERPARAM_TUNING_TRIALS: int = 5
BTC_SYMBOL = 'BTCUSDT'
ADX_PERIOD: int = 14
BBANDS_PERIOD: int = 20
RSI_PERIOD: int = 14
MACD_FAST, MACD_SLOW, MACD_SIGNAL = 12, 26, 9
ATR_PERIOD: int = 14
EMA_SLOW_PERIOD: int = 200
EMA_FAST_PERIOD: int = 50
BTC_CORR_PERIOD: int = 30
STOCH_RSI_PERIOD: int = 14
STOCH_K: int = 3
STOCH_D: int = 3
REL_VOL_PERIOD: int = 30
RSI_OVERBOUGHT: int = 70
RSI_OVERSOLD: int = 30
STOCH_RSI_OVERBOUGHT: int = 80
STOCH_RSI_OVERSOLD: int = 20
TP_ATR_MULTIPLIER: float = 2.0
SL_ATR_MULTIPLIER: float = 1.5
MAX_HOLD_PERIOD: int = 24
DB_KEEP_ALIVE_INTERVAL: int = 300 # Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ (5 Ø¯Ù‚Ø§Ø¦Ù‚)

# Global variables
conn: Optional[psycopg2.extensions.connection] = None
client: Optional[Client] = None
btc_data_cache: Optional[pd.DataFrame] = None

# --- Ø¯ÙˆØ§Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ ---

def get_db_connection(force_reconnect: bool = False) -> Optional[psycopg2.extensions.connection]:
    """
    ÙŠÙˆÙØ± Ø§ØªØµØ§Ù„Ø§Ù‹ ØµØ§Ù„Ø­Ù‹Ø§ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ ÙˆÙŠØ¹ÙŠØ¯ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±.
    """
    global conn
    if force_reconnect or conn is None or conn.closed != 0:
        if conn and not conn.closed:
            try:
                conn.close()
            except psycopg2.Error:
                pass 

        try:
            logger.info("â„¹ï¸ [DB] Ù…Ø­Ø§ÙˆÙ„Ø© (Ø¥Ø¹Ø§Ø¯Ø©) Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
            conn = psycopg2.connect(DB_URL, cursor_factory=RealDictCursor)
            with conn.cursor() as cur:
                cur.execute("""
                    CREATE TABLE IF NOT EXISTS ml_models (
                        id SERIAL PRIMARY KEY, model_name TEXT NOT NULL UNIQUE,
                        model_data BYTEA NOT NULL, trained_at TIMESTAMP DEFAULT NOW(), metrics JSONB );
                """)
            conn.commit()
            logger.info("âœ… [DB] ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø¨Ù†Ø¬Ø§Ø­.")
        except psycopg2.OperationalError as e:
            logger.critical(f"âŒ [DB] Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ù†Ø´Ø§Ø¡ Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            conn = None
        except Exception as e:
            logger.critical(f"âŒ [DB] Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            conn = None
    return conn

def db_keep_alive(stop_event: Event):
    """
    Ø¯Ø§Ù„Ø© ØªØ¹Ù…Ù„ ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ© Ù„Ø¥Ø±Ø³Ø§Ù„ Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¨Ø³ÙŠØ· Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø§ØªØµØ§Ù„.
    """
    logger.info("ğŸ’¡ [Keep-Alive] ØªÙ… Ø¨Ø¯Ø¡ Ø®Ø¯Ù…Ø© Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
    while not stop_event.is_set():
        try:
            local_conn = get_db_connection()
            if local_conn and not local_conn.closed:
                with local_conn.cursor() as cur:
                    cur.execute("SELECT 1;")
                logger.info("ğŸ’¡ [Keep-Alive] ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ù†Ø¨Ø¶Ø© Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø§ØªØµØ§Ù„.")
            else:
                logger.warning("ğŸ’¡ [Keep-Alive] Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø±Ø³Ø§Ù„ Ù†Ø¨Ø¶Ø© ÙˆÙ„ÙƒÙ† Ø§Ù„Ø§ØªØµØ§Ù„ Ù…ØºÙ„Ù‚. Ø³ÙŠØªÙ… Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„ ÙÙŠ Ø§Ù„Ø¯ÙˆØ±Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©.")
        except (psycopg2.InterfaceError, psycopg2.OperationalError) as e:
            logger.error(f"âŒ [Keep-Alive] ÙÙ‚Ø¯Ø§Ù† Ø§Ù„Ø§ØªØµØ§Ù„ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù†Ø¨Ø¶Ø©: {e}. Ø³ÙŠØªÙ… ÙØ±Ø¶ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„.")
            get_db_connection(force_reconnect=True)
        except Exception as e:
            logger.error(f"âŒ [Keep-Alive] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}")

        # Ø§Ù†ØªØ¸Ø± Ø§Ù„ÙØªØ±Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ø£Ùˆ Ø­ØªÙ‰ ÙŠØªÙ… Ø·Ù„Ø¨ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ù
        stop_event.wait(DB_KEEP_ALIVE_INTERVAL)
    logger.info("ğŸ›‘ [Keep-Alive] ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø®Ø¯Ù…Ø© Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")


def get_binance_client():
    global client
    try:
        client = Client(API_KEY, API_SECRET)
        client.ping()
        logger.info("âœ… [Binance] ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª Binance Ø¨Ù†Ø¬Ø§Ø­.")
    except Exception as e:
        logger.critical(f"âŒ [Binance] ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© Ø¹Ù…ÙŠÙ„ Binance: {e}"); exit(1)

def get_validated_symbols(filename: str = 'crypto_list.txt') -> List[str]:
    # ... (Ø§Ù„ÙƒÙˆØ¯ Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±)
    if not client:
        logger.error("âŒ [Validation] Ø¹Ù…ÙŠÙ„ Binance Ù„Ù… ÙŠØªÙ… ØªÙ‡ÙŠØ¦ØªÙ‡.")
        return []
    try:
        script_dir = os.path.dirname(__file__)
        file_path = os.path.join(script_dir, filename)
        with open(file_path, 'r', encoding='utf-8') as f:
            symbols = {s.strip().upper() for s in f if s.strip() and not s.startswith('#')}
        formatted = {f"{s}USDT" if not s.endswith('USDT') else s for s in symbols}
        info = client.get_exchange_info()
        active = {s['symbol'] for s in info['symbols'] if s['status'] == 'TRADING' and s['quoteAsset'] == 'USDT'}
        validated = sorted(list(formatted.intersection(active)))
        logger.info(f"âœ… [Validation] ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(validated)} Ø¹Ù…Ù„Ø© ØµØ§Ù„Ø­Ø© Ù„Ù„ØªØ¯Ø§ÙˆÙ„.")
        return validated
    except FileNotFoundError:
        logger.error(f"âŒ [Validation] Ù…Ù„Ù Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Øª '{filename}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")
        return []
    except Exception as e:
        logger.error(f"âŒ [Validation] Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ²: {e}"); return []
# --- Ø¨Ø§Ù‚ÙŠ Ø¯ÙˆØ§Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„ØªØ¯Ø±ÙŠØ¨ (Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±) ---

def fetch_historical_data(symbol: str, interval: str, days: int) -> Optional[pd.DataFrame]:
    try:
        start_str = (datetime.utcnow() - timedelta(days=days)).strftime("%Y-%m-%d %H:%M:%S")
        klines = client.get_historical_klines(symbol, interval, start_str)
        if not klines: return None
        df = pd.DataFrame(klines, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_volume', 'trades', 'taker_buy_base', 'taker_buy_quote', 'ignore'])
        numeric_cols = ['open', 'high', 'low', 'close', 'volume']
        for col in numeric_cols: df[col] = pd.to_numeric(df[col], errors='coerce')
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('timestamp', inplace=True)
        return df[numeric_cols].dropna()
    except Exception as e:
        logger.error(f"âŒ [Data] Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù€ {symbol} Ø¹Ù„Ù‰ Ø¥Ø·Ø§Ø± {interval}: {e}"); return None

def fetch_and_cache_btc_data():
    global btc_data_cache
    logger.info("â„¹ï¸ [BTC Data] Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ† ÙˆØªØ®Ø²ÙŠÙ†Ù‡Ø§...")
    btc_data_cache = fetch_historical_data(BTC_SYMBOL, SIGNAL_GENERATION_TIMEFRAME, DATA_LOOKBACK_DAYS_FOR_TRAINING)
    if btc_data_cache is None:
        logger.critical("âŒ [BTC Data] ÙØ´Ù„ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ†."); exit(1)
    btc_data_cache['btc_returns'] = btc_data_cache['close'].pct_change()

def calculate_features(df: pd.DataFrame, btc_df: pd.DataFrame) -> pd.DataFrame:
    # ... (Ø§Ù„ÙƒÙˆØ¯ Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±)
    df_calc = df.copy()
    high_low = df_calc['high'] - df_calc['low']
    tr = pd.concat([high_low, (df_calc['high'] - df_calc['close'].shift()).abs(), (df_calc['low'] - df_calc['close'].shift()).abs()], axis=1).max(axis=1)
    df_calc['atr'] = tr.ewm(span=ATR_PERIOD, adjust=False).mean()
    plus_dm = ((df_calc['high'].diff() > -df_calc['low'].diff()) & (df_calc['high'].diff() > 0)).astype(int)
    minus_dm = ((-df_calc['low'].diff() > df_calc['high'].diff()) & (-df_calc['low'].diff() > 0)).astype(int)
    plus_di = 100 * (plus_dm.ewm(span=ADX_PERIOD, adjust=False).mean() / df_calc['atr'])
    minus_di = 100 * (minus_dm.ewm(span=ADX_PERIOD, adjust=False).mean() / df_calc['atr'])
    dx = 100 * (abs(plus_di - minus_di) / (plus_di + minus_di).replace(0, 1e-9))
    df_calc['adx'] = dx.ewm(span=ADX_PERIOD, adjust=False).mean()
    delta = df_calc['close'].diff()
    gain = delta.clip(lower=0).ewm(com=RSI_PERIOD - 1, adjust=False).mean()
    loss = -delta.clip(upper=0).ewm(com=RSI_PERIOD - 1, adjust=False).mean()
    df_calc['rsi'] = 100 - (100 / (1 + (gain / loss.replace(0, 1e-9))))
    ema_fast = df_calc['close'].ewm(span=MACD_FAST, adjust=False).mean()
    ema_slow = df_calc['close'].ewm(span=MACD_SLOW, adjust=False).mean()
    macd_line = ema_fast - ema_slow
    signal_line = macd_line.ewm(span=MACD_SIGNAL, adjust=False).mean()
    df_calc['macd_hist'] = macd_line - signal_line
    # ... (rest of the function is the same)
    return df_calc

def get_triple_barrier_labels(prices: pd.Series, atr: pd.Series) -> pd.Series:
    # ... (Ø§Ù„ÙƒÙˆØ¯ Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±)
    labels = pd.Series(0, index=prices.index, dtype=int)
    for i in tqdm(range(len(prices) - MAX_HOLD_PERIOD), desc="Labeling", leave=False):
        entry_price = prices.iloc[i]
        current_atr = atr.iloc[i]
        if pd.isna(current_atr) or current_atr == 0: continue
        upper_barrier = entry_price + (current_atr * TP_ATR_MULTIPLIER)
        lower_barrier = entry_price - (current_atr * SL_ATR_MULTIPLIER)
        for j in range(1, MAX_HOLD_PERIOD + 1):
            if i + j >= len(prices): break
            if prices.iloc[i + j] >= upper_barrier:
                labels.iloc[i] = 1; break
            if prices.iloc[i + j] <= lower_barrier:
                labels.iloc[i] = -1; break
    return labels

def prepare_data_for_ml(df_15m: pd.DataFrame, df_4h: pd.DataFrame, btc_df: pd.DataFrame, symbol: str) -> Optional[Tuple[pd.DataFrame, pd.Series, List[str]]]:
    # ... (Ø§Ù„ÙƒÙˆØ¯ Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±)
    logger.info(f"â„¹ï¸ [ML Prep] Preparing data for {symbol}...")
    df_featured = calculate_features(df_15m, btc_df)
    # ... rest of the function ...
    return df_featured[[]], df_featured['target'], []


def tune_and_train_model(X: pd.DataFrame, y: pd.Series) -> Tuple[Optional[Any], Optional[Any], Optional[Dict[str, Any]]]:
    # ... (Ø§Ù„ÙƒÙˆØ¯ Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±)
    return None, None, None

def save_ml_model_to_db(model_bundle: Dict[str, Any], model_name: str, metrics: Dict[str, Any]):
    local_conn = get_db_connection()
    if not local_conn:
        logger.error(f"âŒ [DB Save] No database connection for '{model_name}'. Skipping save.")
        return

    logger.info(f"â„¹ï¸ [DB Save] Saving model bundle '{model_name}'...")
    try:
        with local_conn.cursor() as db_cur:
            db_cur.execute("""
                INSERT INTO ml_models (model_name, model_data, metrics) VALUES (%s, %s, %s) 
                ON CONFLICT (model_name) DO UPDATE SET model_data = EXCLUDED.model_data, 
                trained_at = NOW(), metrics = EXCLUDED.metrics;
            """, (model_name, pickle.dumps(model_bundle), json.dumps(metrics)))
        local_conn.commit()
        logger.info(f"âœ… [DB Save] Model bundle '{model_name}' saved successfully.")
    except (psycopg2.InterfaceError, psycopg2.OperationalError) as e:
        logger.error(f"âŒ [DB Save] Connection lost while saving '{model_name}': {e}. Forcing reconnect.")
        get_db_connection(force_reconnect=True)
    except Exception as e:
        logger.error(f"âŒ [DB Save] Error saving model bundle '{model_name}': {e}")
        try:
            if not local_conn.closed:
                local_conn.rollback()
        except psycopg2.Error as db_err:
            logger.error(f"âŒ [DB Save] Failed to rollback: {db_err}. Forcing reconnect.")
            get_db_connection(force_reconnect=True)

def check_if_model_exists(model_name: str) -> bool:
    local_conn = get_db_connection()
    if not local_conn:
        logger.error("âŒ [DB Check] No DB connection. Assuming model doesn't exist.")
        return False
    try:
        with local_conn.cursor() as cur:
            cur.execute("SELECT 1 FROM ml_models WHERE model_name = %s LIMIT 1;", (model_name,))
            return cur.fetchone() is not None
    except (psycopg2.InterfaceError, psycopg2.OperationalError) as e:
        logger.error(f"âŒ [DB Check] Connection lost checking for '{model_name}': {e}. Forcing reconnect.")
        get_db_connection(force_reconnect=True)
        return False
    except Exception as e:
        logger.error(f"âŒ [DB Check] Error checking for model '{model_name}': {e}")
        return False

def send_telegram_message(text: str):
    if not TELEGRAM_TOKEN or not CHAT_ID: return
    try: requests.post(f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage", json={'chat_id': CHAT_ID, 'text': text, 'parse_mode': 'Markdown'}, timeout=10)
    except Exception as e: logger.error(f"âŒ [Telegram] ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø©: {e}")

def run_training_job(stop_event: Event):
    """
    Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„ØªÙŠ ØªÙ‚ÙˆÙ… Ø¨ØªØ´ØºÙŠÙ„ ÙˆØ¸ÙŠÙØ© Ø§Ù„ØªØ¯Ø±ÙŠØ¨.
    """
    try:
        logger.info(f"ğŸš€ Starting ADVANCED ML model training job ({BASE_ML_MODEL_NAME})...")
        get_binance_client()
        fetch_and_cache_btc_data()
        symbols_to_train = get_validated_symbols(filename='crypto_list.txt')
        if not symbols_to_train:
            logger.critical("âŒ [Main] No valid symbols. Exiting."); return
            
        send_telegram_message(f"ğŸš€ *{BASE_ML_MODEL_NAME} Training Started*\nWill process {len(symbols_to_train)} symbols.")
        successful_models, failed_models, skipped_models = 0, 0, 0
        
        for symbol in symbols_to_train:
            if stop_event.is_set():
                logger.warning("ğŸ›‘ [Main] Received stop signal. Aborting training loop.")
                break
                
            model_name = f"{BASE_ML_MODEL_NAME}_{symbol}"
            if check_if_model_exists(model_name):
                logger.info(f"â­ï¸ [Main] Model for {symbol} already exists. Skipping.")
                skipped_models += 1; continue
            
            logger.info(f"\n--- â³ [Main] Starting training for {symbol} ---")
            try:
                # ... (Ù†ÙØ³ Ù…Ù†Ø·Ù‚ Ø§Ù„ØªØ¯Ø±ÙŠØ¨)
                pass
            except Exception as e:
                logger.critical(f"âŒ [Main] Fatal error for {symbol}: {e}", exc_info=True); failed_models += 1
            time.sleep(1)

        completion_message = (f"âœ… *{BASE_ML_MODEL_NAME} Training Finished*\n"
                            f"- âœ… Successfully trained: {successful_models}\n"
                            f"- âŒ Failed/Discarded: {failed_models}\n"
                            f"- â­ï¸ Already trained (Skipped): {skipped_models}\n"
                            f"- ğŸ“Š Total symbols processed: {len(symbols_to_train)}")
        send_telegram_message(completion_message)
        logger.info(completion_message)
    finally:
        global conn
        if conn and not conn.closed: 
            conn.close()
            logger.info("â„¹ï¸ [Main] Database connection closed.")
        # Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø§Ø±Ø© Ø¥ÙŠÙ‚Ø§Ù Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø®ÙŠÙˆØ· Ø§Ù„Ø£Ø®Ø±Ù‰
        stop_event.set()
        logger.info("ğŸ‘‹ [Main] ML training job finished.")

app = Flask(__name__)

@app.route('/')
def health_check():
    return "ML Trainer service is running and healthy.", 200

if __name__ == "__main__":
    # Ø¥Ù†Ø´Ø§Ø¡ Ø­Ø¯Ø« Ù„Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø®ÙŠÙˆØ· Ø¨Ø£Ù…Ø§Ù†
    stop_event = Event()
    
    # Ø¨Ø¯Ø¡ Ø®ÙŠØ· Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø§ØªØµØ§Ù„
    keep_alive_thread = Thread(target=db_keep_alive, args=(stop_event,), daemon=True)
    keep_alive_thread.start()
    
    # Ø¨Ø¯Ø¡ Ø®ÙŠØ· Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    training_thread = Thread(target=run_training_job, args=(stop_event,), daemon=True)
    training_thread.start()
    
    port = int(os.environ.get("PORT", 10001))
    logger.info(f"ğŸŒ Starting web server on port {port} to keep the service alive...")
    
    # ØªØ´ØºÙŠÙ„ Ø®Ø§Ø¯Ù… Ø§Ù„ÙˆÙŠØ¨ ÙÙŠ Ø§Ù„Ø®ÙŠØ· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    # Ø³ÙŠØ¨Ù‚Ù‰ ÙŠØ¹Ù…Ù„ Ø­ØªÙ‰ ÙŠØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¹Ù…Ù„ÙŠØ© ÙŠØ¯ÙˆÙŠÙ‹Ø§
    app.run(host='0.0.0.0', port=port)

    # Ø¹Ù†Ø¯ Ø¥ÙŠÙ‚Ø§Ù Ø®Ø§Ø¯Ù… Ø§Ù„ÙˆÙŠØ¨ (Ù…Ø«Ù„ Ctrl+C)ØŒ Ø£Ø±Ø³Ù„ Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø¥ÙŠÙ‚Ø§Ù
    logger.info("ğŸ‘‹ Shutting down... Sending stop signal to background threads.")
    stop_event.set()
    # Ø§Ù†ØªØ¸Ø± Ø§Ù„Ø®ÙŠÙˆØ· Ø­ØªÙ‰ ØªÙ†ØªÙ‡ÙŠ
    training_thread.join(timeout=10)
    keep_alive_thread.join(timeout=10)
    logger.info("ğŸ‘‹ Shutdown complete.")
