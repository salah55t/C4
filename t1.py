import time
import os
import json
import logging
import numpy as np
import pandas as pd
import pickle
import re
from binance.client import Client
from datetime import datetime, timedelta, timezone
from decouple import config
from typing import List, Dict, Optional, Any
from sklearn.preprocessing import StandardScaler
import warnings
import threading
import http.server
import socketserver

# --- ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª ---
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.simplefilter(action='ignore', category=UserWarning)

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger('CryptoBacktesterDetailed')

# --- ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±) ---
try:
    API_KEY: str = config('BINANCE_API_KEY', default='')
    API_SECRET: str = config('BINANCE_API_SECRET', default='')
except Exception as e:
    logger.warning(f"Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ù…ÙØ§ØªÙŠØ­ API Ù…Ù† Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©: {e}")
    API_KEY, API_SECRET = '', ''

# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ ----------------------
BACKTEST_DAYS: int = 10
INITIAL_CAPITAL: float = 10000.0
RISK_PER_TRADE_PERCENT: float = 1.0
MAX_OPEN_TRADES: int = 30
BUY_CONFIDENCE_THRESHOLD: float = 0.70
TRADING_FEE_PERCENT: float = 0.1

# ---------------------- Ø«ÙˆØ§Ø¨Øª Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© ----------------------
BASE_ML_MODEL_NAME: str = 'LightGBM_Scalping_V8_With_Momentum'
MODEL_FOLDER: str = 'V8'
TIMEFRAME: str = '15m'
TIMEFRAMES_FOR_TREND_ANALYSIS: List[str] = ['15m', '1h', '4h']
BTC_SYMBOL: str = 'BTCUSDT'
ADX_PERIOD: int = 14; RSI_PERIOD: int = 14; ATR_PERIOD: int = 14
EMA_PERIODS: List[int] = [21, 50, 200]
REL_VOL_PERIOD: int = 30; MOMENTUM_PERIOD: int = 12; EMA_SLOPE_PERIOD: int = 5
ATR_FALLBACK_SL_MULTIPLIER: float = 1.5
ATR_FALLBACK_TP_MULTIPLIER: float = 2.2

# --- Ù…ØªØºÙŠØ±Ø§Øª Ø¹Ø§Ù…Ø© ---
client: Optional[Client] = None
exchange_info_map: Dict[str, Any] = {}
ml_models_cache: Dict[str, Any] = {}

# ---------------------- Ø®Ø§Ø¯Ù… Ø§Ù„ÙˆÙŠØ¨ Ø§Ù„Ø¨Ø³ÙŠØ· ----------------------
def start_web_server():
    """
    ÙŠØ¨Ø¯Ø£ Ø®Ø§Ø¯Ù… ÙˆÙŠØ¨ Ø¨Ø³ÙŠØ· ÙÙŠ Ø®ÙŠØ· Ù…Ù†ÙØµÙ„ Ù„Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù„Ø·Ù„Ø¨Ø§Øª HTTP.
    Ù‡Ø°Ø§ Ø¶Ø±ÙˆØ±ÙŠ Ù„Ù…Ù†ØµØ§Øª Ù…Ø«Ù„ Render Ù„Ù…Ù†Ø¹ ØªÙˆÙ‚Ù Ø§Ù„Ø®Ø¯Ù…Ø©.
    """
    # Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†ÙØ° Ù…Ù† Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù… 8080 ÙƒÙ‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
    PORT = int(os.environ.get('PORT', 8080))
    
    # Ù…Ø¹Ø§Ù„Ø¬ Ø·Ù„Ø¨Ø§Øª Ø¨Ø³ÙŠØ·
    class Handler(http.server.SimpleHTTPRequestHandler):
        def do_GET(self):
            self.send_response(200)
            self.send_header('Content-type', 'text/plain; charset=utf-8')
            self.end_headers()
            self.wfile.write("Ø§Ù„Ø®Ø§Ø¯Ù… ÙŠØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ø³Ù„ÙŠÙ….".encode('utf-8'))

    # Ø§Ø¨Ø¯Ø£ Ø§Ù„Ø®Ø§Ø¯Ù… ÙÙŠ Ø®ÙŠØ· Ù…Ù†ÙØµÙ„
    def run_server():
        with socketserver.TCPServer(("", PORT), Handler) as httpd:
            logger.info(f"Ø®Ø§Ø¯Ù… Ø§Ù„ÙˆÙŠØ¨ ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†ÙØ° {PORT}")
            httpd.serve_forever()

    server_thread = threading.Thread(target=run_server)
    server_thread.daemon = True  # Ø§Ø³Ù…Ø­ Ù„Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ø¨Ø§Ù„Ø®Ø±ÙˆØ¬ Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù† Ø§Ù„Ø®ÙŠØ· ÙŠØ¹Ù…Ù„
    server_thread.start()

# ---------------------- Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© (Ù…Ù‚ØªØ¨Ø³Ø© Ù…Ù† Ø§Ù„Ø¨ÙˆØª) ----------------------

def get_exchange_info_map() -> None:
    global exchange_info_map
    if not client: return
    logger.info("Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ù…Ù† Ø§Ù„Ù…Ù†ØµØ©...")
    try:
        info = client.get_exchange_info()
        exchange_info_map = {s['symbol']: s for s in info['symbols']}
        logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ù„Ù€ {len(exchange_info_map)} Ø¹Ù…Ù„Ø©.")
    except Exception as e:
        logger.error(f"ÙØ´Ù„ Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù†ØµØ©: {e}")

def get_validated_symbols(filename: str = 'crypto_list.txt') -> List[str]:
    if not client: return []
    try:
        if not os.path.exists(filename):
            logger.error(f"Ù…Ù„Ù Ø§Ù„Ø¹Ù…Ù„Ø§Øª '{filename}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. ÙŠØ±Ø¬Ù‰ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ù ÙˆØ¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù…Ù„Ø§Øª.")
            return []
        with open(filename, 'r', encoding='utf-8') as f:
            raw_symbols = {line.strip().upper() for line in f if line.strip() and not line.startswith('#')}
        formatted = {f"{s}USDT" if not s.endswith('USDT') else s for s in raw_symbols}
        if not exchange_info_map: get_exchange_info_map()
        active = {s for s, info in exchange_info_map.items() if info.get('quoteAsset') == 'USDT' and info.get('status') == 'TRADING'}
        validated = sorted(list(formatted.intersection(active)))
        logger.info(f"Ø³ÙŠØªÙ… Ø§Ø®ØªØ¨Ø§Ø± {len(validated)} Ø¹Ù…Ù„Ø©.")
        return validated
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¹Ù…Ù„Ø§Øª: {e}", exc_info=True)
        return []

def fetch_historical_data(symbol: str, interval: str, start_date_str: str) -> Optional[pd.DataFrame]:
    if not client: return None
    try:
        klines = client.get_historical_klines(symbol, interval, start_str=start_date_str)
        if not klines: return None
        df = pd.DataFrame(klines, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_volume', 'trades', 'taker_buy_base', 'taker_buy_quote', 'ignore'])
        df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']]
        for col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True)
        df.set_index('timestamp', inplace=True)
        return df.dropna()
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„Ù€ {symbol}: {e}")
        return None

# --- [Ù…ÙØµØ­Ø­] --- ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¯Ø§Ù„Ø© Ù„ØªÙ‚Ø¨Ù„ Ø§Ø³Ù… Ø§Ù„Ø¹Ù…Ù„Ø©
def calculate_features(df: pd.DataFrame, btc_df: Optional[pd.DataFrame], symbol: str) -> pd.DataFrame:
    df_calc = df.copy()
    for period in EMA_PERIODS:
        df_calc[f'ema_{period}'] = df_calc['close'].ewm(span=period, adjust=False).mean()
    high_low = df_calc['high'] - df_calc['low']
    high_close = (df_calc['high'] - df_calc['close'].shift()).abs()
    low_close = (df_calc['low'] - df_calc['close'].shift()).abs()
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    df_calc['atr'] = tr.ewm(span=ATR_PERIOD, adjust=False).mean()
    up_move = df_calc['high'].diff()
    down_move = -df_calc['low'].diff()
    plus_dm = pd.Series(np.where((up_move > down_move) & (up_move > 0), up_move, 0.0), index=df_calc.index)
    minus_dm = pd.Series(np.where((down_move > up_move) & (down_move > 0), down_move, 0.0), index=df_calc.index)
    plus_di = 100 * plus_dm.ewm(span=ADX_PERIOD, adjust=False).mean() / df_calc['atr'].replace(0, 1e-9)
    minus_di = 100 * minus_dm.ewm(span=ADX_PERIOD, adjust=False).mean() / df_calc['atr'].replace(0, 1e-9)
    dx = 100 * (abs(plus_di - minus_di) / (plus_di + minus_di).replace(0, 1e-9))
    df_calc['adx'] = dx.ewm(span=ADX_PERIOD, adjust=False).mean()
    delta = df_calc['close'].diff()
    gain = delta.clip(lower=0).ewm(com=RSI_PERIOD - 1, adjust=False).mean()
    loss = -delta.clip(upper=0).ewm(com=RSI_PERIOD - 1, adjust=False).mean()
    df_calc['rsi'] = 100 - (100 / (1 + (gain / loss.replace(0, 1e-9))))
    df_calc['relative_volume'] = df_calc['volume'] / (df_calc['volume'].rolling(window=REL_VOL_PERIOD, min_periods=1).mean() + 1e-9)
    df_calc['price_vs_ema50'] = (df_calc['close'] / df_calc['ema_50']) - 1
    df_calc['price_vs_ema200'] = (df_calc['close'] / df_calc['ema_200']) - 1
    
    # --- [Ù…ÙØµØ­Ø­] --- Ù…Ù†Ø·Ù‚ Ø¬Ø¯ÙŠØ¯ Ù„Ø­Ø³Ø§Ø¨ Ø§Ø±ØªØ¨Ø§Ø· Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ†
    if symbol == BTC_SYMBOL:
        df_calc['btc_correlation'] = 1.0
    elif btc_df is not None and not btc_df.empty:
        if 'btc_returns' not in btc_df.columns:
            raise ValueError("btc_df is missing the 'btc_returns' column")
        merged_df = pd.merge(df_calc, btc_df[['btc_returns']], left_index=True, right_index=True, how='left').fillna(0)
        df_calc['btc_correlation'] = df_calc['close'].pct_change().rolling(window=30).corr(merged_df['btc_returns'])
    else:
        df_calc['btc_correlation'] = 0.0

    df_calc[f'roc_{MOMENTUM_PERIOD}'] = (df_calc['close'] / df_calc['close'].shift(MOMENTUM_PERIOD) - 1) * 100
    df_calc['roc_acceleration'] = df_calc[f'roc_{MOMENTUM_PERIOD}'].diff()
    ema_slope = df_calc['close'].ewm(span=EMA_SLOPE_PERIOD, adjust=False).mean()
    df_calc[f'ema_slope_{EMA_SLOPE_PERIOD}'] = (ema_slope - ema_slope.shift(1)) / ema_slope.shift(1).replace(0, 1e-9) * 100
    df_calc['hour_of_day'] = df_calc.index.hour
    return df_calc.astype('float32', errors='ignore')

def load_ml_model_bundle_from_folder(symbol: str) -> Optional[Dict[str, Any]]:
    global ml_models_cache
    model_name = f"{BASE_ML_MODEL_NAME}_{symbol}"
    if model_name in ml_models_cache: return ml_models_cache[model_name]
    model_path = os.path.join(MODEL_FOLDER, f"{model_name}.pkl")
    if not os.path.exists(model_path):
        logger.debug(f"âš ï¸ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: '{model_path}'.")
        return None
    try:
        with open(model_path, 'rb') as f:
            model_bundle = pickle.load(f)
        if 'model' in model_bundle and 'scaler' in model_bundle and 'feature_names' in model_bundle:
            ml_models_cache[model_name] = model_bundle
            return model_bundle
        return None
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ {symbol}: {e}", exc_info=True)
        return None

class TradingStrategy:
    def __init__(self, symbol: str):
        self.symbol = symbol
        model_bundle = load_ml_model_bundle_from_folder(symbol)
        self.ml_model, self.scaler, self.feature_names = (model_bundle.get('model'), model_bundle.get('scaler'), model_bundle.get('feature_names')) if model_bundle else (None, None, None)

    # --- [Ù…ÙØµØ­Ø­] --- ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¯Ø§Ù„Ø© Ù„ØªÙ…Ø±ÙŠØ± Ø§Ø³Ù… Ø§Ù„Ø¹Ù…Ù„Ø©
    def get_features(self, df_15m: pd.DataFrame, df_4h: pd.DataFrame, btc_df: pd.DataFrame) -> Optional[pd.DataFrame]:
        if self.feature_names is None: return None
        try:
            df_featured = calculate_features(df_15m, btc_df, self.symbol)
            df_4h_features = calculate_features(df_4h, None, self.symbol)
            df_4h_features = df_4h_features.rename(columns=lambda c: f"{c}_4h", inplace=False)
            required_4h_cols = ['rsi_4h', 'price_vs_ema50_4h']
            df_featured = df_featured.join(df_4h_features[required_4h_cols], how='outer')
            df_featured.fillna(method='ffill', inplace=True)
            for col in self.feature_names:
                if col not in df_featured.columns: df_featured[col] = 0.0
            df_featured.replace([np.inf, -np.inf], np.nan, inplace=True)
            return df_featured.dropna(subset=self.feature_names)
        except Exception as e:
            logger.error(f"âŒ [{self.symbol}] ÙØ´Ù„ Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª: {e}", exc_info=True)
            return None

    def generate_buy_signal(self, features_row: pd.Series) -> Optional[Dict[str, Any]]:
        if not all([self.ml_model, self.scaler, self.feature_names]): return None
        try:
            features_df = pd.DataFrame([features_row], columns=self.feature_names)
            features_scaled_np = self.scaler.transform(features_df)
            features_scaled_df = pd.DataFrame(features_scaled_np, columns=self.feature_names)
            prediction = self.ml_model.predict(features_scaled_df)[0]
            if prediction != 1: return None
            prediction_proba = self.ml_model.predict_proba(features_scaled_df)
            confidence = float(np.max(prediction_proba[0]))
            return {'prediction': int(prediction), 'confidence': confidence}
        except Exception as e:
            logger.warning(f"âš ï¸ [{self.symbol}] Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
            return None

def calculate_tp_sl(entry_price: float, last_atr: float) -> Optional[Dict[str, Any]]:
    if last_atr <= 0: return None
    tp = entry_price + (last_atr * ATR_FALLBACK_TP_MULTIPLIER)
    sl = entry_price - (last_atr * ATR_FALLBACK_SL_MULTIPLIER)
    return {'target_price': tp, 'stop_loss': sl}

def determine_market_trend_at_time(timestamp: pd.Timestamp, btc_data_all_tf: Dict[str, pd.DataFrame]) -> Dict:
    details = {}
    total_score = 0
    tf_weights = {'15m': 0.2, '1h': 0.3, '4h': 0.5}
    
    for tf, df in btc_data_all_tf.items():
        if timestamp not in df.index:
            details[tf] = {"score": 0, "label": "ØºÙŠØ± ÙˆØ§Ø¶Ø­", "reason": "Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ©"}
            continue
        
        last_candle = df.loc[timestamp]
        close, ema21, ema50, ema200 = last_candle['close'], last_candle['ema_21'], last_candle['ema_50'], last_candle['ema_200']
        
        tf_score = 0
        if close > ema21: tf_score += 1
        elif close < ema21: tf_score -= 1
        if ema21 > ema50: tf_score += 1
        elif ema21 < ema50: tf_score -= 1
        if ema50 > ema200: tf_score += 1
        elif ema50 < ema200: tf_score -= 1
        
        label = "Ù…Ø­Ø§ÙŠØ¯"
        if tf_score >= 2: label = "ØµØ§Ø¹Ø¯"
        elif tf_score <= -2: label = "Ù‡Ø§Ø¨Ø·"
        details[tf] = {"score": tf_score, "label": label}

        total_score += tf_score * tf_weights[tf]

    final_score = round(total_score)
    trend_label = "Ù…Ø­Ø§ÙŠØ¯"
    if final_score >= 4: trend_label = "ØµØ§Ø¹Ø¯ Ù‚ÙˆÙŠ"
    elif final_score >= 1: trend_label = "ØµØ§Ø¹Ø¯"
    elif final_score <= -4: trend_label = "Ù‡Ø§Ø¨Ø· Ù‚ÙˆÙŠ"
    elif final_score <= -1: trend_label = "Ù‡Ø§Ø¨Ø·"
    
    return {"trend_score": final_score, "trend_label": trend_label, "details_by_tf": details}

def capture_trade_details(features_row: pd.Series, market_trend: Dict, confidence: float) -> Dict:
    details = {
        "market_trend": market_trend,
        "ml_confidence": f"{confidence:.2%}",
        "filters": {
            "adx": f"{features_row.get('adx', 0):.2f}",
            "rsi": f"{features_row.get('rsi', 0):.2f}",
            "relative_volume": f"{features_row.get('relative_volume', 0):.2f}",
            f"roc_{MOMENTUM_PERIOD}": f"{features_row.get(f'roc_{MOMENTUM_PERIOD}', 0):.2f}",
            f"ema_slope_{EMA_SLOPE_PERIOD}": f"{features_row.get(f'ema_slope_{EMA_SLOPE_PERIOD}', 0):.6f}",
            "btc_correlation": f"{features_row.get('btc_correlation', 0):.2f}",
            "price_vs_ema50": f"{features_row.get('price_vs_ema50', 0):.4f}",
            "price_vs_ema200": f"{features_row.get('price_vs_ema200', 0):.4f}",
            "atr": f"{features_row.get('atr', 0):.8f}"
        }
    }
    return details

def generate_detailed_report(closed_trades: List[Dict], initial_capital: float, final_capital: float):
    logger.info("\n" + "="*80)
    logger.info("ðŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ Ø§Ù„Ù…ÙØµÙ„ ðŸ“Š")
    logger.info("="*80)

    if not closed_trades:
        logger.warning("Ù„Ù… ÙŠØªÙ… Ø¥ØºÙ„Ø§Ù‚ Ø£ÙŠ ØµÙÙ‚Ø§Øª Ø®Ù„Ø§Ù„ ÙØªØ±Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±.")
        return

    total_trades = len(closed_trades)
    wins = [t for t in closed_trades if t['pnl_usdt'] > 0]
    losses = [t for t in closed_trades if t['pnl_usdt'] <= 0]
    win_rate = (len(wins) / total_trades) * 100 if total_trades > 0 else 0
    total_pnl_usdt = final_capital - initial_capital
    total_pnl_pct = (total_pnl_usdt / initial_capital) * 100
    gross_profit = sum(t['pnl_usdt'] for t in wins)
    gross_loss = abs(sum(t['pnl_usdt'] for t in losses))
    profit_factor = gross_profit / gross_loss if gross_loss > 0 else float('inf')
    avg_win_pct = np.mean([t['pnl_pct'] for t in wins]) if wins else 0
    avg_loss_pct = np.mean([t['pnl_pct'] for t in losses]) if losses else 0
    
    logger.info(f"ÙØªØ±Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {BACKTEST_DAYS} Ø£ÙŠØ§Ù…")
    logger.info(f"Ø±Ø£Ø³ Ø§Ù„Ù…Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„ÙŠ: ${initial_capital:,.2f}")
    logger.info(f"Ø±Ø£Ø³ Ø§Ù„Ù…Ø§Ù„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: ${final_capital:,.2f}")
    logger.info("-" * 30)
    logger.info(f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±Ø¨Ø­/Ø§Ù„Ø®Ø³Ø§Ø±Ø©: ${total_pnl_usdt:,.2f} ({total_pnl_pct:.2f}%)")
    logger.info(f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙ‚Ø§Øª: {total_trades}")
    logger.info(f"Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ø±Ø§Ø¨Ø­Ø©: {len(wins)} | Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ø®Ø§Ø³Ø±Ø©: {len(losses)}")
    logger.info(f"Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­: {win_rate:.2f}%")
    logger.info(f"Ø¹Ø§Ù…Ù„ Ø§Ù„Ø±Ø¨Ø­: {profit_factor:.2f}")
    logger.info(f"Ù…ØªÙˆØ³Ø· Ø±Ø¨Ø­ Ø§Ù„ØµÙÙ‚Ø© Ø§Ù„Ø±Ø§Ø¨Ø­Ø©: {avg_win_pct:.2f}%")
    logger.info(f"Ù…ØªÙˆØ³Ø· Ø®Ø³Ø§Ø±Ø© Ø§Ù„ØµÙÙ‚Ø© Ø§Ù„Ø®Ø§Ø³Ø±Ø©: {avg_loss_pct:.2f}%")
    
    logger.info("\n" + "="*80)
    logger.info(f"âœ… Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ø±Ø§Ø¨Ø­Ø© ({len(wins)} ØµÙÙ‚Ø©)")
    logger.info("="*80)
    if not wins:
        logger.info("Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙÙ‚Ø§Øª Ø±Ø§Ø¨Ø­Ø©.")
    else:
        for trade in wins:
            print_trade_details(trade)

    logger.info("\n" + "="*80)
    logger.info(f"âŒ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ø®Ø§Ø³Ø±Ø© ({len(losses)} ØµÙÙ‚Ø©)")
    logger.info("="*80)
    if not losses:
        logger.info("Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙÙ‚Ø§Øª Ø®Ø§Ø³Ø±Ø©.")
    else:
        for trade in losses:
            print_trade_details(trade)

def print_trade_details(trade: Dict):
    details_json = json.dumps(trade['details'], indent=2, ensure_ascii=False)
    logger.info(
        f"\n--- Ø§Ù„Ø¹Ù…Ù„Ø©: {trade['symbol']} | Ø§Ù„Ø±Ø¨Ø­: {trade['pnl_pct']:.2f}% (${trade['pnl_usdt']:.2f}) ---"
        f"\nÙˆÙ‚Øª Ø§Ù„Ø¯Ø®ÙˆÙ„: {trade['entry_time']} | Ø³Ø¹Ø± Ø§Ù„Ø¯Ø®ÙˆÙ„: {trade['entry_price']:.5f}"
        f"\nÙˆÙ‚Øª Ø§Ù„Ø®Ø±ÙˆØ¬: {trade['close_time']} | Ø³Ø¹Ø± Ø§Ù„Ø®Ø±ÙˆØ¬: {trade['closing_price']:.5f} | Ø³Ø¨Ø¨ Ø§Ù„Ø®Ø±ÙˆØ¬: {trade['close_reason']}"
        f"\nØªÙØ§ØµÙŠÙ„ ÙˆÙ‚Øª Ø§Ù„Ø¯Ø®ÙˆÙ„:\n{details_json}"
    )

# ---------------------- Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ ----------------------
def run_backtest():
    global client
    logger.info(f"ðŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ Ù„Ù…Ø¯Ø© {BACKTEST_DAYS} Ø£ÙŠØ§Ù…...")
    
    client = Client(API_KEY, API_SECRET)
    
    symbols_to_test = get_validated_symbols()
    if not symbols_to_test:
        logger.critical("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¹Ù…Ù„Ø§Øª ØµØ§Ù„Ø­Ø© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±. Ø§Ù„Ø®Ø±ÙˆØ¬.")
        return

    start_date = datetime.now(timezone.utc) - timedelta(days=BACKTEST_DAYS)
    start_date_str = start_date.strftime("%d %b %Y %H:%M:%S")
    
    all_data = {}
    logger.info(f"Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„Ù€ {len(symbols_to_test)} Ø¹Ù…Ù„Ø©...")
    for symbol in symbols_to_test + [BTC_SYMBOL]:
        df = fetch_historical_data(symbol, TIMEFRAME, start_date_str)
        if df is not None and not df.empty:
            all_data[symbol] = df
        else:
            logger.warning(f"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù€ {symbol}ØŒ Ø³ÙŠØªÙ… ØªØ¬Ø§Ù‡Ù„Ù‡Ø§.")
        time.sleep(0.5)
    
    symbols_to_test = [s for s in symbols_to_test if s in all_data]
    if not symbols_to_test:
        logger.critical("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø£ÙŠ Ù…Ù† Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©. Ø§Ù„Ø®Ø±ÙˆØ¬.")
        return

    logger.info("Ø¬Ø§Ø±ÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ© ÙˆØ§Ù„Ù…ÙŠØ²Ø§Øª...")
    btc_data_15m = all_data[BTC_SYMBOL]
    btc_data_15m['btc_returns'] = btc_data_15m['close'].pct_change()
    
    btc_data_all_tf = {}
    for tf in TIMEFRAMES_FOR_TREND_ANALYSIS:
        df_btc_tf = fetch_historical_data(BTC_SYMBOL, tf, start_date_str)
        for period in EMA_PERIODS:
            df_btc_tf[f'ema_{period}'] = df_btc_tf['close'].ewm(span=period, adjust=False).mean()
        btc_data_all_tf[tf] = df_btc_tf.dropna()

    all_features = {}
    for symbol in symbols_to_test:
        df_15m = all_data[symbol]
        df_4h = fetch_historical_data(symbol, '4h', start_date_str)
        if df_4h is None: 
            logger.warning(f"Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª 4h Ù„Ù€ {symbol}, Ø³ÙŠØªÙ… ØªØ¬Ø§Ù‡Ù„Ù‡Ø§.")
            continue
        strategy = TradingStrategy(symbol)
        if not all([strategy.ml_model, strategy.scaler, strategy.feature_names]):
            logger.warning(f"Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ {symbol}, Ø³ÙŠØªÙ… ØªØ¬Ø§Ù‡Ù„Ù‡Ø§.")
            continue
        features = strategy.get_features(df_15m, df_4h, btc_data_15m)
        if features is not None and not features.empty:
            all_features[symbol] = features
    
    symbols_to_test = [s for s in symbols_to_test if s in all_features]
    if not symbols_to_test:
        logger.critical("ÙØ´Ù„ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù…Ù„Ø§Øª. Ø§Ù„Ø®Ø±ÙˆØ¬.")
        return

    main_df = pd.concat([df['close'].rename(f"{symbol}_close") for symbol, df in all_data.items()], axis=1)
    main_df.dropna(inplace=True)
    
    capital = INITIAL_CAPITAL
    open_trades: List[Dict] = []
    closed_trades: List[Dict] = []
    
    logger.info(f"â–¶ï¸ Ø¨Ø¯Ø¡ Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ù…Ù† {main_df.index[0]} Ø¥Ù„Ù‰ {main_df.index[-1]}...")
    
    for timestamp, row in main_df.iterrows():
        trades_to_close_indices = []
        for i, trade in enumerate(open_trades):
            symbol = trade['symbol']
            if timestamp not in all_data[symbol].index: continue
            current_candle = all_data[symbol].loc[timestamp]
            
            if current_candle['high'] >= trade['target_price']:
                closing_price, close_reason = trade['target_price'], 'target_hit'
            elif current_candle['low'] <= trade['stop_loss']:
                closing_price, close_reason = trade['stop_loss'], 'stop_loss_hit'
            else:
                continue
            
            pnl_usdt = (closing_price - trade['entry_price']) * trade['quantity']
            fee = (trade['notional_value'] * (TRADING_FEE_PERCENT / 100)) + \
                  (closing_price * trade['quantity'] * (TRADING_FEE_PERCENT / 100))
            net_pnl_usdt = pnl_usdt - fee
            pnl_pct = (net_pnl_usdt / trade['notional_value']) * 100
            capital += trade['notional_value'] + net_pnl_usdt
            
            trade.update({
                'closing_price': closing_price, 'close_time': timestamp,
                'pnl_usdt': net_pnl_usdt, 'pnl_pct': pnl_pct, 'close_reason': close_reason
            })
            closed_trades.append(trade)
            trades_to_close_indices.append(i)

        for i in sorted(trades_to_close_indices, reverse=True):
            del open_trades[i]
            
        if len(open_trades) >= MAX_OPEN_TRADES: continue

        for symbol in symbols_to_test:
            if any(t['symbol'] == symbol for t in open_trades): continue
            if symbol not in all_features or timestamp not in all_features[symbol].index: continue
            
            features_row = all_features[symbol].loc[timestamp]
            if features_row.isnull().any(): continue
            
            strategy = TradingStrategy(symbol)
            ml_signal = strategy.generate_buy_signal(features_row)
            
            if ml_signal and ml_signal['confidence'] >= BUY_CONFIDENCE_THRESHOLD:
                entry_price = features_row['close']
                last_atr = features_row['atr']
                tp_sl = calculate_tp_sl(entry_price, last_atr)
                if not tp_sl: continue
                
                risk_amount_usdt = capital * (RISK_PER_TRADE_PERCENT / 100)
                risk_per_coin = entry_price - tp_sl['stop_loss']
                if risk_per_coin <= 0: continue
                quantity = risk_amount_usdt / risk_per_coin
                notional_value = quantity * entry_price
                
                if capital < notional_value: continue
                
                market_trend = determine_market_trend_at_time(timestamp, btc_data_all_tf)
                trade_details = capture_trade_details(features_row, market_trend, ml_signal['confidence'])
                
                capital -= notional_value
                
                new_trade = {
                    'symbol': symbol, 'entry_time': timestamp, 'entry_price': entry_price,
                    'quantity': quantity, 'notional_value': notional_value,
                    'target_price': tp_sl['target_price'], 'stop_loss': tp_sl['stop_loss'],
                    'details': trade_details
                }
                open_trades.append(new_trade)
                logger.info(f"ðŸŸ¢ ÙØªØ­ ØµÙÙ‚Ø©: {symbol} @ ${entry_price:.4f} ÙÙŠ {timestamp}")

    if open_trades:
        logger.info("Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© ÙÙŠ Ù†Ù‡Ø§ÙŠØ© ÙØªØ±Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±...")
        last_timestamp = main_df.index[-1]
        for trade in open_trades:
            closing_price = main_df.loc[last_timestamp, f"{trade['symbol']}_close"]
            pnl_usdt = (closing_price - trade['entry_price']) * trade['quantity']
            fee = (trade['notional_value'] * (TRADING_FEE_PERCENT / 100)) * 2
            net_pnl_usdt = pnl_usdt - fee
            pnl_pct = (net_pnl_usdt / trade['notional_value']) * 100
            capital += trade['notional_value'] + net_pnl_usdt
            trade.update({
                'closing_price': closing_price, 'close_time': last_timestamp,
                'pnl_usdt': net_pnl_usdt, 'pnl_pct': pnl_pct, 'close_reason': 'end_of_backtest'
            })
            closed_trades.append(trade)

    generate_detailed_report(closed_trades, INITIAL_CAPITAL, capital)

if __name__ == "__main__":
    # --- [Ø¬Ø¯ÙŠØ¯] --- Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø®Ø§Ø¯Ù… Ø§Ù„ÙˆÙŠØ¨
    start_web_server()
    
    if not os.path.exists(MODEL_FOLDER):
        logger.critical(f"Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ '{MODEL_FOLDER}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©.")
    else:
        run_backtest()

