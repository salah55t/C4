# -*- coding: utf-8 -*-
import os
import time
import logging
import requests
import numpy as np
import pandas as pd
import pickle
import argparse
from datetime import datetime, timedelta
from decouple import config
from binance.client import Client
from binance.exceptions import BinanceAPIException
from scipy.signal import find_peaks
from sklearn.preprocessing import StandardScaler
import warnings
import gc

# --- ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª ØºÙŠØ± Ø§Ù„Ù‡Ø§Ù…Ø© ---
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)


# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (Logging) ----------------------
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ultimate_backtester.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('UltimateStrategyBacktester')

# ---------------------- ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© ----------------------
try:
    API_KEY = config('BINANCE_API_KEY', default=None)
    API_SECRET = config('BINANCE_API_SECRET', default=None)
    TELEGRAM_BOT_TOKEN = config('TELEGRAM_BOT_TOKEN', default="PLEASE_FILL_YOUR_TELEGRAM_BOT_TOKEN")
    TELEGRAM_CHAT_ID = config('TELEGRAM_CHAT_ID', default="PLEASE_FILL_YOUR_TELEGRAM_CHAT_ID")
except Exception:
    API_KEY, API_SECRET = None, None
    TELEGRAM_BOT_TOKEN = "PLEASE_FILL_YOUR_TELEGRAM_BOT_TOKEN"
    TELEGRAM_CHAT_ID = "PLEASE_FILL_YOUR_TELEGRAM_CHAT_ID"

# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø«ÙˆØ§Ø¨Øª ÙˆØ§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© ----------------------
COMMISSION_RATE = 0.001
SLIPPAGE_PERCENT = 0.0005
ATR_SL_MULTIPLIER = 1.5
ATR_TP_MULTIPLIER = 2.0
TIMEFRAME = '15m'
HIGHER_TIMEFRAME = '4h'
MAX_OPEN_TRADES = 10
MODEL_CONFIDENCE_THRESHOLD = 0.70
BASE_ML_MODEL_NAME = 'LightGBM_Scalping_V7_With_Ichimoku'
MODEL_FOLDER = 'V7'
BTC_SYMBOL = 'BTCUSDT'

# ---------------------- Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© ----------------------

def send_telegram_report(report_text: str):
    """ÙŠØ±Ø³Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¥Ù„Ù‰ ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…."""
    if TELEGRAM_BOT_TOKEN.startswith("PLEASE_FILL") or TELEGRAM_CHAT_ID.startswith("PLEASE_FILL"):
        logger.error("âŒ Ù„Ù… ÙŠØªÙ… ØªÙƒÙˆÙŠÙ† ØªÙˆÙƒÙ† ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… Ø£Ùˆ Ù…Ø¹Ø±Ù Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©. Ø³ÙŠØªÙ… Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ù‡Ù†Ø§.")
        print("\n" + "="*50 + "\n--- Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ---\n" + "="*50 + "\n" + report_text)
        return

    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    payload = {'chat_id': TELEGRAM_CHAT_ID, 'text': report_text, 'parse_mode': 'Markdown'}
    try:
        requests.post(url, json=payload, timeout=20).raise_for_status()
        logger.info("âœ… ØªÙ… Ø¥Ø±Ø³Ø§Ù„ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ù„ÙÙŠ Ø¥Ù„Ù‰ ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… Ø¨Ù†Ø¬Ø§Ø­.")
    except requests.exceptions.RequestException as e:
        logger.error(f"âŒ ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…: {e}")
        print("\n--- Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ (ÙØ´Ù„ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ Ø¹Ø¨Ø± ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…) ---\n" + report_text)

def get_validated_symbols(client: Client, filename: str = 'crypto_list.txt') -> list[str]:
    """ÙŠÙ‚Ø±Ø£ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ù…ÙˆØ² Ù…Ù† Ù…Ù„Ù ÙˆÙŠØªØ­Ù‚Ù‚ Ù…Ù†Ù‡Ø§ Ù…Ø¹ Binance."""
    logger.info(f"â„¹ï¸ [Ø§Ù„ØªØ­Ù‚Ù‚] Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø±Ù…ÙˆØ² Ù…Ù† '{filename}'...")
    try:
        if not os.path.exists(filename):
            logger.error(f"âŒ Ù…Ù„Ù Ø§Ù„Ø¹Ù…Ù„Ø§Øª '{filename}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")
            return []
        with open(filename, 'r', encoding='utf-8') as f:
            raw_symbols = {line.strip().upper() for line in f if line.strip() and not line.startswith('#')}
        formatted = {f"{s}USDT" if not s.endswith('USDT') else s for s in raw_symbols}
        exchange_info = client.get_exchange_info()
        active = {s['symbol'] for s in exchange_info['symbols'] if s.get('quoteAsset') == 'USDT' and s.get('status') == 'TRADING'}
        validated = sorted(list(formatted.intersection(active)))
        logger.info(f"âœ… [Ø§Ù„ØªØ­Ù‚Ù‚] Ø³ÙŠØªÙ… ØªØ­Ù„ÙŠÙ„ {len(validated)} Ø¹Ù…Ù„Ø© Ù…Ø¹ØªÙ…Ø¯Ø©.")
        return validated
    except Exception as e:
        logger.error(f"âŒ [Ø§Ù„ØªØ­Ù‚Ù‚] Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ²: {e}", exc_info=True)
        return []

def get_historical_data(client: Client, symbol: str, interval: str, start_date: str, end_date: str) -> pd.DataFrame:
    """ÙŠØ¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù…Ù† Binance."""
    logger.info(f"â³ Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„Ù€ {symbol} ({interval}) Ù…Ù† {start_date} Ø¥Ù„Ù‰ {end_date}...")
    try:
        klines = client.get_historical_klines(symbol, interval, start_date, end_date)
        if not klines: return pd.DataFrame()
        df = pd.DataFrame(klines, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_volume', 'trades', 'taker_buy_base', 'taker_buy_quote', 'ignore'])
        df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']]
        for col in ['open', 'high', 'low', 'close', 'volume']:
            df[col] = pd.to_numeric(df[col])
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('timestamp', inplace=True)
        return df
    except BinanceAPIException as e:
        logger.error(f"âŒ Ø®Ø·Ø£ API Ù…Ù† Binance Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª {symbol}: {e}")
        return pd.DataFrame()
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ Ø¹Ø§Ù… Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª {symbol}: {e}")
        return pd.DataFrame()

def load_ml_model_bundle_from_folder(symbol: str) -> dict | None:
    """ÙŠØ­Ù…Ù„ Ø­Ø²Ù…Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ + Ø§Ù„Ù…ÙØ¹Ø¯ÙÙ‘Ù„ + Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ÙŠØ²Ø§Øª) Ù…Ù† Ù…Ù„Ù pkl."""
    model_name = f"{BASE_ML_MODEL_NAME}_{symbol}"
    model_path = os.path.join(MODEL_FOLDER, f"{model_name}.pkl")
    if not os.path.exists(model_path):
        logger.warning(f"âš ï¸ [Ù†Ù…ÙˆØ°Ø¬ ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø©] Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ '{model_path}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ù„Ù„Ø¹Ù…Ù„Ø© {symbol}.")
        return None
    try:
        with open(model_path, 'rb') as f:
            model_bundle = pickle.load(f)
        if 'model' in model_bundle and 'scaler' in model_bundle and 'feature_names' in model_bundle:
            logger.info(f"âœ… [Ù†Ù…ÙˆØ°Ø¬ ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø©] ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ '{model_name}' Ø¨Ù†Ø¬Ø§Ø­.")
            return model_bundle
        else:
            logger.error(f"âŒ Ø­Ø²Ù…Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {model_name} ØºÙŠØ± Ù…ÙƒØªÙ…Ù„Ø©.")
            return None
    except Exception as e:
        logger.error(f"âŒ [Ù†Ù…ÙˆØ°Ø¬ ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø©] Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø¹Ù…Ù„Ø© {symbol}: {e}", exc_info=True)
        return None

# ---------------------- Ø¯Ø§Ù„Ø© Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„ÙƒØ§Ù…Ù„Ø© ----------------------
def calculate_all_features(df: pd.DataFrame, df_4h: pd.DataFrame) -> pd.DataFrame:
    """ÙŠØ­Ø³Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª ÙˆØ§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬."""
    if df.empty:
        return df
        
    df_calc = df.copy()

    # --- Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ---
    df_calc['atr'] = (df_calc['high'] - df_calc['low']).rolling(window=14).mean() # ATR
    delta = df_calc['close'].diff()
    gain = delta.clip(lower=0).ewm(com=14 - 1, adjust=False).mean()
    loss = -delta.clip(upper=0).ewm(com=14 - 1, adjust=False).mean()
    df_calc['rsi'] = 100 - (100 / (1 + (gain / loss.replace(0, 1e-9))))

    # --- MACD ---
    ema12 = df_calc['close'].ewm(span=12, adjust=False).mean()
    ema26 = df_calc['close'].ewm(span=26, adjust=False).mean()
    df_calc['macd'] = ema12 - ema26
    df_calc['macd_signal'] = df_calc['macd'].ewm(span=9, adjust=False).mean()
    df_calc['macd_hist'] = df_calc['macd'] - df_calc['macd_signal']
    df_calc['macd_cross'] = np.where(df_calc['macd'] > df_calc['macd_signal'], 1, -1)

    # --- Stochastic RSI ---
    rsi_val = df_calc['rsi']
    min_rsi = rsi_val.rolling(window=14).min()
    max_rsi = rsi_val.rolling(window=14).max()
    stoch_rsi_val = (rsi_val - min_rsi) / (max_rsi - min_rsi).replace(0, 1e-9)
    df_calc['stoch_rsi_k'] = stoch_rsi_val.rolling(window=3).mean() * 100
    df_calc['stoch_rsi_d'] = df_calc['stoch_rsi_k'].rolling(window=3).mean()
    
    # --- EMAs ---
    df_calc['ema50'] = df_calc['close'].ewm(span=50, adjust=False).mean()
    df_calc['ema200'] = df_calc['close'].ewm(span=200, adjust=False).mean()
    df_calc['price_vs_ema50'] = (df_calc['close'] / df_calc['ema50']) - 1
    df_calc['price_vs_ema200'] = (df_calc['close'] / df_calc['ema200']) - 1

    # --- Ichimoku Cloud ---
    high9 = df_calc['high'].rolling(window=9).max()
    low9 = df_calc['low'].rolling(window=9).min()
    df_calc['tenkan_sen'] = (high9 + low9) / 2
    high26 = df_calc['high'].rolling(window=26).max()
    low26 = df_calc['low'].rolling(window=26).min()
    df_calc['kijun_sen'] = (high26 + low26) / 2
    df_calc['senkou_span_a'] = ((df_calc['tenkan_sen'] + df_calc['kijun_sen']) / 2).shift(26)
    high52 = df_calc['high'].rolling(window=52).max()
    low52 = df_calc['low'].rolling(window=52).min()
    df_calc['senkou_span_b'] = ((high52 + low52) / 2).shift(26)
    df_calc['chikou_span'] = df_calc['close'].shift(-26)

    # --- Ù…ÙŠØ²Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù…Ù† Ichimoku ---
    df_calc['price_vs_tenkan'] = (df_calc['close'] / df_calc['tenkan_sen']) - 1
    df_calc['price_vs_kijun'] = (df_calc['close'] / df_calc['kijun_sen']) - 1
    df_calc['tenkan_vs_kijun'] = (df_calc['tenkan_sen'] / df_calc['kijun_sen']) - 1
    df_calc['tenkan_kijun_cross'] = np.where(df_calc['tenkan_sen'] > df_calc['kijun_sen'], 1, -1)
    df_calc['price_vs_kumo_a'] = (df_calc['close'] / df_calc['senkou_span_a']) - 1
    df_calc['price_vs_kumo_b'] = (df_calc['close'] / df_calc['senkou_span_b']) - 1
    df_calc['price_above_kumo'] = np.where((df_calc['close'] > df_calc['senkou_span_a']) & (df_calc['close'] > df_calc['senkou_span_b']), 1, 0)
    df_calc['price_below_kumo'] = np.where((df_calc['close'] < df_calc['senkou_span_a']) & (df_calc['close'] < df_calc['senkou_span_b']), 1, 0)
    df_calc['price_in_kumo'] = np.where(
        ((df_calc['close'] > df_calc['senkou_span_a']) & (df_calc['close'] < df_calc['senkou_span_b'])) |
        ((df_calc['close'] < df_calc['senkou_span_a']) & (df_calc['close'] > df_calc['senkou_span_b'])), 1, 0)
    df_calc['kumo_thickness'] = np.abs(df_calc['senkou_span_a'] - df_calc['senkou_span_b']) / df_calc['close']
    df_calc['chikou_above_kumo'] = np.where((df_calc['chikou_span'] > df_calc['senkou_span_a'].shift(-26)) & (df_calc['chikou_span'] > df_calc['senkou_span_b'].shift(-26)), 1, 0)
    df_calc['chikou_below_kumo'] = np.where((df_calc['chikou_span'] < df_calc['senkou_span_a'].shift(-26)) & (df_calc['chikou_span'] < df_calc['senkou_span_b'].shift(-26)), 1, 0)

    # --- Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© ---
    avg_atr = df_calc['atr'].mean()
    prominence = avg_atr * 0.6
    if prominence > 0:
        support_indices, _ = find_peaks(-df_calc['low'], prominence=prominence, width=5)
        resistance_indices, _ = find_peaks(df_calc['high'], prominence=prominence, width=5)
        supports = df_calc['low'].iloc[support_indices]
        resistances = df_calc['high'].iloc[resistance_indices]
        
        df_calc['dist_to_support'] = df_calc.apply(lambda row: (np.abs(supports[supports.index < row.name] - row['close']) / row['close']).min() if not supports[supports.index < row.name].empty else 1.0, axis=1)
        df_calc['dist_to_resistance'] = df_calc.apply(lambda row: (np.abs(resistances[resistances.index < row.name] - row['close']) / row['close']).min() if not resistances[resistances.index < row.name].empty else 1.0, axis=1)
        df_calc['score_of_support'] = 1 / (1 + df_calc['dist_to_support'] * 100)
        df_calc['score_of_resistance'] = 1 / (1 + df_calc['dist_to_resistance'] * 100)
    else:
        df_calc[['dist_to_support', 'dist_to_resistance', 'score_of_support', 'score_of_resistance']] = 1.0

    # --- Ù…ÙŠØ²Ø§Øª Ø£Ø®Ø±Ù‰ ---
    df_calc['hour_of_day'] = df_calc.index.hour
    body_size = abs(df_calc['close'] - df_calc['open'])
    df_calc['candlestick_pattern'] = np.select(
        [body_size / (df_calc['high'] - df_calc['low']).replace(0, 1) < 0.1,  # Doji
         (df_calc['close'] > df_calc['open']) & (body_size / (df_calc['high'] - df_calc['low']).replace(0, 1) > 0.8), # Marubozu Bullish
         (df_calc['close'] < df_calc['open']) & (body_size / (df_calc['high'] - df_calc['low']).replace(0, 1) > 0.8)], # Marubozu Bearish
        [0, 1, -1], default=0.5) # Neutral

    # --- Ø¯Ù…Ø¬ Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ Ø§Ù„Ø£Ø¹Ù„Ù‰ (4 Ø³Ø§Ø¹Ø§Øª) ---
    if not df_4h.empty:
        df_4h_calc = df_4h.copy()
        delta_4h = df_4h_calc['close'].diff()
        gain_4h = delta_4h.clip(lower=0).ewm(com=14 - 1, adjust=False).mean()
        loss_4h = -delta_4h.clip(upper=0).ewm(com=14 - 1, adjust=False).mean()
        df_4h_calc['rsi_4h'] = 100 - (100 / (1 + (gain_4h / loss_4h.replace(0, 1e-9))))
        df_4h_calc['ema50_4h'] = df_4h_calc['close'].ewm(span=50, adjust=False).mean()
        
        # Ø¯Ù…Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… merge_asof
        df_calc = pd.merge_asof(df_calc.sort_index(), df_4h_calc[['rsi_4h', 'ema50_4h']].sort_index(), 
                                left_index=True, right_index=True, direction='backward')
        df_calc['price_vs_ema50_4h'] = (df_calc['close'] / df_calc['ema50_4h']) - 1
    else:
        df_calc[['rsi_4h', 'ema50_4h', 'price_vs_ema50_4h']] = np.nan

    # --- ØªØ­Ø¯ÙŠØ¯ Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚ ---
    df_calc['market_condition'] = np.select(
        [df_calc['close'] > df_calc['ema200'],
         df_calc['close'] < df_calc['ema200']],
        [1, -1], default=0) # 1: Uptrend, -1: Downtrend, 0: Sideways

    return df_calc

# ---------------------- Ù…Ø­Ø±Ùƒ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ù„ÙÙŠ ----------------------
def run_backtest(client: Client, start_date: str, end_date: str, trade_amount_usdt: float):
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ù„ÙÙŠ."""
    symbols = get_validated_symbols(client)
    if not symbols: return

    models = {}
    data_frames = {}

    for symbol in symbols:
        model_bundle = load_ml_model_bundle_from_folder(symbol)
        if not model_bundle: continue
        
        df = get_historical_data(client, symbol, TIMEFRAME, start_date, end_date)
        df_4h = get_historical_data(client, symbol, HIGHER_TIMEFRAME, start_date, end_date)
        if df.empty: continue
            
        logger.info(f"âš™ï¸ Ø¬Ø§Ø±ÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù„Ù„Ø¹Ù…Ù„Ø© {symbol}...")
        df_featured = calculate_all_features(df, df_4h)
        
        feature_names = model_bundle['feature_names']
        missing_features = set(feature_names) - set(df_featured.columns)
        if missing_features:
            logger.warning(f"âŒ Ù…ÙŠØ²Ø§Øª Ù†Ø§Ù‚ØµØ© Ù„Ù€ {symbol} Ø¨Ø¹Ø¯ Ø§Ù„Ø­Ø³Ø§Ø¨: {missing_features}. Ø³ÙŠØªÙ… ØªØ®Ø·ÙŠ Ø§Ù„Ø¹Ù…Ù„Ø©.")
            continue
        
        df_featured.dropna(inplace=True)
        if df_featured.empty:
            logger.warning(f"âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ¨Ù‚ÙŠØ© Ù„Ù€ {symbol} Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ©.")
            continue
        
        try:
            features_to_scale = df_featured[feature_names]
            df_featured.loc[:, feature_names] = model_bundle['scaler'].transform(features_to_scale)
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¬ÙŠÙ… Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù„Ù€ {symbol}: {e}. Ø³ÙŠØªÙ… ØªØ®Ø·ÙŠ Ø§Ù„Ø¹Ù…Ù„Ø©.")
            continue

        models[symbol] = model_bundle['model']
        data_frames[symbol] = df_featured
        gc.collect()

    if not data_frames:
        logger.critical("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ùˆ Ù†Ù…Ø§Ø°Ø¬ ØµØ§Ù„Ø­Ø© Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ø¹Ø¯ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù…Ù„Ø§Øª."); return

    logger.info("ğŸš€ Ø¨Ø¯Ø¡ Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„...")
    balance = trade_amount_usdt
    open_trades = []
    all_closed_trades = []
    
    # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù…Ø¤Ø´Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    common_index = None
    for df in data_frames.values():
        common_index = df.index if common_index is None else common_index.intersection(df.index)
    common_index = sorted(list(common_index))

    if not common_index:
        logger.critical("âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¤Ø´Ø± Ø²Ù…Ù†ÙŠ Ù…Ø´ØªØ±Ùƒ Ø¨ÙŠÙ† Ø§Ù„Ø¹Ù…Ù„Ø§Øª."); return

    for timestamp in common_index:
        # Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„ØµÙÙ‚Ø§Øª
        for trade in open_trades[:]:
            symbol = trade['symbol']
            current_price = data_frames[symbol].loc[timestamp]['close']
            
            if current_price <= trade['stop_loss'] or current_price >= trade['target_price']:
                exit_price = trade['stop_loss'] if current_price <= trade['stop_loss'] else trade['target_price']
                exit_price_with_slippage = exit_price * (1 - SLIPPAGE_PERCENT)
                pnl = (exit_price_with_slippage - trade['entry_price_with_slippage']) * trade['quantity']
                
                trade.update({
                    'exit_price': exit_price_with_slippage, 'exit_time': timestamp,
                    'pnl': pnl, 'status': 'Stop Loss' if current_price <= trade['stop_loss'] else 'Take Profit'
                })
                balance += pnl
                all_closed_trades.append(trade)
                open_trades.remove(trade)

        # ÙØªØ­ ØµÙÙ‚Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©
        if len(open_trades) < MAX_OPEN_TRADES:
            for symbol, model in models.items():
                if len(open_trades) >= MAX_OPEN_TRADES: break
                if any(t['symbol'] == symbol for t in open_trades): continue
                if timestamp not in data_frames[symbol].index: continue

                current_data = data_frames[symbol].loc[timestamp]
                
                features_scaled = current_data[model.feature_name_].to_frame().T
                prediction = model.predict(features_scaled)[0]
                prob_for_class_1 = model.predict_proba(features_scaled)[0][list(model.classes_).index(1)]

                if prediction == 1 and prob_for_class_1 >= MODEL_CONFIDENCE_THRESHOLD:
                    entry_price = current_data['close']
                    entry_price_with_slippage = entry_price * (1 + SLIPPAGE_PERCENT)
                    quantity = (trade_amount_usdt / entry_price_with_slippage) * (1 - COMMISSION_RATE)
                    
                    atr_value = current_data['atr']
                    stop_loss = entry_price_with_slippage - (atr_value * ATR_SL_MULTIPLIER)
                    target_price = entry_price_with_slippage + (atr_value * ATR_TP_MULTIPLIER)

                    open_trades.append({
                        'symbol': symbol, 'entry_time': timestamp, 'entry_price': entry_price,
                        'entry_price_with_slippage': entry_price_with_slippage, 'quantity': quantity,
                        'stop_loss': stop_loss, 'target_price': target_price
                    })

    # --- Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© ÙˆØ¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ---
    logger.info("âœ… Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©. Ø¬Ø§Ø±ÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©...")
    total_trades = len(all_closed_trades)
    if total_trades == 0:
        report = "*ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ù„ÙÙŠ*\n\n*ğŸ“‰ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:*\nÙ„Ù… ÙŠØªÙ… ØªÙ†ÙÙŠØ° Ø£ÙŠ ØµÙÙ‚Ø§Øª. Ù‚Ø¯ ØªÙƒÙˆÙ† Ø§Ù„ÙÙ„Ø§ØªØ± ØµØ§Ø±Ù…Ø© Ø¬Ø¯Ø§Ù‹ Ø£Ùˆ Ø£Ù† Ø¸Ø±ÙˆÙ Ø§Ù„Ø³ÙˆÙ‚ Ù„Ù… ØªØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©."
        send_telegram_report(report)
        return

    winning_trades = [t for t in all_closed_trades if t['pnl'] > 0]
    losing_trades = [t for t in all_closed_trades if t['pnl'] < 0]
    win_rate = (len(winning_trades) / total_trades) * 100 if total_trades > 0 else 0
    total_pnl = sum(t['pnl'] for t in all_closed_trades)
    
    total_profit = sum(t['pnl'] for t in winning_trades)
    total_loss = abs(sum(t['pnl'] for t in losing_trades))
    profit_factor = total_profit / total_loss if total_loss > 0 else float('inf')

    report = f"""
*ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ù„ÙÙŠ (Ù…Ø­Ø§ÙƒØ§Ø© Ù†Ù‡Ø§Ø¦ÙŠØ©)*
--------------------------------------
*Ø§Ù„ÙØªØ±Ø©:* Ù…Ù† `{start_date}` Ø¥Ù„Ù‰ `{end_date}`
*Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Øª:* `crypto_list.txt`
*Ø§Ù„Ù…Ø¨Ù„Øº Ù„ÙƒÙ„ ØµÙÙ‚Ø©:* `${trade_amount_usdt:,.2f}`
--------------------------------------
*ğŸ“ˆ Ù…Ù„Ø®Øµ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ:*
*Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±Ø¨Ø­/Ø§Ù„Ø®Ø³Ø§Ø±Ø© (PnL):* `${total_pnl:,.2f}`
*Ø¹Ø§Ù…Ù„ Ø§Ù„Ø±Ø¨Ø­ (Profit Factor):* `{profit_factor:.2f}`

*âš™ï¸ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØµÙÙ‚Ø§Øª:*
*Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙ‚Ø§Øª:* `{total_trades}`
*Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ø±Ø§Ø¨Ø­Ø©:* `{len(winning_trades)}`
*Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ø®Ø§Ø³Ø±Ø©:* `{len(losing_trades)}`
*Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­ (Win Rate):* `{win_rate:.2f}%`
--------------------------------------
*Ù…Ù„Ø§Ø­Ø¸Ø©: Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù„Ø§ ØªØ¶Ù…Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ.*
"""
    send_telegram_report(report)

def main():
    """Main function to run the script."""
    logger.info("ğŸš€ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø®Ù„ÙÙŠ...")
    try:
        client = Client(API_KEY, API_SECRET)
        client.ping()
        logger.info("âœ… ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª Binance Ø¨Ù†Ø¬Ø§Ø­.")
    except Exception as e:
        logger.critical(f"âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Binance. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…ÙØ§ØªÙŠØ­ API. Ø§Ù„Ø®Ø·Ø£: {e}")
        exit(1)

    parser = argparse.ArgumentParser(description="Run a crypto backtesting strategy.")
    end_date_dt = datetime.now()
    start_date_dt = end_date_dt - timedelta(days=30)
    start_date_default = start_date_dt.strftime("%Y-%m-%d")
    end_date_default = end_date_dt.strftime("%Y-%m-%d")

    parser.add_argument('--start-date', type=str, default=start_date_default, help=f'Start date (YYYY-MM-DD). Default: {start_date_default}')
    parser.add_argument('--end-date', type=str, default=end_date_default, help=f'End date (YYYY-MM-DD). Default: {end_date_default}')
    parser.add_argument('--amount', type=float, default=100.0, help='Amount per trade in USDT. Default: 100.0')

    args = parser.parse_args()

    try:
        datetime.strptime(args.start_date, "%Y-%m-%d")
        datetime.strptime(args.end_date, "%Y-%m-%d")
        
        logger.info(f"ğŸ—“ï¸ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù…Ù† {args.start_date} Ø¥Ù„Ù‰ {args.end_date} Ø¨Ù…Ø¨Ù„Øº ${args.amount} Ù„ÙƒÙ„ ØµÙÙ‚Ø©.")
        run_backtest(client, args.start_date, args.end_date, args.amount)

    except ValueError:
        logger.error("âŒ ØµÙŠØºØ© Ø§Ù„ØªØ§Ø±ÙŠØ® ØºÙŠØ± ØµØ­ÙŠØ­Ø©. ÙŠØ±Ø¬Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… YYYY-MM-DD.")
    except Exception as e:
        logger.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}", exc_info=True)

    logger.info("ğŸ‘‹ Ø§Ù†ØªÙ‡Ù‰ Ø¹Ù…Ù„ Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª. ÙˆØ¯Ø§Ø¹Ø§Ù‹!")

# ---------------------- Ù†Ù‚Ø·Ø© Ø§Ù†Ø·Ù„Ø§Ù‚ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ ----------------------
if __name__ == "__main__":
    main()
