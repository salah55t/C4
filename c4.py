
import time
import os
import json
import logging
import requests
import numpy as np
import pandas as pd
import psycopg2
from psycopg2 import sql, OperationalError, InterfaceError # Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø¢Ù…Ù†Ø© ÙˆØ£Ø®Ø·Ø§Ø¡ Ù…Ø­Ø¯Ø¯Ø©
from psycopg2.extras import RealDictCursor # Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙƒÙ‚ÙˆØ§Ù…ÙŠØ³
from binance.client import Client
from binance import ThreadedWebsocketManager
from binance.exceptions import BinanceAPIException, BinanceRequestException # Ø£Ø®Ø·Ø§Ø¡ Binance Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©
from flask import Flask, request, Response
from threading import Thread
from datetime import datetime, timedelta
from decouple import config
from typing import List, Dict, Optional, Tuple, Any, Union # Ù„Ø¥Ø¶Ø§ÙØ© Type Hinting

# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ----------------------
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', # Ø¥Ø¶Ø§ÙØ© Ø§Ø³Ù… Ø§Ù„Ù…Ø³Ø¬Ù„
    handlers=[
        logging.FileHandler('crypto_bot_elliott_fib.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³Ù… Ù…Ø­Ø¯Ø¯ Ù„Ù„Ù…Ø³Ø¬Ù„ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø¬Ø°Ø±
logger = logging.getLogger('CryptoBot')

# ---------------------- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ© ----------------------
try:
    API_KEY: str = config('BINANCE_API_KEY')
    API_SECRET: str = config('BINANCE_API_SECRET')
    TELEGRAM_TOKEN: str = config('TELEGRAM_BOT_TOKEN')
    CHAT_ID: str = config('TELEGRAM_CHAT_ID')
    DB_URL: str = config('DATABASE_URL')
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© None Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø§Ù„Ù…ØªØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§
    WEBHOOK_URL: Optional[str] = config('WEBHOOK_URL', default=None)
except Exception as e:
     logger.critical(f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©: {e}")
     exit(1) # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø±Ù…Ø² Ø®Ø±ÙˆØ¬ ØºÙŠØ± ØµÙØ±ÙŠ Ù„Ù„Ø¥Ø´Ø§Ø±Ø© Ø¥Ù„Ù‰ Ø®Ø·Ø£

logger.info(f"Ù…ÙØªØ§Ø­ Binance API: {'Ù…ÙˆØ¬ÙˆØ¯' if API_KEY else 'ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯'}")
logger.info(f"ØªÙˆÙƒÙ† ØªÙ„ÙŠØ¬Ø±Ø§Ù…: {TELEGRAM_TOKEN[:10]}...{'*' * (len(TELEGRAM_TOKEN)-10)}")
logger.info(f"Ù…Ø¹Ø±Ù Ø¯Ø±Ø¯Ø´Ø© ØªÙ„ÙŠØ¬Ø±Ø§Ù…: {CHAT_ID}")
logger.info(f"Ø±Ø§Ø¨Ø· Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {'Ù…ÙˆØ¬ÙˆØ¯' if DB_URL else 'ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯'}")
logger.info(f"Ø¹Ù†ÙˆØ§Ù† Webhook: {WEBHOOK_URL if WEBHOOK_URL else 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'}")

# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø«ÙˆØ§Ø¨Øª ÙˆØ§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© ----------------------
TRADE_VALUE: float = 10.0         # Ù‚ÙŠÙ…Ø© Ø§Ù„ØµÙÙ‚Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¨Ø§Ù„Ø¯ÙˆÙ„Ø§Ø±
MAX_OPEN_TRADES: int = 4          # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø© ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª
SIGNAL_GENERATION_TIMEFRAME: str = '30m' # Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©
SIGNAL_GENERATION_LOOKBACK_DAYS: int = 5 # Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙŠØ§Ù… Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©
SIGNAL_TRACKING_TIMEFRAME: str = '30m' # Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ Ù„ØªØªØ¨Ø¹ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© ÙˆØªØ­Ø¯ÙŠØ« ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©
SIGNAL_TRACKING_LOOKBACK_DAYS: int = 5   # Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙŠØ§Ù… Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„ØªØªØ¨Ø¹ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©

# =============================================================================
# --- ØªØ¹Ø¯ÙŠÙ„ Ù‚ÙŠÙ… Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª (Ù…Ø«Ø§Ù„) ---
# ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¹Ø¯ÙŠÙ„ Ù‡Ø°Ù‡ Ø§Ù„Ù‚ÙŠÙ… Ù„ØªÙ†Ø§Ø³Ø¨ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØªÙƒ Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„
# =============================================================================
RSI_PERIOD: int = 14          # ÙØªØ±Ø© RSI (Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©: 14)
RSI_OVERSOLD: int = 35        # Ø­Ø¯ Ø§Ù„ØªØ´Ø¨Ø¹ Ø§Ù„Ø¨ÙŠØ¹ÙŠ (Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©: 30) - Ø±ÙØ¹ Ø§Ù„Ø­Ø¯ Ù‚Ù„ÙŠÙ„Ø§Ù‹
RSI_OVERBOUGHT: int = 65      # Ø­Ø¯ Ø§Ù„ØªØ´Ø¨Ø¹ Ø§Ù„Ø´Ø±Ø§Ø¦ÙŠ (Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©: 70) - Ø®ÙØ¶ Ø§Ù„Ø­Ø¯ Ù‚Ù„ÙŠÙ„Ø§Ù‹
EMA_PERIOD: int = 26          # ÙØªØ±Ø© EMA Ù„Ù„ØªØ±Ù†Ø¯ (Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©: 21) - Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ÙØªØ±Ø© Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©
SWING_ORDER: int = 5          # ØªØ±ØªÙŠØ¨ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù‚Ù…Ù… ÙˆØ§Ù„Ù‚ÙŠØ¹Ø§Ù†
FIB_LEVELS_TO_CHECK: List[float] = [0.382, 0.5, 0.618]
FIB_TOLERANCE: float = 0.007
LOOKBACK_FOR_SWINGS: int = 100
ENTRY_ATR_PERIOD: int = 14     # ÙØªØ±Ø© ATR Ù„Ù„Ø¯Ø®ÙˆÙ„
ENTRY_ATR_MULTIPLIER: float = 1.5 # Ù…Ø¶Ø§Ø¹Ù ATR Ù„Ù„Ù‡Ø¯Ù/Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ø£ÙˆÙ„ÙŠ (Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©: 1.2) - Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù…Ø¶Ø§Ø¹Ù
BOLLINGER_WINDOW: int = 20     # ÙØªØ±Ø© Bollinger Bands
BOLLINGER_STD_DEV: int = 2       # Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ Ù„Ù€ Bollinger Bands
MACD_FAST: int = 12            # ÙØªØ±Ø© MACD Ø§Ù„Ø³Ø±ÙŠØ¹Ø©
MACD_SLOW: int = 26            # ÙØªØ±Ø© MACD Ø§Ù„Ø¨Ø·ÙŠØ¦Ø©
MACD_SIGNAL: int = 9             # ÙØªØ±Ø© Ø®Ø· Ø¥Ø´Ø§Ø±Ø© MACD
ADX_PERIOD: int = 14            # ÙØªØ±Ø© ADX
SUPERTREND_PERIOD: int = 10     # ÙØªØ±Ø© SuperTrend
SUPERTREND_MULTIPLIER: float = 3.0 # Ù…Ø¶Ø§Ø¹Ù SuperTrend

# ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ù…ØªØ­Ø±Ùƒ
TRAILING_STOP_ACTIVATION_PROFIT_PCT: float = 0.02 Ø¯ # Ù†Ø³Ø¨Ø© Ø§Ù„Ø±Ø¨Ø­ Ù„ØªÙØ¹ÙŠÙ„ Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ (1.5%)
TRAILING_STOP_ATR_MULTIPLIER: float = 2.5        # Ù…Ø¶Ø§Ø¹Ù ATR Ù„Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ (Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©: 2.5) - ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¶Ø§Ø¹Ù Ù„ÙŠÙƒÙˆÙ† Ø£Ø¶ÙŠÙ‚
TRAILING_STOP_MOVE_INCREMENT_PCT: float = 0.002  # Ù†Ø³Ø¨Ø© Ø§Ù„Ø²ÙŠØ§Ø¯Ø© ÙÙŠ Ø§Ù„Ø³Ø¹Ø± Ù„ØªØ­Ø±ÙŠÙƒ Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ (0.2%)

# Ø´Ø±ÙˆØ· Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ø¥Ø´Ø§Ø±Ø©
MIN_PROFIT_MARGIN_PCT: float = 1.5 # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù Ø§Ù„Ù…Ø¦ÙˆÙŠØ©
MIN_VOLUME_15M_USDT: float = 100000.0 # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ù„Ø³ÙŠÙˆÙ„Ø© ÙÙŠ Ø¢Ø®Ø± 15 Ø¯Ù‚ÙŠÙ‚Ø© Ø¨Ø§Ù„Ø¯ÙˆÙ„Ø§Ø±
# =============================================================================
# --- Ù†Ù‡Ø§ÙŠØ© ØªØ¹Ø¯ÙŠÙ„ Ù‚ÙŠÙ… Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª ---
# =============================================================================

# Ù…ØªØºÙŠØ±Ø§Øª Ø¹Ø§Ù„Ù…ÙŠØ© (Ø³ÙŠØªÙ… ØªÙ‡ÙŠØ¦ØªÙ‡Ø§ Ù„Ø§Ø­Ù‚Ù‹Ø§)
conn: Optional[psycopg2.extensions.connection] = None
cur: Optional[psycopg2.extensions.cursor] = None
client: Optional[Client] = None
ticker_data: Dict[str, float] = {} # Ù‚Ø§Ù…ÙˆØ³ Ù„ØªØ®Ø²ÙŠÙ† Ø£Ø­Ø¯Ø« Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ Ù„Ù„Ø±Ù…ÙˆØ²

# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ø¹Ù…ÙŠÙ„ Binance ----------------------
try:
    logger.info("â„¹ï¸ [Binance] ØªÙ‡ÙŠØ¦Ø© Ø¹Ù…ÙŠÙ„ Binance...")
    client = Client(API_KEY, API_SECRET)
    client.ping() # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„ ÙˆØµØ­Ø© Ø§Ù„Ù…ÙØ§ØªÙŠØ­
    server_time = client.get_server_time()
    logger.info(f"âœ… [Binance] ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø¹Ù…ÙŠÙ„ Binance. ÙˆÙ‚Øª Ø§Ù„Ø®Ø§Ø¯Ù…: {datetime.fromtimestamp(server_time['serverTime']/1000)}")
except BinanceRequestException as req_err:
     logger.critical(f"âŒ [Binance] Ø®Ø·Ø£ ÙÙŠ Ø·Ù„Ø¨ Binance (Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù…Ø´ÙƒÙ„Ø© Ø´Ø¨ÙƒØ© Ø£Ùˆ Ø·Ù„Ø¨): {req_err}")
     exit(1)
except BinanceAPIException as api_err:
     logger.critical(f"âŒ [Binance] Ø®Ø·Ø£ Ù…Ù† Binance API (Ù‚Ø¯ ØªÙƒÙˆÙ† Ø§Ù„Ù…ÙØ§ØªÙŠØ­ ØºÙŠØ± ØµØ§Ù„Ø­Ø© Ø£Ùˆ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…): {api_err}")
     exit(1)
except Exception as e:
    logger.critical(f"âŒ [Binance] ÙØ´Ù„ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ø¹Ù…ÙŠÙ„ Binance: {e}")
    exit(1)

# ---------------------- Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ© ----------------------
def get_fear_greed_index() -> str:
    """ÙŠØ¬Ù„Ø¨ Ù…Ø¤Ø´Ø± Ø§Ù„Ø®ÙˆÙ ÙˆØ§Ù„Ø·Ù…Ø¹ Ù…Ù† alternative.me ÙˆÙŠØªØ±Ø¬Ù… Ø§Ù„ØªØµÙ†ÙŠÙ Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©."""
    classification_translation_ar = {
        "Extreme Fear": "Ø®ÙˆÙ Ø´Ø¯ÙŠØ¯", "Fear": "Ø®ÙˆÙ", "Neutral": "Ù…Ø­Ø§ÙŠØ¯",
        "Greed": "Ø¬Ø´Ø¹", "Extreme Greed": "Ø¬Ø´Ø¹ Ø´Ø¯ÙŠØ¯",
    }
    url = "https://api.alternative.me/fng/"
    logger.debug(f"â„¹ï¸ [Indicators] Ø¬Ù„Ø¨ Ù…Ø¤Ø´Ø± Ø§Ù„Ø®ÙˆÙ ÙˆØ§Ù„Ø·Ù…Ø¹ Ù…Ù† {url}...")
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        data = response.json()
        value = int(data["data"][0]["value"])
        classification_en = data["data"][0]["value_classification"]
        classification_ar = classification_translation_ar.get(classification_en, classification_en)
        logger.debug(f"âœ… [Indicators] Ù…Ø¤Ø´Ø± Ø§Ù„Ø®ÙˆÙ ÙˆØ§Ù„Ø·Ù…Ø¹: {value} ({classification_ar})")
        return f"{value} ({classification_ar})"
    except requests.exceptions.RequestException as e:
         logger.error(f"âŒ [Indicators] Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø´Ø¨ÙƒØ© Ø¹Ù†Ø¯ Ø¬Ù„Ø¨ Ù…Ø¤Ø´Ø± Ø§Ù„Ø®ÙˆÙ ÙˆØ§Ù„Ø·Ù…Ø¹: {e}")
         return "N/A (Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø´Ø¨ÙƒØ©)"
    except (KeyError, IndexError, ValueError, json.JSONDecodeError) as e:
        logger.error(f"âŒ [Indicators] Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø³ÙŠÙ‚ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¤Ø´Ø± Ø§Ù„Ø®ÙˆÙ ÙˆØ§Ù„Ø·Ù…Ø¹: {e}")
        return "N/A (Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª)"
    except Exception as e:
        logger.error(f"âŒ [Indicators] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø¬Ù„Ø¨ Ù…Ø¤Ø´Ø± Ø§Ù„Ø®ÙˆÙ ÙˆØ§Ù„Ø·Ù…Ø¹: {e}", exc_info=True)
        return "N/A (Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ)"

def fetch_historical_data(symbol: str, interval: str = SIGNAL_GENERATION_TIMEFRAME, days: int = SIGNAL_GENERATION_LOOKBACK_DAYS) -> Optional[pd.DataFrame]:
    """Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„Ù„Ø´Ù…ÙˆØ¹ Ù…Ù† Binance."""
    if not client:
        logger.error("âŒ [Data] Ø¹Ù…ÙŠÙ„ Binance ØºÙŠØ± Ù…Ù‡ÙŠØ£ Ù„Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
        return None
    try:
        start_dt = datetime.utcnow() - timedelta(days=days + 1) # Ø¥Ø¶Ø§ÙØ© ÙŠÙˆÙ… Ø¥Ø¶Ø§ÙÙŠ ÙƒØ§Ø­ØªÙŠØ§Ø·
        start_str = start_dt.strftime("%Y-%m-%d %H:%M:%S")
        logger.debug(f"â„¹ï¸ [Data] Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª {interval} Ù„Ù„Ø²ÙˆØ¬ {symbol} Ù…Ù†Ø° {start_str} (Ø­Ø¯ 1000 Ø´Ù…Ø¹Ø©)...")

        klines = client.get_historical_klines(symbol, interval, start_str, limit=1000)

        if not klines:
            logger.warning(f"âš ï¸ [Data] Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ§Ø±ÙŠØ®ÙŠØ© ({interval}) Ù„Ù„Ø²ÙˆØ¬ {symbol} Ù„Ù„ÙØªØ±Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©.")
            return None

        df = pd.DataFrame(klines, columns=[
            'timestamp', 'open', 'high', 'low', 'close', 'volume',
            'close_time', 'quote_volume', 'trades', 'taker_buy_base', 'taker_buy_quote', 'ignore'
        ])

        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        numeric_cols = ['open', 'high', 'low', 'close', 'volume']
        for col in numeric_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce') # coerce ØªØ­ÙˆÙ„ Ø§Ù„Ù‚ÙŠÙ… ØºÙŠØ± Ø§Ù„ØµØ§Ù„Ø­Ø© Ø¥Ù„Ù‰ NaN

        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('timestamp', inplace=True)

        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ÙÙ‚Ø·
        df = df[numeric_cols]

        initial_len = len(df)
        df.dropna(subset=numeric_cols, inplace=True) # Ø­Ø°Ù Ø§Ù„ØµÙÙˆÙ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ NaN ÙÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©

        if len(df) < initial_len:
            logger.debug(f"â„¹ï¸ [Data] {symbol}: ØªÙ… Ø­Ø°Ù {initial_len - len(df)} ØµÙ Ø¨Ø³Ø¨Ø¨ NaN ÙÙŠ Ø¨ÙŠØ§Ù†Ø§Øª OHLCV.")

        if df.empty:
            logger.warning(f"âš ï¸ [Data] DataFrame Ù„Ù„Ø²ÙˆØ¬ {symbol} ÙØ§Ø±Øº Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© NaN Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©.")
            return None

        logger.debug(f"âœ… [Data] ØªÙ… Ø¬Ù„Ø¨ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© {len(df)} Ø´Ù…Ø¹Ø© ØªØ§Ø±ÙŠØ®ÙŠØ© ({interval}) Ù„Ù„Ø²ÙˆØ¬ {symbol}.")
        return df

    except BinanceAPIException as api_err:
         logger.error(f"âŒ [Data] Ø®Ø·Ø£ API Ù…Ù† Binance Ø¹Ù†Ø¯ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª {symbol}: {api_err}")
         return None
    except BinanceRequestException as req_err:
         logger.error(f"âŒ [Data] Ø®Ø·Ø£ Ø·Ù„Ø¨ Ø£Ùˆ Ø´Ø¨ÙƒØ© Ø¹Ù†Ø¯ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª {symbol}: {req_err}")
         return None
    except Exception as e:
        logger.error(f"âŒ [Data] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„Ù„Ø²ÙˆØ¬ {symbol}: {e}", exc_info=True)
        return None


def calculate_ema(series: pd.Series, span: int) -> pd.Series:
    """Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ØªØ­Ø±Ùƒ Ø§Ù„Ø£Ø³ÙŠ (EMA)."""
    if series is None or series.isnull().all() or len(series) < span:
        # Ø¥Ø±Ø¬Ø§Ø¹ Ø³Ù„Ø³Ù„Ø© ÙØ§Ø±ØºØ© Ø¨Ù†ÙØ³ Ø§Ù„ÙÙ‡Ø±Ø³ Ø¥Ø°Ø§ Ø£Ù…ÙƒÙ† Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆØ§ÙÙ‚
        return pd.Series(index=series.index if series is not None else None, dtype=float)
    return series.ewm(span=span, adjust=False).mean()


def get_btc_trend_4h() -> str:
    """ÙŠØ­Ø³Ø¨ ØªØ±Ù†Ø¯ Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ† Ø¹Ù„Ù‰ ÙØ±ÙŠÙ… 4 Ø³Ø§Ø¹Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… EMA20 ÙˆEMA50."""
    # Ù…Ù„Ø§Ø­Ø¸Ø©: Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© Ù„Ø§ ØªØ²Ø§Ù„ ØªØ³ØªØ®Ø¯Ù… EMA20 Ùˆ EMA50 Ø¯Ø§Ø®Ù„ÙŠÙ‹Ø§ØŒ Ù‚Ø¯ ØªØ±ØºØ¨ ÙÙŠ ØªÙˆØ­ÙŠØ¯Ù‡Ø§ Ù…Ø¹ EMA_PERIOD Ø§Ù„Ø¹Ø§Ù… Ø¥Ø°Ø§ Ø£Ø±Ø¯Øª
    logger.debug("â„¹ï¸ [Indicators] Ø­Ø³Ø§Ø¨ ØªØ±Ù†Ø¯ Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ† 4 Ø³Ø§Ø¹Ø§Øª...")
    try:
        df = fetch_historical_data("BTCUSDT", interval=Client.KLINE_INTERVAL_4HOUR, days=10) # Ø·Ù„Ø¨ Ø£ÙŠØ§Ù… Ø£ÙƒØ«Ø± Ù‚Ù„ÙŠÙ„Ø§Ù‹
        if df is None or df.empty or len(df) < 50 + 1: # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù€ EMA50
            logger.warning("âš ï¸ [Indicators] Ø¨ÙŠØ§Ù†Ø§Øª BTC/USDT 4H ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ±Ù†Ø¯.")
            return "N/A (Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ©)"

        df['close'] = pd.to_numeric(df['close'], errors='coerce')
        df.dropna(subset=['close'], inplace=True)
        if len(df) < 50:
             logger.warning("âš ï¸ [Indicators] Ø¨ÙŠØ§Ù†Ø§Øª BTC/USDT 4H ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© NaN.")
             return "N/A (Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ©)"

        ema20 = calculate_ema(df['close'], 20).iloc[-1] # Ù„Ø§ ÙŠØ²Ø§Ù„ ÙŠØ³ØªØ®Ø¯Ù… 20 Ù‡Ù†Ø§
        ema50 = calculate_ema(df['close'], 50).iloc[-1] # Ù„Ø§ ÙŠØ²Ø§Ù„ ÙŠØ³ØªØ®Ø¯Ù… 50 Ù‡Ù†Ø§
        current_close = df['close'].iloc[-1]

        if pd.isna(ema20) or pd.isna(ema50) or pd.isna(current_close):
            logger.warning("âš ï¸ [Indicators] Ù‚ÙŠÙ… EMA Ø£Ùˆ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ Ù„Ù€ BTC Ù‡ÙŠ NaN.")
            return "N/A (Ø®Ø·Ø£ Ø­Ø³Ø§Ø¨ÙŠ)"

        diff_ema20_pct = abs(current_close - ema20) / current_close if current_close > 0 else 0

        if current_close > ema20 > ema50:
            trend = "ØµØ¹ÙˆØ¯ ğŸ“ˆ"
        elif current_close < ema20 < ema50:
            trend = "Ù‡Ø¨ÙˆØ· ğŸ“‰"
        elif diff_ema20_pct < 0.005: # Ø£Ù‚Ù„ Ù…Ù† 0.5% ÙØ±Ù‚ØŒ ÙŠØ¹ØªØ¨Ø± Ø§Ø³ØªÙ‚Ø±Ø§Ø±
            trend = "Ø§Ø³ØªÙ‚Ø±Ø§Ø± ğŸ”„"
        else: # ØªÙ‚Ø§Ø·Ø¹ Ø£Ùˆ ØªØ¨Ø§Ø¹Ø¯ ØºÙŠØ± ÙˆØ§Ø¶Ø­
            trend = "ØªØ°Ø¨Ø°Ø¨ ğŸ”€"

        logger.debug(f"âœ… [Indicators] ØªØ±Ù†Ø¯ Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ† 4H: {trend}")
        return trend
    except Exception as e:
        logger.error(f"âŒ [Indicators] Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ ØªØ±Ù†Ø¯ Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ† Ø¹Ù„Ù‰ Ø£Ø±Ø¨Ø¹ Ø³Ø§Ø¹Ø§Øª: {e}", exc_info=True)
        return "N/A (Ø®Ø·Ø£)"

# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ----------------------
def init_db(retries: int = 5, delay: int = 5) -> None:
    """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø©."""
    global conn, cur
    logger.info("[DB] Ø¨Ø¯Ø¡ ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    for attempt in range(retries):
        try:
            logger.info(f"[DB] Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}/{retries})...")
            conn = psycopg2.connect(DB_URL, connect_timeout=10, cursor_factory=RealDictCursor)
            conn.autocommit = False # Ø§Ù„ØªØ­ÙƒÙ… Ø§Ù„ÙŠØ¯ÙˆÙŠ Ø¨Ø§Ù„Ù€ commit/rollback
            cur = conn.cursor()
            logger.info("âœ… [DB] ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­.")

            # --- Ø¥Ù†Ø´Ø§Ø¡ Ø£Ùˆ ØªØ­Ø¯ÙŠØ« Ø¬Ø¯ÙˆÙ„ signals ---
            logger.info("[DB] Ø§Ù„ØªØ­Ù‚Ù‚/Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ 'signals'...")
            cur.execute("""
                CREATE TABLE IF NOT EXISTS signals (
                    id SERIAL PRIMARY KEY,
                    symbol TEXT NOT NULL,
                    entry_price DOUBLE PRECISION NOT NULL,
                    initial_target DOUBLE PRECISION NOT NULL,
                    initial_stop_loss DOUBLE PRECISION NOT NULL,
                    current_target DOUBLE PRECISION NOT NULL,
                    current_stop_loss DOUBLE PRECISION NOT NULL,
                    r2_score DOUBLE PRECISION, -- ÙŠÙ…Ø«Ù„ Ø§Ù„Ø¢Ù† Ø¯Ø±Ø¬Ø© Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ù…ÙˆØ²ÙˆÙ†Ø©
                    volume_15m DOUBLE PRECISION,
                    achieved_target BOOLEAN DEFAULT FALSE,
                    hit_stop_loss BOOLEAN DEFAULT FALSE,
                    closing_price DOUBLE PRECISION,
                    closed_at TIMESTAMP,
                    sent_at TIMESTAMP DEFAULT NOW(),
                    profit_percentage DOUBLE PRECISION,
                    profitable_stop_loss BOOLEAN DEFAULT FALSE,
                    is_trailing_active BOOLEAN DEFAULT FALSE,
                    strategy_name TEXT,
                    signal_details JSONB,
                    last_trailing_update_price DOUBLE PRECISION
                );""")
            conn.commit()
            logger.info("âœ… [DB] Ø¬Ø¯ÙˆÙ„ 'signals' Ù…ÙˆØ¬ÙˆØ¯ Ø£Ùˆ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡.")

            # --- Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆØ¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†Ø§Ù‚ØµØ© (Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±) ---
            required_columns = {
                "symbol", "entry_price", "initial_target", "initial_stop_loss",
                "current_target", "current_stop_loss", "r2_score", "volume_15m",
                "achieved_target", "hit_stop_loss", "closing_price", "closed_at",
                "sent_at", "profit_percentage", "profitable_stop_loss",
                "is_trailing_active", "strategy_name", "signal_details",
                "last_trailing_update_price"
            }
            cur.execute("SELECT column_name FROM information_schema.columns WHERE table_name = 'signals' AND table_schema = 'public';")
            existing_columns = {row['column_name'] for row in cur.fetchall()}
            missing_columns = required_columns - existing_columns

            if missing_columns:
                logger.warning(f"âš ï¸ [DB] Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ Ø¬Ø¯ÙˆÙ„ 'signals': {missing_columns}. Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¶Ø§ÙØªÙ‡Ø§...")
                # (Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø£ØµÙ„ÙŠ Ù„Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙƒØ§Ù† Ø¬ÙŠØ¯Ù‹Ø§ØŒ ÙŠÙ…ÙƒÙ† Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ù‡ Ø£Ùˆ ØªØ­Ø³ÙŠÙ†Ù‡ Ù‡Ù†Ø§ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±)
                # ... (ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© ÙƒÙˆØ¯ ALTER TABLE Ù‡Ù†Ø§ Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØªÙˆÙ‚Ø¹ ØªØºÙŠÙŠØ±Ø§Øª Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©) ...
                logger.warning("âš ï¸ [DB] Ù„Ù… ÙŠØªÙ… ØªÙ†ÙÙŠØ° Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…Ø­Ø³Ù†. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ ÙŠØ¯ÙˆÙŠÙ‹Ø§ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±.")
            else:
                logger.info("âœ… [DB] Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø¬Ø¯ÙˆÙ„ 'signals'.")

            # --- Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ market_dominance (Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§) ---
            logger.info("[DB] Ø§Ù„ØªØ­Ù‚Ù‚/Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ 'market_dominance'...")
            cur.execute("""
                CREATE TABLE IF NOT EXISTS market_dominance (
                    id SERIAL PRIMARY KEY,
                    recorded_at TIMESTAMP DEFAULT NOW(),
                    btc_dominance DOUBLE PRECISION,
                    eth_dominance DOUBLE PRECISION
                );
            """)
            conn.commit()
            logger.info("âœ… [DB] Ø¬Ø¯ÙˆÙ„ 'market_dominance' Ù…ÙˆØ¬ÙˆØ¯ Ø£Ùˆ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡.")

            logger.info("âœ… [DB] ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªÙ…Øª Ø¨Ù†Ø¬Ø§Ø­.")
            return # Ù†Ø¬Ø­ Ø§Ù„Ø§ØªØµØ§Ù„ ÙˆØ§Ù„ØªÙ‡ÙŠØ¦Ø©

        except OperationalError as op_err:
            logger.error(f"âŒ [DB] Ø®Ø·Ø£ ØªØ´ØºÙŠÙ„ÙŠ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ (Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}): {op_err}")
            if conn: conn.rollback()
            if attempt == retries - 1:
                 logger.critical("âŒ [DB] ÙØ´Ù„Øª Ø¬Ù…ÙŠØ¹ Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
                 raise op_err # Ø¥Ø¹Ø§Ø¯Ø© Ø±ÙØ¹ Ø§Ù„Ø®Ø·Ø£ Ø¨Ø¹Ø¯ ÙØ´Ù„ ÙƒÙ„ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª
            time.sleep(delay)
        except Exception as e:
            logger.critical(f"âŒ [DB] ÙØ´Ù„ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}): {e}", exc_info=True)
            if conn: conn.rollback()
            if attempt == retries - 1:
                 logger.critical("âŒ [DB] ÙØ´Ù„Øª Ø¬Ù…ÙŠØ¹ Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
                 raise e
            time.sleep(delay)

    # Ø¥Ø°Ø§ ÙˆØµÙ„ Ø§Ù„ÙƒÙˆØ¯ Ø¥Ù„Ù‰ Ù‡Ù†Ø§ØŒ ÙÙ‚Ø¯ ÙØ´Ù„Øª ÙƒÙ„ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª
    logger.critical("âŒ [DB] ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯ Ø¹Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø§Øª.")
    exit(1)


def check_db_connection() -> bool:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø§Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙ‡ÙŠØ¦Ø© Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±."""
    global conn, cur
    try:
        if conn is None or conn.closed != 0:
            logger.warning("âš ï¸ [DB] Ø§Ù„Ø§ØªØµØ§Ù„ Ù…ØºÙ„Ù‚ Ø£Ùˆ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙ‡ÙŠØ¦Ø©...")
            init_db() # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„ ÙˆØ§Ù„ØªÙ‡ÙŠØ¦Ø©
            return True # Ù†ÙØªØ±Ø¶ Ù†Ø¬Ø§Ø­ Ø§Ù„ØªÙ‡ÙŠØ¦Ø© (init_db Ø³ØªØ±ÙØ¹ Ø®Ø·Ø£ Ø¥Ø°Ø§ ÙØ´Ù„Øª)
        else:
             # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ø§ØªØµØ§Ù„ Ù„Ø§ ÙŠØ²Ø§Ù„ ÙŠØ¹Ù…Ù„ Ø¨Ø¥Ø±Ø³Ø§Ù„ Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¨Ø³ÙŠØ·
             with conn.cursor() as check_cur: # Ø§Ø³ØªØ®Ø¯Ø§Ù… cursor Ù…Ø¤Ù‚Øª
                  check_cur.execute("SELECT 1;")
                  check_cur.fetchone()
             # logger.debug("[DB] Ø§Ù„Ø§ØªØµØ§Ù„ Ù†Ø´Ø·.") # Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ Ù„Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù…ØªÙƒØ±Ø±
             return True
    except (OperationalError, InterfaceError) as e:
        logger.error(f"âŒ [DB] ÙÙ‚Ø¯Ø§Ù† Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ({e}). Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙ‡ÙŠØ¦Ø©...")
        try:
             init_db()
             return True
        except Exception as recon_err:
            logger.error(f"âŒ [DB] ÙØ´Ù„Øª Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø¹Ø¯ ÙÙ‚Ø¯Ø§Ù† Ø§Ù„Ø§ØªØµØ§Ù„: {recon_err}")
            return False
    except Exception as e:
        logger.error(f"âŒ [DB] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„: {e}", exc_info=True)
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„ ÙƒØ¥Ø¬Ø±Ø§Ø¡ ÙˆÙ‚Ø§Ø¦ÙŠ
        try:
            init_db()
            return True
        except Exception as recon_err:
             logger.error(f"âŒ [DB] ÙØ´Ù„Øª Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø¹Ø¯ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {recon_err}")
             return False


def convert_np_values(obj: Any) -> Any:
    """ØªØ­ÙˆÙŠÙ„ Ø£Ù†ÙˆØ§Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª NumPy Ø¥Ù„Ù‰ Ø£Ù†ÙˆØ§Ø¹ Python Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù„Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ JSON Ùˆ DB."""
    if isinstance(obj, dict):
        return {k: convert_np_values(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [convert_np_values(item) for item in obj]
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, (np.integer, np.int_)): # np.int_ Ù‚Ø¯ÙŠÙ… Ù„ÙƒÙ† Ù„Ø§ ÙŠØ²Ø§Ù„ ÙŠØ¹Ù…Ù„
        return int(obj)
    elif isinstance(obj, (np.floating, np.float64)): # ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… np.float64 Ù…Ø¨Ø§Ø´Ø±Ø©
        return float(obj)
    elif isinstance(obj, (np.bool_)):
        return bool(obj)
    elif pd.isna(obj): # Ù…Ø¹Ø§Ù„Ø¬Ø© NaT Ù…Ù† Pandas Ø£ÙŠØ¶Ù‹Ø§
        return None
    else:
        return obj

# ---------------------- Ù‚Ø±Ø§Ø¡Ø© Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù†Ù‡Ø§ ----------------------
def get_crypto_symbols(filename: str = 'crypto_list.txt') -> List[str]:
    """
    Ù‚Ø±Ø§Ø¡Ø© Ù‚Ø§Ø¦Ù…Ø© Ø±Ù…ÙˆØ² Ø§Ù„Ø¹Ù…Ù„Ø§Øª Ù…Ù† Ù…Ù„Ù Ù†ØµÙŠØŒ Ø«Ù… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØªÙ‡Ø§
    ÙˆÙƒÙˆÙ†Ù‡Ø§ Ø£Ø²ÙˆØ§Ø¬ USDT Ù…ØªØ§Ø­Ø© Ù„Ù„ØªØ¯Ø§ÙˆÙ„ Ø¹Ù„Ù‰ Binance Spot.
    """
    raw_symbols: List[str] = []
    logger.info(f"â„¹ï¸ [Data] Ù‚Ø±Ø§Ø¡Ø© Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ù…ÙˆØ² Ù…Ù† Ø§Ù„Ù…Ù„Ù '{filename}'...")
    try:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        file_path = os.path.join(script_dir, filename)

        if not os.path.exists(file_path):
            file_path = os.path.abspath(filename) # Ø¬Ø±Ø¨ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯ Ø¨Ø¬Ø§Ù†Ø¨ Ø§Ù„Ø³ÙƒØ±Ø¨Øª
            if not os.path.exists(file_path):
                 logger.error(f"âŒ [Data] Ø§Ù„Ù…Ù„Ù '{filename}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø³ÙƒØ±Ø¨Øª Ø£Ùˆ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø­Ø§Ù„ÙŠ.")
                 return [] # Ø¥Ø±Ø¬Ø§Ø¹ Ù‚Ø§Ø¦Ù…Ø© ÙØ§Ø±ØºØ© Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù
            else:
                 logger.warning(f"âš ï¸ [Data] Ø§Ù„Ù…Ù„Ù '{filename}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø³ÙƒØ±Ø¨Øª. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ù„Ù ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø­Ø§Ù„ÙŠ: '{file_path}'")

        with open(file_path, 'r', encoding='utf-8') as f:
            # ØªÙ†Ø¸ÙŠÙ ÙˆØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø±Ù…ÙˆØ²: Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙØ±Ø§ØºØ§ØªØŒ ØªØ­ÙˆÙŠÙ„ Ù„Ø£Ø­Ø±Ù ÙƒØ¨ÙŠØ±Ø©ØŒ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù†ØªÙ‡Ø§Ø¡ Ø¨Ù€ USDT
            raw_symbols = [f"{line.strip().upper().replace('USDT', '')}USDT"
                           for line in f if line.strip() and not line.startswith('#')]
        raw_symbols = sorted(list(set(raw_symbols))) # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª ÙˆØ§Ù„ØªØ±ØªÙŠØ¨
        logger.info(f"â„¹ï¸ [Data] ØªÙ… Ù‚Ø±Ø§Ø¡Ø© {len(raw_symbols)} Ø±Ù…Ø² Ù…Ø¨Ø¯Ø¦ÙŠ Ù…Ù† '{file_path}'.")

    except FileNotFoundError:
         logger.error(f"âŒ [Data] Ø§Ù„Ù…Ù„Ù '{filename}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")
         return []
    except Exception as e:
        logger.error(f"âŒ [Data] Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù '{filename}': {e}", exc_info=True)
        return [] # Ø¥Ø±Ø¬Ø§Ø¹ Ù‚Ø§Ø¦Ù…Ø© ÙØ§Ø±ØºØ© ÙÙŠ Ø­Ø§Ù„Ø© Ø­Ø¯ÙˆØ« Ø®Ø·Ø£

    if not raw_symbols:
         logger.warning("âš ï¸ [Data] Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ù„Ù„Ø±Ù…ÙˆØ² ÙØ§Ø±ØºØ©.")
         return []

    # --- Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ² Ù…Ù‚Ø§Ø¨Ù„ Binance API ---
    if not client:
        logger.error("âŒ [Data Validation] Ø¹Ù…ÙŠÙ„ Binance ØºÙŠØ± Ù…Ù‡ÙŠØ£. Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ².")
        return raw_symbols # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© ØºÙŠØ± Ø§Ù„Ù…ÙÙ„ØªØ±Ø© Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¬Ø§Ù‡Ø²Ù‹Ø§

    try:
        logger.info("â„¹ï¸ [Data Validation] Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ø±Ù…ÙˆØ² ÙˆØ­Ø§Ù„Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ù…Ù† Binance API...")
        exchange_info = client.get_exchange_info()
        # Ø¨Ù†Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© (set) Ø¨Ø±Ù…ÙˆØ² USDT Ø§Ù„ØµØ§Ù„Ø­Ø© Ù„Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„ÙÙˆØ±ÙŠ Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ø¨Ø­Ø«
        valid_trading_usdt_symbols = {
            s['symbol'] for s in exchange_info['symbols']
            if s.get('quoteAsset') == 'USDT' and    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø¹Ù…Ù„Ø© Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø© Ù‡ÙŠ USDT
               s.get('status') == 'TRADING' and         # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø­Ø§Ù„Ø© Ù‡ÙŠ TRADING
               s.get('isSpotTradingAllowed') is True    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ù‡ Ù…Ø³Ù…ÙˆØ­ Ø¨Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„ÙÙˆØ±ÙŠ
        }
        logger.info(f"â„¹ï¸ [Data Validation] ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(valid_trading_usdt_symbols)} Ø²ÙˆØ¬ USDT ØµØ§Ù„Ø­ Ù„Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„ÙÙˆØ±ÙŠ Ø¹Ù„Ù‰ Binance.")

        # ÙÙ„ØªØ±Ø© Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù‚Ø±ÙˆØ¡Ø© Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØµØ§Ù„Ø­Ø© Ù…Ù† Binance
        validated_symbols = [symbol for symbol in raw_symbols if symbol in valid_trading_usdt_symbols]

        removed_count = len(raw_symbols) - len(validated_symbols)
        if removed_count > 0:
            removed_symbols = set(raw_symbols) - set(validated_symbols)
            logger.warning(f"âš ï¸ [Data Validation] ØªÙ… Ø¥Ø²Ø§Ù„Ø© {removed_count} Ø±Ù…Ø² ØºÙŠØ± ØµØ§Ù„Ø­ Ø£Ùˆ ØºÙŠØ± Ù…ØªØ§Ø­ Ù„Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„ÙÙˆØ±ÙŠ USDT Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©: {', '.join(removed_symbols)}")

        logger.info(f"âœ… [Data Validation] ØªÙ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ². Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… {len(validated_symbols)} Ø±Ù…Ø² ØµØ§Ù„Ø­.")
        return validated_symbols

    except (BinanceAPIException, BinanceRequestException) as binance_err:
         logger.error(f"âŒ [Data Validation] Ø®Ø·Ø£ Ù…Ù† Binance API Ø£Ùˆ Ø§Ù„Ø´Ø¨ÙƒØ© Ø¹Ù†Ø¯ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ²: {binance_err}")
         logger.warning("âš ï¸ [Data Validation] Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø¨Ø¯ÙˆÙ† ØªØ­Ù‚Ù‚ Binance.")
         return raw_symbols # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© ØºÙŠØ± Ø§Ù„Ù…ÙÙ„ØªØ±Ø© ÙÙŠ Ø­Ø§Ù„Ø© Ø®Ø·Ø£ API
    except Exception as api_err:
         logger.error(f"âŒ [Data Validation] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø±Ù…ÙˆØ² Binance: {api_err}", exc_info=True)
         logger.warning("âš ï¸ [Data Validation] Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø¨Ø¯ÙˆÙ† ØªØ­Ù‚Ù‚ Binance.")
         return raw_symbols # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© ØºÙŠØ± Ø§Ù„Ù…ÙÙ„ØªØ±Ø© ÙÙŠ Ø­Ø§Ù„Ø© Ø®Ø·Ø£ API


# ---------------------- Ø¥Ø¯Ø§Ø±Ø© WebSocket Ù„Ø£Ø³Ø¹Ø§Ø± Ticker ----------------------
def handle_ticker_message(msg: Union[List[Dict[str, Any]], Dict[str, Any]]) -> None:
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³Ø§Ø¦Ù„ WebSocket Ø§Ù„ÙˆØ§Ø±Ø¯Ø© Ù„Ø£Ø³Ø¹Ø§Ø± mini-ticker."""
    global ticker_data
    try:
        if isinstance(msg, list):
            for ticker_item in msg:
                symbol = ticker_item.get('s')
                price_str = ticker_item.get('c') # Ø³Ø¹Ø± Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø£Ø®ÙŠØ± ÙƒÙ€ string
                if symbol and 'USDT' in symbol and price_str:
                    try:
                        ticker_data[symbol] = float(price_str)
                    except ValueError:
                         logger.warning(f"âš ï¸ [WS] Ù‚ÙŠÙ…Ø© Ø³Ø¹Ø± ØºÙŠØ± ØµØ§Ù„Ø­Ø© Ù„Ù„Ø±Ù…Ø² {symbol}: '{price_str}'")
        elif isinstance(msg, dict):
             if msg.get('e') == 'error':
                 logger.error(f"âŒ [WS] Ø±Ø³Ø§Ù„Ø© Ø®Ø·Ø£ Ù…Ù† WebSocket: {msg.get('m', 'Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªÙØ§ØµÙŠÙ„ Ø®Ø·Ø£')}")
             elif msg.get('stream') and msg.get('data'): # Handle combined streams format
                 for ticker_item in msg.get('data', []):
                    symbol = ticker_item.get('s')
                    price_str = ticker_item.get('c')
                    if symbol and 'USDT' in symbol and price_str:
                        try:
                            ticker_data[symbol] = float(price_str)
                        except ValueError:
                             logger.warning(f"âš ï¸ [WS] Ù‚ÙŠÙ…Ø© Ø³Ø¹Ø± ØºÙŠØ± ØµØ§Ù„Ø­Ø© Ù„Ù„Ø±Ù…Ø² {symbol} ÙÙŠ combined stream: '{price_str}'")
        else:
             logger.warning(f"âš ï¸ [WS] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø±Ø³Ø§Ù„Ø© WebSocket Ø¨ØªÙ†Ø³ÙŠÙ‚ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {type(msg)}")

    except Exception as e:
        logger.error(f"âŒ [WS] Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³Ø§Ù„Ø© ticker: {e}", exc_info=True)


def run_ticker_socket_manager() -> None:
    """ØªØ´ØºÙŠÙ„ ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§ØªØµØ§Ù„ WebSocket Ù„Ù€ mini-ticker."""
    while True:
        try:
            logger.info("â„¹ï¸ [WS] Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ WebSocket Manager Ù„Ø£Ø³Ø¹Ø§Ø± Ticker...")
            twm = ThreadedWebsocketManager(api_key=API_KEY, api_secret=API_SECRET)
            twm.start() # Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø¯ÙŠØ±

            # Ø§Ø³ØªØ®Ø¯Ø§Ù… start_miniticker_socket ÙŠØºØ·ÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±Ù…ÙˆØ² ÙˆÙ‡Ùˆ Ù…Ù†Ø§Ø³Ø¨ Ù‡Ù†Ø§
            stream_name = twm.start_miniticker_socket(callback=handle_ticker_message)
            logger.info(f"âœ… [WS] ØªÙ… Ø¨Ø¯Ø¡ WebSocket stream: {stream_name}")

            twm.join() # Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø­ØªÙ‰ ÙŠØªÙˆÙ‚Ù Ø§Ù„Ù…Ø¯ÙŠØ± (Ø¹Ø§Ø¯Ø© Ø¨Ø³Ø¨Ø¨ Ø®Ø·Ø£ Ø£Ùˆ Ø¥ÙŠÙ‚Ø§Ù)
            logger.warning("âš ï¸ [WS] Ù…Ø¯ÙŠØ± WebSocket ØªÙˆÙ‚Ù. Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ´ØºÙŠÙ„...")

        except Exception as e:
            logger.error(f"âŒ [WS] Ø®Ø·Ø£ ÙØ§Ø¯Ø­ ÙÙŠ WebSocket Manager: {e}. Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ Ø®Ù„Ø§Ù„ 15 Ø«Ø§Ù†ÙŠØ©...", exc_info=True)

        # Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ù‚Ø¨Ù„ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„ØªØ¬Ù†Ø¨ Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø£Ùˆ Ø­Ø¸Ø± Ø§Ù„Ù€ IP
        time.sleep(15)

# ---------------------- Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ© ----------------------

def calculate_rsi_indicator(df: pd.DataFrame, period: int = RSI_PERIOD) -> pd.DataFrame:
    """Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø± Ø§Ù„Ù‚ÙˆØ© Ø§Ù„Ù†Ø³Ø¨ÙŠØ© (RSI)."""
    df = df.copy()
    if 'close' not in df.columns or df['close'].isnull().all():
        logger.warning("âš ï¸ [Indicator RSI] Ø¹Ù…ÙˆØ¯ 'close' Ù…ÙÙ‚ÙˆØ¯ Ø£Ùˆ ÙØ§Ø±Øº.")
        df['rsi'] = np.nan
        return df
    if len(df) < period:
        logger.warning(f"âš ï¸ [Indicator RSI] Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© ({len(df)} < {period}) Ù„Ø­Ø³Ø§Ø¨ RSI.")
        df['rsi'] = np.nan
        return df

    delta = df['close'].diff()
    gain = delta.clip(lower=0)
    loss = -delta.clip(upper=0)

    # Ø§Ø³ØªØ®Ø¯Ø§Ù… ewm Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ØªØ­Ø±Ùƒ Ø§Ù„Ø£Ø³ÙŠ Ù„Ù„Ù…ÙƒØ§Ø³Ø¨ ÙˆØ§Ù„Ø®Ø³Ø§Ø¦Ø±
    avg_gain = gain.ewm(com=period - 1, adjust=False).mean()
    avg_loss = loss.ewm(com=period - 1, adjust=False).mean()

    # Ø­Ø³Ø§Ø¨ RS ÙˆØªØ¬Ù†Ø¨ Ø§Ù„Ù‚Ø³Ù…Ø© Ø¹Ù„Ù‰ ØµÙØ±
    rs = avg_gain / avg_loss.replace(0, np.nan) # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„ØµÙØ± Ø¨Ù€ NaN Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ù‚Ø³Ù…Ø© Ø¹Ù„ÙŠÙ‡

    # Ø­Ø³Ø§Ø¨ RSI
    rsi_series = 100 - (100 / (1 + rs))

    # Ù…Ù„Ø¡ Ø§Ù„Ù‚ÙŠÙ… NaN Ø§Ù„Ø£ÙˆÙ„ÙŠØ© (Ø§Ù„Ù†Ø§ØªØ¬Ø© Ø¹Ù† diff Ø£Ùˆ avg_loss=0) Ø¨Ø§Ù„Ù‚ÙŠÙ…Ø© 50 (Ù…Ø­Ø§ÙŠØ¯)
    # ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù… forward fill Ù„Ø³Ø¯ Ø§Ù„ÙØ¬ÙˆØ§Øª Ø¥Ù† ÙˆØ¬Ø¯Øª (Ù†Ø§Ø¯Ø± Ø§Ù„Ø­Ø¯ÙˆØ« Ù…Ø¹ adjust=False)
    df['rsi'] = rsi_series.ffill().fillna(50)

    return df

def calculate_atr_indicator(df: pd.DataFrame, period: int = ENTRY_ATR_PERIOD) -> pd.DataFrame:
    """Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø± Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ù‰ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ (ATR)."""
    df = df.copy()
    required_cols = ['high', 'low', 'close']
    if not all(col in df.columns for col in required_cols) or df[required_cols].isnull().all().any():
        logger.warning("âš ï¸ [Indicator ATR] Ø£Ø¹Ù…Ø¯Ø© 'high', 'low', 'close' Ù…ÙÙ‚ÙˆØ¯Ø© Ø£Ùˆ ÙØ§Ø±ØºØ©.")
        df['atr'] = np.nan
        return df
    if len(df) < period + 1: # Ù†Ø­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø´Ù…Ø¹Ø© ÙˆØ§Ø­Ø¯Ø© Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ø­Ø³Ø§Ø¨ shift(1)
        logger.warning(f"âš ï¸ [Indicator ATR] Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© ({len(df)} < {period + 1}) Ù„Ø­Ø³Ø§Ø¨ ATR.")
        df['atr'] = np.nan
        return df

    high_low = df['high'] - df['low']
    high_close_prev = (df['high'] - df['close'].shift(1)).abs()
    low_close_prev = (df['low'] - df['close'].shift(1)).abs()

    # Ø­Ø³Ø§Ø¨ True Range (TR) - ØªØ¬Ø§Ù‡Ù„ NaN Ø£Ø«Ù†Ø§Ø¡ Ø­Ø³Ø§Ø¨ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰
    tr = pd.concat([high_low, high_close_prev, low_close_prev], axis=1).max(axis=1, skipna=False)

    # Ø­Ø³Ø§Ø¨ ATR Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… EMA (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… span ÙŠØ¹Ø·ÙŠ Ù†ØªÙŠØ¬Ø© Ø£Ù‚Ø±Ø¨ Ù„Ù€ TradingView Ù…Ù† com=period-1)
    df['atr'] = tr.ewm(span=period, adjust=False).mean()
    return df


def calculate_bollinger_bands(df: pd.DataFrame, window: int = BOLLINGER_WINDOW, num_std: int = BOLLINGER_STD_DEV) -> pd.DataFrame:
    """Ø­Ø³Ø§Ø¨ Ù†Ø·Ø§Ù‚Ø§Øª Ø¨ÙˆÙ„ÙŠÙ†Ø¬Ø±."""
    df = df.copy()
    if 'close' not in df.columns or df['close'].isnull().all():
        logger.warning("âš ï¸ [Indicator BB] Ø¹Ù…ÙˆØ¯ 'close' Ù…ÙÙ‚ÙˆØ¯ Ø£Ùˆ ÙØ§Ø±Øº.")
        df['bb_middle'] = np.nan
        df['bb_upper'] = np.nan
        df['bb_lower'] = np.nan
        return df
    if len(df) < window:
         logger.warning(f"âš ï¸ [Indicator BB] Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© ({len(df)} < {window}) Ù„Ø­Ø³Ø§Ø¨ BB.")
         df['bb_middle'] = np.nan
         df['bb_upper'] = np.nan
         df['bb_lower'] = np.nan
         return df

    df['bb_middle'] = df['close'].rolling(window=window).mean()
    df['bb_std'] = df['close'].rolling(window=window).std()
    df['bb_upper'] = df['bb_middle'] + num_std * df['bb_std']
    df['bb_lower'] = df['bb_middle'] - num_std * df['bb_std']
    return df


def calculate_macd(df: pd.DataFrame, fast: int = MACD_FAST, slow: int = MACD_SLOW, signal: int = MACD_SIGNAL) -> pd.DataFrame:
    """Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø± MACD ÙˆØ®Ø· Ø§Ù„Ø¥Ø´Ø§Ø±Ø© ÙˆØ§Ù„Ù‡ÙŠØ³ØªÙˆØ¬Ø±Ø§Ù…."""
    df = df.copy()
    if 'close' not in df.columns or df['close'].isnull().all():
        logger.warning("âš ï¸ [Indicator MACD] Ø¹Ù…ÙˆØ¯ 'close' Ù…ÙÙ‚ÙˆØ¯ Ø£Ùˆ ÙØ§Ø±Øº.")
        df['macd'] = np.nan
        df['macd_signal'] = np.nan
        df['macd_hist'] = np.nan
        return df
    min_len = max(fast, slow, signal)
    if len(df) < min_len:
        logger.warning(f"âš ï¸ [Indicator MACD] Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© ({len(df)} < {min_len}) Ù„Ø­Ø³Ø§Ø¨ MACD.")
        df['macd'] = np.nan
        df['macd_signal'] = np.nan
        df['macd_hist'] = np.nan
        return df

    ema_fast = calculate_ema(df['close'], fast)
    ema_slow = calculate_ema(df['close'], slow)
    df['macd'] = ema_fast - ema_slow
    df['macd_signal'] = calculate_ema(df['macd'], signal) # Ø­Ø³Ø§Ø¨ EMA Ù„Ù„Ù€ MACD line
    df['macd_hist'] = df['macd'] - df['macd_signal']
    return df


def calculate_adx(df: pd.DataFrame, period: int = ADX_PERIOD) -> pd.DataFrame:
    """Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø± ADX Ùˆ DI+ Ùˆ DI-."""
    df_calc = df.copy() # Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù„Ù‰ Ù†Ø³Ø®Ø©
    required_cols = ['high', 'low', 'close']
    if not all(col in df_calc.columns for col in required_cols) or df_calc[required_cols].isnull().all().any():
        logger.warning("âš ï¸ [Indicator ADX] Ø£Ø¹Ù…Ø¯Ø© 'high', 'low', 'close' Ù…ÙÙ‚ÙˆØ¯Ø© Ø£Ùˆ ÙØ§Ø±ØºØ©.")
        df_calc['adx'] = np.nan
        df_calc['di_plus'] = np.nan
        df_calc['di_minus'] = np.nan
        return df_calc
    # ÙŠØªØ·Ù„Ø¨ ADX ÙØªØ±Ø© + ÙØªØ±Ø© Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ù€ smoothing
    if len(df_calc) < period * 2:
        logger.warning(f"âš ï¸ [Indicator ADX] Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© ({len(df_calc)} < {period * 2}) Ù„Ø­Ø³Ø§Ø¨ ADX.")
        df_calc['adx'] = np.nan
        df_calc['di_plus'] = np.nan
        df_calc['di_minus'] = np.nan
        return df_calc

    # Ø­Ø³Ø§Ø¨ True Range (TR)
    df_calc['high-low'] = df_calc['high'] - df_calc['low']
    df_calc['high-prev_close'] = abs(df_calc['high'] - df_calc['close'].shift(1))
    df_calc['low-prev_close'] = abs(df_calc['low'] - df_calc['close'].shift(1))
    df_calc['tr'] = df_calc[['high-low', 'high-prev_close', 'low-prev_close']].max(axis=1, skipna=False)

    # Ø­Ø³Ø§Ø¨ Directional Movement (+DM, -DM)
    df_calc['up_move'] = df_calc['high'] - df_calc['high'].shift(1)
    df_calc['down_move'] = df_calc['low'].shift(1) - df_calc['low']
    df_calc['+dm'] = np.where((df_calc['up_move'] > df_calc['down_move']) & (df_calc['up_move'] > 0), df_calc['up_move'], 0)
    df_calc['-dm'] = np.where((df_calc['down_move'] > df_calc['up_move']) & (df_calc['down_move'] > 0), df_calc['down_move'], 0)

    # Ø§Ø³ØªØ®Ø¯Ø§Ù… EMA Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ù„Ø³Ø§Ø¡ (alpha = 1/period)
    alpha = 1 / period
    df_calc['tr_smooth'] = df_calc['tr'].ewm(alpha=alpha, adjust=False).mean()
    df_calc['+dm_smooth'] = df_calc['+dm'].ewm(alpha=alpha, adjust=False).mean()
    df_calc['-dm_smooth'] = df_calc['-dm'].ewm(alpha=alpha, adjust=False).mean()

    # Ø­Ø³Ø§Ø¨ Directional Indicators (DI+, DI-) ÙˆØªØ¬Ù†Ø¨ Ø§Ù„Ù‚Ø³Ù…Ø© Ø¹Ù„Ù‰ ØµÙØ±
    df_calc['di_plus'] = np.where(df_calc['tr_smooth'] > 0, 100 * (df_calc['+dm_smooth'] / df_calc['tr_smooth']), 0)
    df_calc['di_minus'] = np.where(df_calc['tr_smooth'] > 0, 100 * (df_calc['-dm_smooth'] / df_calc['tr_smooth']), 0)

    # Ø­Ø³Ø§Ø¨ Directional Movement Index (DX)
    di_sum = df_calc['di_plus'] + df_calc['di_minus']
    df_calc['dx'] = np.where(di_sum > 0, 100 * abs(df_calc['di_plus'] - df_calc['di_minus']) / di_sum, 0)

    # Ø­Ø³Ø§Ø¨ Average Directional Index (ADX) Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… EMA
    df_calc['adx'] = df_calc['dx'].ewm(alpha=alpha, adjust=False).mean()

    # Ø¥Ø±Ø¬Ø§Ø¹ DataFrame Ù…Ø¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙÙ‚Ø· (Ø£Ùˆ ÙŠÙ…ÙƒÙ† Ø¯Ù…Ø¬Ù‡Ø§ Ù…Ø¹ Ø§Ù„Ø£ØµÙ„ÙŠ)
    return df_calc[['adx', 'di_plus', 'di_minus']]


def calculate_vwap(df: pd.DataFrame) -> pd.DataFrame:
    """Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…Ø±Ø¬Ø­ Ø¨Ø§Ù„Ø­Ø¬Ù… (VWAP) - ÙŠØ¹Ø§Ø¯ ØªØ¹ÙŠÙŠÙ†Ù‡ ÙŠÙˆÙ…ÙŠÙ‹Ø§."""
    df = df.copy()
    required_cols = ['high', 'low', 'close', 'volume']
    if not all(col in df.columns for col in required_cols) or df[required_cols].isnull().all().any():
        logger.warning("âš ï¸ [Indicator VWAP] Ø£Ø¹Ù…Ø¯Ø© 'high', 'low', 'close', 'volume' Ù…ÙÙ‚ÙˆØ¯Ø© Ø£Ùˆ ÙØ§Ø±ØºØ©.")
        df['vwap'] = np.nan
        return df
    if not isinstance(df.index, pd.DatetimeIndex):
        try:
            # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙÙ‡Ø±Ø³ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† DatetimeIndex
            df.index = pd.to_datetime(df.index)
            logger.warning("âš ï¸ [Indicator VWAP] ØªÙ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙÙ‡Ø±Ø³ Ø¥Ù„Ù‰ DatetimeIndex.")
        except Exception:
            logger.error("âŒ [Indicator VWAP] ÙØ´Ù„ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙÙ‡Ø±Ø³ Ø¥Ù„Ù‰ DatetimeIndexØŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø­Ø³Ø§Ø¨ VWAP Ø§Ù„ÙŠÙˆÙ…ÙŠ.")
            df['vwap'] = np.nan
            return df

    df['date'] = df.index.date
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠ ÙˆØ§Ù„Ø­Ø¬Ù… * Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠ
    df['typical_price'] = (df['high'] + df['low'] + df['close']) / 3
    df['tp_vol'] = df['typical_price'] * df['volume']

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¬Ø§Ù…ÙŠØ¹ Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠØ© Ø¶Ù…Ù† ÙƒÙ„ ÙŠÙˆÙ…
    try:
        # Group by date and calculate cumulative sums
        df['cum_tp_vol'] = df.groupby('date')['tp_vol'].cumsum()
        df['cum_volume'] = df.groupby('date')['volume'].cumsum()
    except KeyError as e:
        logger.error(f"âŒ [Indicator VWAP] Ø®Ø·Ø£ ÙÙŠ ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„ØªØ§Ø±ÙŠØ®: {e}. Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„ÙÙ‡Ø±Ø³ ØºÙŠØ± ØµØ­ÙŠØ­.")
        df['vwap'] = np.nan
        # Ø­Ø°Ù Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ÙˆØ¬ÙˆØ¯Ø©
        df.drop(columns=['date', 'typical_price', 'tp_vol', 'cum_tp_vol', 'cum_volume'], inplace=True, errors='ignore')
        return df
    except Exception as e:
         logger.error(f"âŒ [Indicator VWAP] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ ØªØ¬Ù…ÙŠØ¹ VWAP: {e}", exc_info=True)
         df['vwap'] = np.nan
         df.drop(columns=['date', 'typical_price', 'tp_vol', 'cum_tp_vol', 'cum_volume'], inplace=True, errors='ignore')
         return df


    # Ø­Ø³Ø§Ø¨ VWAP ÙˆØªØ¬Ù†Ø¨ Ø§Ù„Ù‚Ø³Ù…Ø© Ø¹Ù„Ù‰ ØµÙØ±
    df['vwap'] = np.where(df['cum_volume'] > 0, df['cum_tp_vol'] / df['cum_volume'], np.nan)

    # Ù…Ù„Ø¡ Ù‚ÙŠÙ… NaN Ø§Ù„Ø£ÙˆÙ„ÙŠØ© ÙÙŠ Ø¨Ø¯Ø§ÙŠØ© ÙƒÙ„ ÙŠÙˆÙ… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© (backfill)
    # Ø­ÙŠØ« Ø£Ù† VWAP Ø§Ù„ÙŠÙˆÙ…ÙŠ ÙŠØªØ±Ø§ÙƒÙ…ØŒ Ø£ÙˆÙ„ Ù‚ÙŠÙ…Ø© Ù‚Ø¯ ØªÙƒÙˆÙ† NaNØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø­Ø³ÙˆØ¨Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©
    df['vwap'] = df['vwap'].bfill()

    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©
    df.drop(columns=['date', 'typical_price', 'tp_vol', 'cum_tp_vol', 'cum_volume'], inplace=True, errors='ignore')
    return df


def calculate_obv(df: pd.DataFrame) -> pd.DataFrame:
    """Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø± Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„Ù…ØªÙˆØ§Ø²Ù† (On-Balance Volume - OBV)."""
    df = df.copy()
    required_cols = ['close', 'volume']
    if not all(col in df.columns for col in required_cols) or df[required_cols].isnull().all().any():
        logger.warning("âš ï¸ [Indicator OBV] Ø£Ø¹Ù…Ø¯Ø© 'close' Ø£Ùˆ 'volume' Ù…ÙÙ‚ÙˆØ¯Ø© Ø£Ùˆ ÙØ§Ø±ØºØ©.")
        df['obv'] = np.nan
        return df
    if not pd.api.types.is_numeric_dtype(df['close']) or not pd.api.types.is_numeric_dtype(df['volume']):
        logger.warning("âš ï¸ [Indicator OBV] Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© 'close' Ø£Ùˆ 'volume' Ù„ÙŠØ³Øª Ø±Ù‚Ù…ÙŠØ©.")
        df['obv'] = np.nan
        return df

    obv = np.zeros(len(df), dtype=np.float64) # Ø§Ø³ØªØ®Ø¯Ø§Ù… numpy array Ø£Ø³Ø±Ø¹
    close = df['close'].values
    volume = df['volume'].values

    # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØºÙŠØ±Ø§Øª ÙÙŠ Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©
    close_diff = df['close'].diff().values

    for i in range(1, len(df)):
        if np.isnan(close[i]) or np.isnan(volume[i]) or np.isnan(close_diff[i]):
            obv[i] = obv[i-1] # Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© ÙÙŠ Ø­Ø§Ù„Ø© ÙˆØ¬ÙˆØ¯ NaN
            continue

        if close_diff[i] > 0: # Ø§Ù„Ø³Ø¹Ø± Ø§Ø±ØªÙØ¹
            obv[i] = obv[i-1] + volume[i]
        elif close_diff[i] < 0: # Ø§Ù„Ø³Ø¹Ø± Ø§Ù†Ø®ÙØ¶
             obv[i] = obv[i-1] - volume[i]
        else: # Ø§Ù„Ø³Ø¹Ø± Ù„Ù… ÙŠØªØºÙŠØ±
             obv[i] = obv[i-1]

    df['obv'] = obv
    return df


def calculate_supertrend(df: pd.DataFrame, period: int = SUPERTREND_PERIOD, multiplier: float = SUPERTREND_MULTIPLIER) -> pd.DataFrame:
    """Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø± SuperTrend."""
    df_st = df.copy()
    required_cols = ['high', 'low', 'close']
    if not all(col in df_st.columns for col in required_cols) or df_st[required_cols].isnull().all().any():
        logger.warning("âš ï¸ [Indicator SuperTrend] Ø£Ø¹Ù…Ø¯Ø© 'high', 'low', 'close' Ù…ÙÙ‚ÙˆØ¯Ø© Ø£Ùˆ ÙØ§Ø±ØºØ©.")
        df_st['supertrend'] = np.nan
        df_st['supertrend_trend'] = 0 # 0: ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ, 1: ØµØ§Ø¹Ø¯, -1: Ù‡Ø§Ø¨Ø·
        return df_st

    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¹Ù…ÙˆØ¯ ATR Ø£Ùˆ Ø­Ø³Ø§Ø¨Ù‡
    if 'atr' not in df_st.columns or df_st['atr'].isnull().all():
        logger.debug(f"â„¹ï¸ [Indicator SuperTrend] Ø­Ø³Ø§Ø¨ ATR (period={period}) Ù„Ù€ SuperTrend...")
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙØªØ±Ø© ATR Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù€ SuperTrend Ù‡Ù†Ø§
        df_st = calculate_atr_indicator(df_st, period=period)

    if 'atr' not in df_st.columns or df_st['atr'].isnull().all():
         logger.warning("âš ï¸ [Indicator SuperTrend] Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø­Ø³Ø§Ø¨ SuperTrend Ø¨Ø³Ø¨Ø¨ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù‚ÙŠÙ… ATR ØµØ§Ù„Ø­Ø©.")
         df_st['supertrend'] = np.nan
         df_st['supertrend_trend'] = 0
         return df_st
    if len(df_st) < period:
        logger.warning(f"âš ï¸ [Indicator SuperTrend] Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© ({len(df_st)} < {period}) Ù„Ø­Ø³Ø§Ø¨ SuperTrend.")
        df_st['supertrend'] = np.nan
        df_st['supertrend_trend'] = 0
        return df_st

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ø·Ø§Ù‚Ø§Øª Ø§Ù„Ø¹Ù„ÙˆÙŠØ© ÙˆØ§Ù„Ø³ÙÙ„ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    hl2 = (df_st['high'] + df_st['low']) / 2
    df_st['basic_ub'] = hl2 + multiplier * df_st['atr']
    df_st['basic_lb'] = hl2 - multiplier * df_st['atr']

    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
    df_st['final_ub'] = 0.0
    df_st['final_lb'] = 0.0
    df_st['supertrend'] = np.nan
    df_st['supertrend_trend'] = 0 # 1 for uptrend, -1 for downtrend

    # Ø§Ø³ØªØ®Ø¯Ø§Ù… .values Ù„Ù„ÙˆØµÙˆÙ„ Ø§Ù„Ø£Ø³Ø±Ø¹ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø­Ù„Ù‚Ø©
    close = df_st['close'].values
    basic_ub = df_st['basic_ub'].values
    basic_lb = df_st['basic_lb'].values
    final_ub = df_st['final_ub'].values # Ø³ÙŠØªÙ… ØªØ¹Ø¯ÙŠÙ„Ù‡ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø­Ù„Ù‚Ø©
    final_lb = df_st['final_lb'].values # Ø³ÙŠØªÙ… ØªØ¹Ø¯ÙŠÙ„Ù‡ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø­Ù„Ù‚Ø©
    st = df_st['supertrend'].values     # Ø³ÙŠØªÙ… ØªØ¹Ø¯ÙŠÙ„Ù‡ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø­Ù„Ù‚Ø©
    st_trend = df_st['supertrend_trend'].values # Ø³ÙŠØªÙ… ØªØ¹Ø¯ÙŠÙ„Ù‡ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø­Ù„Ù‚Ø©

    # Ø§Ù„Ø¨Ø¯Ø¡ Ù…Ù† Ø§Ù„Ø´Ù…Ø¹Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© (index 1) Ù„Ø£Ù†Ù†Ø§ Ù†Ù‚Ø§Ø±Ù† Ù…Ø¹ Ø§Ù„Ø³Ø§Ø¨Ù‚
    for i in range(1, len(df_st)):
        # Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ NaN ÙÙŠ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø´Ù…Ø¹Ø©
        if pd.isna(basic_ub[i]) or pd.isna(basic_lb[i]) or pd.isna(close[i]):
            # ÙÙŠ Ø­Ø§Ù„Ø© NaNØŒ Ø§Ø­ØªÙØ¸ Ø¨Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ù„Ù„Ù€ final bands ÙˆØ§Ù„Ù€ supertrend ÙˆØ§Ù„Ø§ØªØ¬Ø§Ù‡
            final_ub[i] = final_ub[i-1]
            final_lb[i] = final_lb[i-1]
            st[i] = st[i-1]
            st_trend[i] = st_trend[i-1]
            continue

        # Ø­Ø³Ø§Ø¨ Final Upper Band
        if basic_ub[i] < final_ub[i-1] or close[i-1] > final_ub[i-1]:
            final_ub[i] = basic_ub[i]
        else:
            final_ub[i] = final_ub[i-1]

        # Ø­Ø³Ø§Ø¨ Final Lower Band
        if basic_lb[i] > final_lb[i-1] or close[i-1] < final_lb[i-1]:
            final_lb[i] = basic_lb[i]
        else:
            final_lb[i] = final_lb[i-1]

        # ØªØ­Ø¯ÙŠØ¯ Ø®Ø· SuperTrend ÙˆØ§Ù„Ø§ØªØ¬Ø§Ù‡
        if st[i-1] == final_ub[i-1]: # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù‡Ø§Ø¨Ø·Ù‹Ø§
            if close[i] <= final_ub[i]: # Ø§Ø³ØªÙ…Ø± ÙÙŠ Ø§Ù„Ù‡Ø¨ÙˆØ·
                st[i] = final_ub[i]
                st_trend[i] = -1
            else: # ØªØºÙŠØ± Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø¥Ù„Ù‰ ØµØ§Ø¹Ø¯
                st[i] = final_lb[i]
                st_trend[i] = 1
        elif st[i-1] == final_lb[i-1]: # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³Ø§Ø¨Ù‚ ØµØ§Ø¹Ø¯Ù‹Ø§
            if close[i] >= final_lb[i]: # Ø§Ø³ØªÙ…Ø± ÙÙŠ Ø§Ù„ØµØ¹ÙˆØ¯
                st[i] = final_lb[i]
                st_trend[i] = 1
            else: # ØªØºÙŠØ± Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø¥Ù„Ù‰ Ù‡Ø§Ø¨Ø·
                st[i] = final_ub[i]
                st_trend[i] = -1
        else: # Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© (Ø£Ùˆ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© NaN)
             if close[i] > final_ub[i]: # Ø¨Ø¯Ø§ÙŠØ© Ø§ØªØ¬Ø§Ù‡ ØµØ§Ø¹Ø¯
                 st[i] = final_lb[i]
                 st_trend[i] = 1
             elif close[i] < final_lb[i]: # Ø¨Ø¯Ø§ÙŠØ© Ø§ØªØ¬Ø§Ù‡ Ù‡Ø§Ø¨Ø·
                  st[i] = final_ub[i]
                  st_trend[i] = -1
             else: # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¹Ø± Ø¨ÙŠÙ† Ø§Ù„Ù†Ø·Ø§Ù‚ÙŠÙ† ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© (Ù†Ø§Ø¯Ø±)
                  st[i] = np.nan # Ø£Ùˆ ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚ÙŠÙ…Ø© Ø³Ø§Ø¨Ù‚Ø© Ø¥Ù† ÙˆØ¬Ø¯Øª
                  st_trend[i] = 0


    # Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ø­Ø³ÙˆØ¨Ø© Ø¥Ù„Ù‰ DataFrame
    df_st['final_ub'] = final_ub
    df_st['final_lb'] = final_lb
    df_st['supertrend'] = st
    df_st['supertrend_trend'] = st_trend

    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©
    df_st.drop(columns=['basic_ub', 'basic_lb', 'final_ub', 'final_lb'], inplace=True, errors='ignore')

    return df_st


# ---------------------- Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø´Ù…ÙˆØ¹ Ø§Ù„ÙŠØ§Ø¨Ø§Ù†ÙŠØ© ----------------------

def is_hammer(row: pd.Series) -> int:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø·Ø±Ù‚Ø© (Ø¥Ø´Ø§Ø±Ø© ØµØ¹ÙˆØ¯ÙŠØ©)."""
    o, h, l, c = row.get('open'), row.get('high'), row.get('low'), row.get('close')
    if pd.isna([o, h, l, c]).any(): return 0
    body = abs(c - o)
    candle_range = h - l
    if candle_range == 0: return 0
    lower_shadow = min(o, c) - l
    upper_shadow = h - max(o, c)
    is_small_body = body < (candle_range * 0.35) # ØªØ³Ø§Ù…Ø­ Ø£ÙƒØ¨Ø± Ù‚Ù„ÙŠÙ„Ø§Ù‹ Ù„Ù„Ø¬Ø³Ù…
    is_long_lower_shadow = lower_shadow >= 1.8 * body if body > 0 else lower_shadow > candle_range * 0.6
    is_small_upper_shadow = upper_shadow <= body * 0.6 if body > 0 else upper_shadow < candle_range * 0.15
    return 100 if is_small_body and is_long_lower_shadow and is_small_upper_shadow else 0

def is_shooting_star(row: pd.Series) -> int:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø´Ù‡Ø§Ø¨ (Ø¥Ø´Ø§Ø±Ø© Ù‡Ø¨ÙˆØ·ÙŠØ©)."""
    o, h, l, c = row.get('open'), row.get('high'), row.get('low'), row.get('close')
    if pd.isna([o, h, l, c]).any(): return 0
    body = abs(c - o)
    candle_range = h - l
    if candle_range == 0: return 0
    lower_shadow = min(o, c) - l
    upper_shadow = h - max(o, c)
    is_small_body = body < (candle_range * 0.35)
    is_long_upper_shadow = upper_shadow >= 1.8 * body if body > 0 else upper_shadow > candle_range * 0.6
    is_small_lower_shadow = lower_shadow <= body * 0.6 if body > 0 else lower_shadow < candle_range * 0.15
    return -100 if is_small_body and is_long_upper_shadow and is_small_lower_shadow else 0 # Ø¥Ø´Ø§Ø±Ø© Ø³Ø§Ù„Ø¨Ø©

def is_doji(row: pd.Series) -> int:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ Ø¯ÙˆØ¬ÙŠ (Ø¹Ø¯Ù… ÙŠÙ‚ÙŠÙ†)."""
    o, h, l, c = row.get('open'), row.get('high'), row.get('low'), row.get('close')
    if pd.isna([o, h, l, c]).any(): return 0
    candle_range = h - l
    if candle_range == 0: return 0
    return 100 if abs(c - o) <= (candle_range * 0.1) else 0 # Ø§Ù„Ø¬Ø³Ù… ØµØºÙŠØ± Ø¬Ø¯Ù‹Ø§

def compute_engulfing(df: pd.DataFrame, idx: int) -> int:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§Ø¨ØªÙ„Ø§Ø¹ Ø§Ù„ØµØ¹ÙˆØ¯ÙŠ Ø£Ùˆ Ø§Ù„Ù‡Ø¨ÙˆØ·ÙŠ."""
    if idx == 0: return 0
    prev = df.iloc[idx - 1]
    curr = df.iloc[idx]
    # ØªØ­Ù‚Ù‚ Ù…Ù† NaN ÙÙŠ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
    if pd.isna([prev['close'], prev['open'], curr['close'], curr['open']]).any():
        return 0

    # Ø§Ø¨ØªÙ„Ø§Ø¹ ØµØ¹ÙˆØ¯ÙŠ: Ø´Ù…Ø¹Ø© Ø³Ø§Ø¨Ù‚Ø© Ù‡Ø§Ø¨Ø·Ø©ØŒ Ø­Ø§Ù„ÙŠØ© ØµØ§Ø¹Ø¯Ø© ØªØ¨ØªÙ„Ø¹ Ø¬Ø³Ù… Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
    is_bullish = (prev['close'] < prev['open'] and curr['close'] > curr['open'] and
                  curr['open'] <= prev['close'] and curr['close'] >= prev['open'])
    # Ø§Ø¨ØªÙ„Ø§Ø¹ Ù‡Ø¨ÙˆØ·ÙŠ: Ø´Ù…Ø¹Ø© Ø³Ø§Ø¨Ù‚Ø© ØµØ§Ø¹Ø¯Ø©ØŒ Ø­Ø§Ù„ÙŠØ© Ù‡Ø§Ø¨Ø·Ø© ØªØ¨ØªÙ„Ø¹ Ø¬Ø³Ù… Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
    is_bearish = (prev['close'] > prev['open'] and curr['close'] < curr['open'] and
                  curr['open'] >= prev['close'] and curr['close'] <= prev['open'])

    if is_bullish: return 100
    if is_bearish: return -100
    return 0

def detect_candlestick_patterns(df: pd.DataFrame) -> pd.DataFrame:
    """ØªØ·Ø¨ÙŠÙ‚ Ø¯ÙˆØ§Ù„ Ø§ÙƒØªØ´Ø§Ù Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø´Ù…ÙˆØ¹ Ø¹Ù„Ù‰ DataFrame."""
    df = df.copy()
    logger.debug("â„¹ï¸ [Indicators] Ø§ÙƒØªØ´Ø§Ù Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø´Ù…ÙˆØ¹...")
    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙŠ ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ ØµÙ ÙˆØ§Ø­Ø¯
    df['Hammer'] = df.apply(is_hammer, axis=1)
    df['ShootingStar'] = df.apply(is_shooting_star, axis=1)
    df['Doji'] = df.apply(is_doji, axis=1)
    # df['SpinningTop'] = df.apply(is_spinning_top, axis=1) # ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØªÙ‡ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§Ø¨ØªÙ„Ø§Ø¹ ÙŠØªØ·Ù„Ø¨ Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„ØµÙ Ø§Ù„Ø³Ø§Ø¨Ù‚
    engulfing_values = [compute_engulfing(df, i) for i in range(len(df))]
    df['Engulfing'] = engulfing_values

    # ØªØ¬Ù…ÙŠØ¹ Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ø´Ù…ÙˆØ¹ Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ© ÙˆØ§Ù„Ø³Ù„Ø¨ÙŠØ© Ø§Ù„Ù‚ÙˆÙŠØ©
    # Ù„Ø§Ø­Ø¸: Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù‡Ù†Ø§ Ù‡ÙŠ 100 Ø£Ùˆ 0ØŒ Ø§Ù„ÙˆØ²Ù† Ø³ÙŠØ·Ø¨Ù‚ Ù„Ø§Ø­Ù‚Ù‹Ø§ ÙÙŠ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©
    df['BullishCandleSignal'] = df.apply(lambda row: 1 if (row['Hammer'] == 100 or row['Engulfing'] == 100) else 0, axis=1)
    df['BearishCandleSignal'] = df.apply(lambda row: 1 if (row['ShootingStar'] == -100 or row['Engulfing'] == -100) else 0, axis=1)

    # Ø­Ø°Ù Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ÙØ±Ø¯ÙŠØ© Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ø§Ø­Ù‚Ù‹Ø§
    # df.drop(columns=['Hammer', 'ShootingStar', 'Doji', 'Engulfing'], inplace=True, errors='ignore')
    logger.debug("âœ… [Indicators] ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø´Ù…ÙˆØ¹.")
    return df

# ---------------------- Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø£Ø®Ø±Ù‰ (Elliott, Swings, Volume) ----------------------
def detect_swings(prices: np.ndarray, order: int = SWING_ORDER) -> Tuple[List[Tuple[int, float]], List[Tuple[int, float]]]:
    """Ø§ÙƒØªØ´Ø§Ù Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ£Ø±Ø¬Ø­ (Ø§Ù„Ù‚Ù…Ù… ÙˆØ§Ù„Ù‚ÙŠØ¹Ø§Ù†) ÙÙŠ Ø³Ù„Ø³Ù„Ø© Ø²Ù…Ù†ÙŠØ© (numpy array)."""
    n = len(prices)
    if n < 2 * order + 1: return [], []

    maxima_indices = []
    minima_indices = []

    # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¨ØªØ¬Ù†Ø¨ Ø§Ù„Ø­Ù„Ù‚Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø·Ø±Ø§Ù ØºÙŠØ± Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©
    for i in range(order, n - order):
        window = prices[i - order : i + order + 1]
        center_val = prices[i]

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† NaN ÙÙŠ Ø§Ù„Ù†Ø§ÙØ°Ø©
        if np.isnan(window).any(): continue

        is_max = np.all(center_val >= window) # Ù‡Ù„ Ù‡Ùˆ Ø£ÙƒØ¨Ø± Ø£Ùˆ ÙŠØ³Ø§ÙˆÙŠ Ø§Ù„ÙƒÙ„ØŸ
        is_min = np.all(center_val <= window) # Ù‡Ù„ Ù‡Ùˆ Ø£ØµØºØ± Ø£Ùˆ ÙŠØ³Ø§ÙˆÙŠ Ø§Ù„ÙƒÙ„ØŸ
        # Ø§Ù„ØªØ£ÙƒØ¯ Ø£Ù†Ù‡ Ø§Ù„Ù‚Ù…Ø©/Ø§Ù„Ù‚Ø§Ø¹ Ø§Ù„ÙˆØ­ÙŠØ¯ ÙÙŠ Ø§Ù„Ù†Ø§ÙØ°Ø© (Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø± ÙÙŠ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ù…Ø³Ø·Ø­Ø©)
        is_unique_max = is_max and (np.sum(window == center_val) == 1)
        is_unique_min = is_min and (np.sum(window == center_val) == 1)

        if is_unique_max:
            # Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù‚Ù…Ø© Ù‚Ø±ÙŠØ¨Ø© Ø¬Ø¯Ù‹Ø§ (Ø¶Ù…Ù† Ù…Ø³Ø§ÙØ© order)
            if not maxima_indices or i > maxima_indices[-1] + order:
                 maxima_indices.append(i)
        elif is_unique_min:
            # Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù‚Ø§Ø¹ Ù‚Ø±ÙŠØ¨ Ø¬Ø¯Ù‹Ø§
            if not minima_indices or i > minima_indices[-1] + order:
                minima_indices.append(i)

    maxima = [(idx, prices[idx]) for idx in maxima_indices]
    minima = [(idx, prices[idx]) for idx in minima_indices]
    return maxima, minima

def detect_elliott_waves(df: pd.DataFrame, order: int = SWING_ORDER) -> List[Dict[str, Any]]:
    """Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø³ÙŠØ·Ø© Ù„ØªØ­Ø¯ÙŠØ¯ Ù…ÙˆØ¬Ø§Øª Ø¥Ù„ÙŠÙˆØª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ£Ø±Ø¬Ø­Ø§Øª Ù‡ÙŠØ³ØªÙˆØ¬Ø±Ø§Ù… MACD."""
    if 'macd_hist' not in df.columns or df['macd_hist'].isnull().all():
        logger.warning("âš ï¸ [Elliott] Ø¹Ù…ÙˆØ¯ 'macd_hist' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ø£Ùˆ ÙØ§Ø±Øº Ù„Ø­Ø³Ø§Ø¨ Ù…ÙˆØ¬Ø§Øª Ø¥Ù„ÙŠÙˆØª.")
        return []

    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚ÙŠÙ… ØºÙŠØ± Ø§Ù„ÙØ§Ø±ØºØ© ÙÙ‚Ø·
    macd_values = df['macd_hist'].dropna().values
    if len(macd_values) < 2 * order + 1:
         logger.warning("âš ï¸ [Elliott] Ø¨ÙŠØ§Ù†Ø§Øª MACD hist ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© NaN.")
         return []

    maxima, minima = detect_swings(macd_values, order=order)

    # Ø¯Ù…Ø¬ ÙˆØªØ±ØªÙŠØ¨ Ø¬Ù…ÙŠØ¹ Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ£Ø±Ø¬Ø­ Ø­Ø³Ø¨ Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ø£ØµÙ„ÙŠ
    # (ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø±Ø¨Ø· Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ø£ØµÙ„ÙŠ Ù…Ù† df Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© NaN)
    df_nonan_macd = df['macd_hist'].dropna()
    all_swings = sorted(
        [(df_nonan_macd.index[idx], val, 'max') for idx, val in maxima] +
        [(df_nonan_macd.index[idx], val, 'min') for idx, val in minima],
        key=lambda x: x[0] # Ø§Ù„ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ø²Ù…Ù† (Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ø£ØµÙ„ÙŠ)
    )

    waves = []
    wave_number = 1
    for timestamp, val, typ in all_swings:
        # Ø§Ù„ØªØµÙ†ÙŠÙ Ø¨Ø³ÙŠØ· Ø¬Ø¯Ù‹Ø§ Ù‡Ù†Ø§ØŒ Ù‚Ø¯ Ù„Ø§ ÙŠØªØ¨Ø¹ Ù‚ÙˆØ§Ø¹Ø¯ Ø¥Ù„ÙŠÙˆØª Ø¨Ø¯Ù‚Ø©
        wave_type = "Impulse" if (typ == 'max' and val > 0) or (typ == 'min' and val >= 0) else "Correction"
        waves.append({
            "wave": wave_number,
            "timestamp": str(timestamp),
            "macd_hist_value": float(val),
            "swing_type": typ,
            "classified_type": wave_type
        })
        wave_number += 1
    return waves


def fetch_recent_volume(symbol: str) -> float:
    """Ø¬Ù„Ø¨ Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø¨Ø§Ù„Ù€ USDT Ù„Ø¢Ø®Ø± 15 Ø¯Ù‚ÙŠÙ‚Ø© Ù„Ù„Ø±Ù…Ø² Ø§Ù„Ù…Ø­Ø¯Ø¯."""
    if not client:
         logger.error(f"âŒ [Data Volume] Ø¹Ù…ÙŠÙ„ Binance ØºÙŠØ± Ù…Ù‡ÙŠØ£ Ù„Ø¬Ù„Ø¨ Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ù„Ù€ {symbol}.")
         return 0.0
    try:
        logger.debug(f"â„¹ï¸ [Data Volume] Ø¬Ù„Ø¨ Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ (15 Ø¯Ù‚ÙŠÙ‚Ø©) Ù„Ù€ {symbol}...")
        # Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø© Ø§Ù„ÙˆØ§Ø­Ø¯Ø© Ù„Ø¢Ø®Ø± 15 Ø¯Ù‚ÙŠÙ‚Ø©
        klines = client.get_klines(symbol=symbol, interval=Client.KLINE_INTERVAL_1MINUTE, limit=15)
        if not klines or len(klines) < 15:
             logger.warning(f"âš ï¸ [Data Volume] Ø¨ÙŠØ§Ù†Ø§Øª 1m ØºÙŠØ± ÙƒØ§ÙÙŠØ© (Ø£Ù‚Ù„ Ù…Ù† 15 Ø´Ù…Ø¹Ø©) Ù„Ù„Ø²ÙˆØ¬ {symbol}.")
             return 0.0

        # Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø¨Ø§Ù„Ø¹Ù…Ù„Ø© Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø© (Quote Asset Volume) Ù‡Ùˆ Ø§Ù„Ø­Ù‚Ù„ Ø§Ù„Ø«Ø§Ù…Ù† (index 7)
        volume_usdt = sum(float(k[7]) for k in klines if len(k) > 7 and k[7])
        logger.debug(f"âœ… [Data Volume] Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ø¢Ø®Ø± 15 Ø¯Ù‚ÙŠÙ‚Ø© Ù„Ù„Ø²ÙˆØ¬ {symbol}: {volume_usdt:.2f} USDT")
        return volume_usdt
    except (BinanceAPIException, BinanceRequestException) as binance_err:
         logger.error(f"âŒ [Data Volume] Ø®Ø·Ø£ Ù…Ù† Binance API Ø£Ùˆ Ø§Ù„Ø´Ø¨ÙƒØ© Ø¹Ù†Ø¯ Ø¬Ù„Ø¨ Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ù„Ù€ {symbol}: {binance_err}")
         return 0.0
    except Exception as e:
        logger.error(f"âŒ [Data Volume] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø¬Ù„Ø¨ Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ù„Ù„Ø²ÙˆØ¬ {symbol}: {e}", exc_info=True)
        return 0.0

# ---------------------- Ø¯Ø§Ù„Ø© ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø´Ø§Ù…Ù„ ----------------------
def generate_performance_report() -> str:
    """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø£Ø¯Ø§Ø¡ Ø´Ø§Ù…Ù„ ÙˆÙ…ÙØµÙ„ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."""
    logger.info("â„¹ï¸ [Report] ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡...")
    if not check_db_connection() or not conn or not cur:
        return "âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ‚Ø±ÙŠØ±ØŒ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."
    try:
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… cursor Ø¬Ø¯ÙŠØ¯ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¯Ø§Ù„Ø© Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… Ø§Ù„ØªØ¯Ø§Ø®Ù„
        with conn.cursor() as report_cur: # ÙŠØ³ØªØ®Ø¯Ù… RealDictCursor
            # 1. Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©
            report_cur.execute("SELECT COUNT(*) AS count FROM signals WHERE achieved_target = FALSE AND hit_stop_loss = FALSE;")
            open_signals_count = (report_cur.fetchone() or {}).get('count', 0)

            # 2. Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø©
            report_cur.execute("""
                SELECT
                    COUNT(*) AS total_closed,
                    COUNT(CASE WHEN profit_percentage > 0 THEN 1 END) AS winning_signals,
                    COUNT(CASE WHEN profit_percentage < 0 THEN 1 END) AS losing_signals,
                    COUNT(CASE WHEN profit_percentage = 0 THEN 1 END) AS neutral_signals,
                    COALESCE(SUM(profit_percentage), 0) AS total_profit_pct,
                    COALESCE(AVG(profit_percentage), 0) AS avg_profit_pct,
                    COALESCE(SUM(CASE WHEN profit_percentage > 0 THEN profit_percentage ELSE 0 END), 0) AS gross_profit_pct,
                    COALESCE(SUM(CASE WHEN profit_percentage < 0 THEN profit_percentage ELSE 0 END), 0) AS gross_loss_pct,
                    COALESCE(AVG(CASE WHEN profit_percentage > 0 THEN profit_percentage END), 0) AS avg_win_pct,
                    COALESCE(AVG(CASE WHEN profit_percentage < 0 THEN profit_percentage END), 0) AS avg_loss_pct
                FROM signals
                WHERE achieved_target = TRUE OR hit_stop_loss = TRUE;
            """)
            closed_stats = report_cur.fetchone() or {} # Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø­Ø§Ù„Ø© Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù†ØªØ§Ø¦Ø¬

            total_closed = closed_stats.get('total_closed', 0)
            winning_signals = closed_stats.get('winning_signals', 0)
            losing_signals = closed_stats.get('losing_signals', 0)
            total_profit_pct = closed_stats.get('total_profit_pct', 0.0)
            gross_profit_pct = closed_stats.get('gross_profit_pct', 0.0)
            gross_loss_pct = closed_stats.get('gross_loss_pct', 0.0) # Ø³ØªÙƒÙˆÙ† Ø³Ø§Ù„Ø¨Ø© Ø£Ùˆ ØµÙØ±
            avg_win_pct = closed_stats.get('avg_win_pct', 0.0)
            avg_loss_pct = closed_stats.get('avg_loss_pct', 0.0) # Ø³ØªÙƒÙˆÙ† Ø³Ø§Ù„Ø¨Ø© Ø£Ùˆ ØµÙØ±

            # 3. Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù…Ø´ØªÙ‚Ø©
            win_rate = (winning_signals / total_closed * 100) if total_closed > 0 else 0.0
             # Profit Factor: Total Profit / Absolute Total Loss
            profit_factor = (gross_profit_pct / abs(gross_loss_pct)) if gross_loss_pct != 0 else float('inf')

        # 4. ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        report = (
            f"ğŸ“Š *ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø´Ø§Ù…Ù„:*\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"ğŸ“ˆ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø© Ø­Ø§Ù„ÙŠÙ‹Ø§: *{open_signals_count}*\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"ğŸ“‰ *Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø©:*\n"
            f"  â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø©: *{total_closed}*\n"
            f"  âœ… Ø¥Ø´Ø§Ø±Ø§Øª Ø±Ø§Ø¨Ø­Ø©: *{winning_signals}*\n"
            f"  âŒ Ø¥Ø´Ø§Ø±Ø§Øª Ø®Ø§Ø³Ø±Ø©: *{losing_signals}*\n"
            f"  â€¢ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø±Ø¨Ø­ (Win Rate): *{win_rate:.2f}%*\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"ğŸ’° *Ø§Ù„Ø±Ø¨Ø­ÙŠØ©:*\n"
            f"  â€¢ ØµØ§ÙÙŠ Ø§Ù„Ø±Ø¨Ø­/Ø§Ù„Ø®Ø³Ø§Ø±Ø© (Ø¥Ø¬Ù…Ø§Ù„ÙŠ %): *{total_profit_pct:+.2f}%*\n"
            f"  â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø±Ø¨Ø­ (%): *{gross_profit_pct:+.2f}%*\n"
            f"  â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø®Ø³Ø§Ø±Ø© (%): *{gross_loss_pct:.2f}%*\n"
            f"  â€¢ Ù…ØªÙˆØ³Ø· Ø±Ø¨Ø­ Ø§Ù„ØµÙÙ‚Ø© Ø§Ù„Ø±Ø§Ø¨Ø­Ø©: *{avg_win_pct:+.2f}%*\n"
            f"  â€¢ Ù…ØªÙˆØ³Ø· Ø®Ø³Ø§Ø±Ø© Ø§Ù„ØµÙÙ‚Ø© Ø§Ù„Ø®Ø§Ø³Ø±Ø©: *{avg_loss_pct:.2f}%*\n"
            f"  â€¢ Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø±Ø¨Ø­ (Profit Factor): *{'âˆ' if profit_factor == float('inf') else f'{profit_factor:.2f}'}*\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"ğŸ•°ï¸ _Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø­ØªÙ‰: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}_"
        )
        logger.info("âœ… [Report] ØªÙ… ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¨Ù†Ø¬Ø§Ø­.")
        return report

    except psycopg2.Error as db_err:
        logger.error(f"âŒ [Report] Ø®Ø·Ø£ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù†Ø¯ ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡: {db_err}")
        if conn: conn.rollback() # ØªØ±Ø§Ø¬Ø¹ Ø¹Ù† Ø£ÙŠ Ù…Ø¹Ø§Ù…Ù„Ø© Ù‚Ø¯ ØªÙƒÙˆÙ† Ù…ÙØªÙˆØ­Ø©
        return "âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù†Ø¯ ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡."
    except Exception as e:
        logger.error(f"âŒ [Report] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡: {e}", exc_info=True)
        return "âŒ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡."

# ---------------------- Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø­Ø§ÙØ¸Ø© (Ø§Ù„Ù…Ø¹Ø¯Ù„Ø©) ----------------------
class ConservativeTradingStrategy:
    """ØªØºÙ„ÙŠÙ Ù…Ù†Ø·Ù‚ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„ØªØ¯Ø§ÙˆÙ„ ÙˆØ§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ù‡Ø§ Ù…Ø¹ Ù†Ø¸Ø§Ù… Ù†Ù‚Ø§Ø·."""

    def __init__(self, symbol: str):
        self.symbol = symbol
        # Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
        self.required_cols_indicators = [
            'open', 'high', 'low', 'close', 'volume', # Ø£Ø³Ø§Ø³ÙŠØ©
            'ema_trend', 'rsi', 'atr', 'bb_upper', 'bb_lower', 'bb_middle',
            'macd', 'macd_signal', 'macd_hist',
            'adx', 'di_plus', 'di_minus',
            'vwap', 'obv', 'supertrend', 'supertrend_trend',
            'BullishCandleSignal', 'BearishCandleSignal' # Ù…Ù† Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø´Ù…ÙˆØ¹
        ]
        # Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„ØªÙˆÙ„ÙŠØ¯ Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø´Ø±Ø§Ø¡ (Ù…Ø¹ OBV Ø§Ù„Ø³Ø§Ø¨Ù‚)
        self.required_cols_buy_signal = [
            'close', 'ema_trend', 'rsi', 'atr', 'macd', 'macd_signal',
            'supertrend_trend', 'adx', 'di_plus', 'di_minus', 'vwap', 'bb_upper',
            'BullishCandleSignal', 'obv'
        ]

        # =====================================================================
        # --- Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ù‚Ø§Ø· (Ø§Ù„Ø£ÙˆØ²Ø§Ù†) Ù„Ø´Ø±ÙˆØ· Ø§Ù„Ø´Ø±Ø§Ø¡ ---
        # Ù‚Ù… Ø¨ØªØ¹Ø¯ÙŠÙ„ Ù‡Ø°Ù‡ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ù„ØªØ¹ÙƒØ³ Ø£Ù‡Ù…ÙŠØ© ÙƒÙ„ Ø´Ø±Ø· ÙÙŠ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØªÙƒ
        # =====================================================================
        self.condition_weights = {
            'ema_up': 2.0,          # Ø§Ù„Ø³Ø¹Ø± ÙÙˆÙ‚ EMA
            'supertrend_up': 2.5,   # SuperTrend ØµØ§Ø¹Ø¯ (Ø£Ù‡Ù…)
            'above_vwap': 1.5,      # Ø§Ù„Ø³Ø¹Ø± ÙÙˆÙ‚ VWAP
            'macd_bullish': 2.0,    # ØªÙ‚Ø§Ø·Ø¹ MACD Ø¥ÙŠØ¬Ø§Ø¨ÙŠ
            'adx_trending_bullish': 2.0, # ADX Ù‚ÙˆÙŠ Ùˆ DI+ Ø£Ø¹Ù„Ù‰
            'rsi_ok': 1.0,          # RSI ÙÙŠ Ù…Ù†Ø·Ù‚Ø© Ù…Ù‚Ø¨ÙˆÙ„Ø© (Ù„ÙŠØ³ Ø´Ø±Ø§Ø¡ Ù…ÙØ±Ø·)
            'bullish_candle': 1.5,  # ÙˆØ¬ÙˆØ¯ Ø´Ù…Ø¹Ø© Ø§Ø¨ØªÙ„Ø§Ø¹ Ø£Ùˆ Ù…Ø·Ø±Ù‚Ø©
            'not_bb_extreme': 0.5,  # Ø§Ù„Ø³Ø¹Ø± Ù„ÙŠØ³ Ø¹Ù†Ø¯ Ù†Ø·Ø§Ù‚ Ø¨ÙˆÙ„ÙŠÙ†Ø¬Ø± Ø§Ù„Ø¹Ù„ÙˆÙŠ (Ø£Ù‚Ù„ Ø£Ù‡Ù…ÙŠØ©)
            'obv_rising': 2.0       # OBV ÙŠØ±ØªÙØ¹ (ØªØ£ÙƒÙŠØ¯ Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„)
        }
        # =====================================================================

        # Ø­Ø³Ø§Ø¨ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙƒÙ†Ø©
        self.total_possible_score = sum(self.condition_weights.values())

        # =====================================================================
        # --- Ø¹ØªØ¨Ø© Ø¯Ø±Ø¬Ø© Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (ÙƒÙ†Ø³Ø¨Ø© Ù…Ø¦ÙˆÙŠØ©) ---
        # Ù…Ø«Ø§Ù„: 70% ØªØ¹Ù†ÙŠ Ø£Ù† Ø§Ù„Ø¥Ø´Ø§Ø±Ø© ÙŠØ¬Ø¨ Ø£Ù† ØªØ­Ù‚Ù‚ 70% Ù…Ù† Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙƒÙ†Ø©
        # =====================================================================
        self.min_score_threshold_pct = 0.70 # 70%
        self.min_signal_score = self.total_possible_score * self.min_score_threshold_pct
        # =====================================================================

    def populate_indicators(self, df: pd.DataFrame) -> Optional[pd.DataFrame]:
        """Ø­Ø³Ø§Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©."""
        logger.debug(f"â„¹ï¸ [Strategy {self.symbol}] Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª...")
        # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø£Ø·ÙˆÙ„ ÙØªØ±Ø© Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„Ù…Ø¤Ø´Ø±Ø§Øª
        min_len_required = max(EMA_PERIOD, RSI_PERIOD, ENTRY_ATR_PERIOD, BOLLINGER_WINDOW, MACD_SLOW, ADX_PERIOD*2, SUPERTREND_PERIOD, LOOKBACK_FOR_SWINGS) + 5 # Ø¥Ø¶Ø§ÙØ© Ù‡Ø§Ù…Ø´

        if len(df) < min_len_required:
            logger.warning(f"âš ï¸ [Strategy {self.symbol}] DataFrame Ù‚ØµÙŠØ± Ø¬Ø¯Ù‹Ø§ ({len(df)} < {min_len_required}) Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª.")
            return None

        try:
            df_calc = df.copy()
            # ---- ØªØ³Ù„Ø³Ù„ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ù…Ù‡Ù… (Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ÙŠØ§Øª) ----
            # ATR Ù…Ø·Ù„ÙˆØ¨ Ù„Ù€ SuperTrend Ùˆ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©/Ø§Ù„Ù‡Ø¯Ù
            df_calc = calculate_atr_indicator(df_calc, ENTRY_ATR_PERIOD)
            # SuperTrend ÙŠØ­ØªØ§Ø¬ ATR Ù…Ø­Ø³ÙˆØ¨ Ø¨ÙØªØ±ØªÙ‡ Ø§Ù„Ø®Ø§ØµØ©
            df_calc = calculate_supertrend(df_calc, SUPERTREND_PERIOD, SUPERTREND_MULTIPLIER)
            # Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
            df_calc['ema_trend'] = calculate_ema(df_calc['close'], EMA_PERIOD)
            df_calc = calculate_rsi_indicator(df_calc, RSI_PERIOD)
            df_calc = calculate_bollinger_bands(df_calc, BOLLINGER_WINDOW, BOLLINGER_STD_DEV)
            df_calc = calculate_macd(df_calc, MACD_FAST, MACD_SLOW, MACD_SIGNAL)
            adx_df = calculate_adx(df_calc, ADX_PERIOD) # Ø­Ø³Ø§Ø¨ ADX ÙÙŠ DataFrame Ù…Ù†ÙØµÙ„ Ù…Ø¤Ù‚ØªÙ‹Ø§
            df_calc = df_calc.join(adx_df) # Ø¶Ù… Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            df_calc = calculate_vwap(df_calc)
            df_calc = calculate_obv(df_calc)
            df_calc = detect_candlestick_patterns(df_calc) # ÙŠØ­Ø³Ø¨ BullishCandleSignal

            # --- Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ø­Ø³Ø§Ø¨ ---
            missing_cols = [col for col in self.required_cols_indicators if col not in df_calc.columns]
            if missing_cols:
                 logger.error(f"âŒ [Strategy {self.symbol}] Ø£Ø¹Ù…Ø¯Ø© Ù…Ø¤Ø´Ø±Ø§Øª Ù…Ø·Ù„ÙˆØ¨Ø© Ù…ÙÙ‚ÙˆØ¯Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ø­Ø³Ø§Ø¨: {missing_cols}")
                 logger.debug(f"Columns present: {df_calc.columns.tolist()}")
                 return None

            # --- Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ NaN Ø¨Ø¹Ø¯ Ø­Ø³Ø§Ø¨ *ÙƒÙ„* Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª ---
            initial_len = len(df_calc)
            # Ø­Ø°Ù Ø§Ù„ØµÙÙˆÙ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ NaN ÙÙŠ Ø£ÙŠ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
            df_cleaned = df_calc.dropna(subset=self.required_cols_indicators).copy()
            dropped_count = initial_len - len(df_cleaned)

            if dropped_count > 0:
                 logger.debug(f"â„¹ï¸ [Strategy {self.symbol}] ØªÙ… Ø­Ø°Ù {dropped_count} ØµÙ Ø¨Ø³Ø¨Ø¨ NaN ÙÙŠ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª.")
            if df_cleaned.empty:
                logger.warning(f"âš ï¸ [Strategy {self.symbol}] DataFrame ÙØ§Ø±Øº Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© NaN Ù…Ù† Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª.")
                return None

            latest = df_cleaned.iloc[-1]
            logger.debug(f"âœ… [Strategy {self.symbol}] ØªÙ… Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª. Ø¢Ø®Ø± Ø§ØªØ¬Ø§Ù‡ SuperTrend: {latest.get('supertrend_trend', 'N/A')}, ADX: {latest.get('adx', np.nan):.2f}")
            return df_cleaned

        except KeyError as ke:
             logger.error(f"âŒ [Strategy {self.symbol}] Ø®Ø·Ø£: Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ø£Ø«Ù†Ø§Ø¡ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª: {ke}", exc_info=True)
             return None
        except Exception as e:
            logger.error(f"âŒ [Strategy {self.symbol}] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª: {e}", exc_info=True)
            return None

    def generate_buy_signal(self, df_processed: pd.DataFrame) -> Optional[Dict[str, Any]]:
        """
        ØªÙˆÙ„ÙŠØ¯ Ø¥Ø´Ø§Ø±Ø© Ø´Ø±Ø§Ø¡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ DataFrame Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ ÙˆÙ†Ø¸Ø§Ù… Ø§Ù„Ù†Ù‚Ø§Ø·.
        """
        logger.debug(f"â„¹ï¸ [Strategy {self.symbol}] ØªÙˆÙ„ÙŠØ¯ Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø´Ø±Ø§Ø¡...")

        # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© DataFrame Ø§Ù„Ù…Ø¯Ø®Ù„ ÙˆØ§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„Ø¥Ø´Ø§Ø±Ø©
        if df_processed is None or df_processed.empty or len(df_processed) < 2: # Ù†Ø­ØªØ§Ø¬ ØµÙÙŠÙ† Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© (OBV)
            logger.warning(f"âš ï¸ [Strategy {self.symbol}] DataFrame ÙØ§Ø±Øº Ø£Ùˆ Ù‚ØµÙŠØ± Ø¬Ø¯Ù‹Ø§ (<2)ØŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªÙˆÙ„ÙŠØ¯ Ø¥Ø´Ø§Ø±Ø©.")
            return None
        missing_cols = [col for col in self.required_cols_buy_signal if col not in df_processed.columns]
        if missing_cols:
            logger.warning(f"âš ï¸ [Strategy {self.symbol}] DataFrame ÙŠÙØªÙ‚Ø¯ Ø£Ø¹Ù…Ø¯Ø© Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„Ø¥Ø´Ø§Ø±Ø©: {missing_cols}.")
            return None

        # 2. ÙØ­Øµ ØªØ±Ù†Ø¯ Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ† (Ø´Ø±Ø· Ø£ÙˆÙ„ÙŠ)
        btc_trend = get_btc_trend_4h()
        if "Ù‡Ø¨ÙˆØ·" in btc_trend:
            logger.info(f"â„¹ï¸ [Strategy {self.symbol}] Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ù…ØªÙˆÙ‚Ù Ù…Ø¤Ù‚ØªÙ‹Ø§ Ø¨Ø³Ø¨Ø¨ ØªØ±Ù†Ø¯ Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ† Ø§Ù„Ù‡Ø§Ø¨Ø· ({btc_trend}).")
            return None
        elif "N/A" in btc_trend:
             logger.warning(f"âš ï¸ [Strategy {self.symbol}] Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­Ø¯ÙŠØ¯ ØªØ±Ù†Ø¯ Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ†ØŒ Ø³ÙŠØªÙ… ØªØ¬Ø§Ù‡Ù„ Ù‡Ø°Ø§ Ø§Ù„Ø´Ø±Ø·.")

        # 3. Ø§Ø³ØªØ®Ù„Ø§Øµ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ù…Ø¹Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø© ÙˆØ§Ù„Ø³Ø§Ø¨Ù‚Ø© ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† NaN
        last_row = df_processed.iloc[-1]
        prev_row = df_processed.iloc[-2] # Ù†Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØµÙ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù„Ù…Ù‚Ø§Ø±Ù†Ø© OBV

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† NaN ÙÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„ØµÙ Ø§Ù„Ø£Ø®ÙŠØ±
        last_row_check = last_row[self.required_cols_buy_signal]
        if last_row_check.isnull().any():
            nan_cols = last_row_check[last_row_check.isnull()].index.tolist()
            logger.warning(f"âš ï¸ [Strategy {self.symbol}] Ø§Ù„ØµÙ Ø§Ù„Ø£Ø®ÙŠØ± ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ NaN ÙÙŠ Ø£Ø¹Ù…Ø¯Ø© Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„Ø¥Ø´Ø§Ø±Ø©: {nan_cols}.")
            return None
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† NaN ÙÙŠ OBV Ù„Ù„ØµÙ Ø§Ù„Ø³Ø§Ø¨Ù‚
        if pd.isna(prev_row['obv']):
           logger.warning(f"âš ï¸ [Strategy {self.symbol}] Ù‚ÙŠÙ…Ø© OBV Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ù‡ÙŠ NaN. Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§ØªØ¬Ø§Ù‡ OBV.")
           return None

        # 4. ØªØ·Ø¨ÙŠÙ‚ Ø´Ø±ÙˆØ· Ø§Ù„Ø´Ø±Ø§Ø¡ ÙˆØ­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ø±Ø¬Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£ÙˆØ²Ø§Ù†
        signal_details = {}
        current_score = 0.0

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙƒÙ„ Ø´Ø±Ø· ÙˆØ¥Ø¶Ø§ÙØ© ÙˆØ²Ù†Ù‡ Ø¥Ù„Ù‰ Ø§Ù„Ø¯Ø±Ø¬Ø© Ø¥Ø°Ø§ ØªØ­Ù‚Ù‚
        if last_row['close'] > last_row['ema_trend']:
            current_score += self.condition_weights['ema_up']
            signal_details['EMA'] = f'Above {EMA_PERIOD} EMA (+{self.condition_weights["ema_up"]})'
        if last_row['supertrend_trend'] == 1:
            current_score += self.condition_weights['supertrend_up']
            signal_details['SuperTrend'] = f'Up Trend (+{self.condition_weights["supertrend_up"]})'
        if last_row['close'] > last_row['vwap']:
            current_score += self.condition_weights['above_vwap']
            signal_details['VWAP'] = f'Above VWAP (+{self.condition_weights["above_vwap"]})'
        if last_row['macd'] > last_row['macd_signal']:
            current_score += self.condition_weights['macd_bullish']
            signal_details['MACD'] = f'Bullish Cross (+{self.condition_weights["macd_bullish"]})'
        if last_row['adx'] > 20 and last_row['di_plus'] > last_row['di_minus']:
            current_score += self.condition_weights['adx_trending_bullish']
            signal_details['ADX/DI'] = f'Trending Bullish (ADX:{last_row["adx"]:.1f}, DI+>DI-) (+{self.condition_weights["adx_trending_bullish"]})'
        if last_row['rsi'] < RSI_OVERBOUGHT and last_row['rsi'] > RSI_OVERSOLD: # Ø§Ù„ØªØ£ÙƒØ¯ Ø£Ù†Ù‡ Ù„ÙŠØ³ Ø´Ø±Ø§Ø¡ Ø£Ùˆ Ø¨ÙŠØ¹ Ù…ÙØ±Ø·
            current_score += self.condition_weights['rsi_ok']
            signal_details['RSI'] = f'OK ({RSI_OVERSOLD}<{last_row["rsi"]:.1f}<{RSI_OVERBOUGHT}) (+{self.condition_weights["rsi_ok"]})'
        if last_row['BullishCandleSignal'] == 1: # Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¢Ù† 0 Ø£Ùˆ 1
            current_score += self.condition_weights['bullish_candle']
            signal_details['Candle'] = f'Bullish Pattern (+{self.condition_weights["bullish_candle"]})'
        if last_row['close'] < last_row['bb_upper']:
            current_score += self.condition_weights['not_bb_extreme']
            signal_details['Bollinger'] = f'Not at Upper Band (+{self.condition_weights["not_bb_extreme"]})'
        if last_row['obv'] > prev_row['obv']:
            current_score += self.condition_weights['obv_rising']
            signal_details['OBV'] = f'Rising (+{self.condition_weights["obv_rising"]})'

        # --- Ù‚Ø±Ø§Ø± Ø§Ù„Ø´Ø±Ø§Ø¡ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¯Ø±Ø¬Ø© ---
        if current_score < self.min_signal_score:
            logger.debug(f"â„¹ï¸ [Strategy {self.symbol}] Ù„Ù… ØªØªØ­Ù‚Ù‚ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (Score: {current_score:.2f} / {self.total_possible_score:.2f}, Threshold: {self.min_signal_score:.2f}).")
            return None # Ù„Ù… ØªØªØ­Ù‚Ù‚ Ø§Ù„Ø´Ø±ÙˆØ·

        # 5. ÙØ­Øµ Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ (Ø§Ù„Ø³ÙŠÙˆÙ„Ø©) - ÙŠØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡Ùˆ
        volume_recent = fetch_recent_volume(self.symbol)
        if volume_recent < MIN_VOLUME_15M_USDT:
            logger.info(f"â„¹ï¸ [Strategy {self.symbol}] Ø§Ù„Ø³ÙŠÙˆÙ„Ø© ({volume_recent:,.0f} USDT) Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ ({MIN_VOLUME_15M_USDT:,.0f} USDT). ØªÙ… Ø±ÙØ¶ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©.")
            return None

        # 6. Ø­Ø³Ø§Ø¨ Ø§Ù„Ù‡Ø¯Ù ÙˆÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ATR - ÙŠØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡Ùˆ
        current_price = last_row['close']
        current_atr = last_row.get('atr')

        # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù…Ø¶Ø§Ø¹ÙØ§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù‚ÙˆØ© ADX (ÙŠÙ…ÙƒÙ† Ø§Ù„Ø¥Ø¨Ù‚Ø§Ø¡ Ø¹Ù„ÙŠÙ‡ Ø£Ùˆ ØªØ¹Ø¯ÙŠÙ„Ù‡)
        adx_val_sig = last_row.get('adx', 0)
        if adx_val_sig > 25: # ØªØ±Ù†Ø¯ Ù‚ÙˆÙŠ
            target_multiplier = ENTRY_ATR_MULTIPLIER # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø¹Ø¯Ù„Ø©
            stop_loss_multiplier = ENTRY_ATR_MULTIPLIER * 0.8 # ÙŠÙ…ÙƒÙ† ØªØ¹Ø¯ÙŠÙ„ Ù…Ø¶Ø§Ø¹Ù Ø§Ù„ÙˆÙ‚Ù Ù„Ù„ØªØ±Ù†Ø¯ Ø§Ù„Ù‚ÙˆÙŠ
            signal_details['SL_Target_Mode'] = f'Strong Trend (ADX {adx_val_sig:.1f})'
        else: # ØªØ±Ù†Ø¯ Ø£Ø¶Ø¹Ù Ø£Ùˆ ØºÙŠØ± ÙˆØ§Ø¶Ø­
            target_multiplier = ENTRY_ATR_MULTIPLIER
            stop_loss_multiplier = ENTRY_ATR_MULTIPLIER
            signal_details['SL_Target_Mode'] = f'Standard (ADX {adx_val_sig:.1f})'

        initial_target = current_price + (target_multiplier * current_atr)
        initial_stop_loss = current_price - (stop_loss_multiplier * current_atr)

        # Ø¶Ù…Ø§Ù† Ø£Ù† ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ù„Ø§ ÙŠØ³Ø§ÙˆÙŠ ØµÙØ±Ù‹Ø§ Ø£Ùˆ Ø³Ø§Ù„Ø¨Ù‹Ø§
        if initial_stop_loss <= 0:
            min_sl_price = current_price * (1 - 0.10) # Ù…Ø«Ø§Ù„: 10% ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰ Ù„Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
            initial_stop_loss = max(min_sl_price, current_price * 0.001)
            logger.warning(f"âš ï¸ [Strategy {self.symbol}] ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ù…Ø­Ø³ÙˆØ¨ ({initial_stop_loss}) ØºÙŠØ± ØµØ§Ù„Ø­. ØªÙ… ØªØ¹Ø¯ÙŠÙ„Ù‡ Ø¥Ù„Ù‰ {initial_stop_loss:.8f}")
            signal_details['Warning'] = f'Initial SL adjusted (was <= 0, set to {initial_stop_loss:.8f})'

        # 7. ÙØ­Øµ Ù‡Ø§Ù…Ø´ Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„Ø£Ø¯Ù†Ù‰ - ÙŠØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡Ùˆ
        profit_margin_pct = ((initial_target / current_price) - 1) * 100 if current_price > 0 else 0
        if profit_margin_pct < MIN_PROFIT_MARGIN_PCT:
            logger.info(f"â„¹ï¸ [Strategy {self.symbol}] Ù‡Ø§Ù…Ø´ Ø§Ù„Ø±Ø¨Ø­ ({profit_margin_pct:.2f}%) Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ({MIN_PROFIT_MARGIN_PCT:.2f}%). ØªÙ… Ø±ÙØ¶ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©.")
            return None

        # 8. ØªØ¬Ù…ÙŠØ¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù…Ø¹ Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…ÙˆØ²ÙˆÙ†Ø©
        signal_output = {
            'symbol': self.symbol,
            'entry_price': float(f"{current_price:.8g}"),
            'initial_target': float(f"{initial_target:.8g}"),
            'initial_stop_loss': float(f"{initial_stop_loss:.8g}"),
            'current_target': float(f"{initial_target:.8g}"),
            'current_stop_loss': float(f"{initial_stop_loss:.8g}"),
            'r2_score': float(f"{current_score:.2f}"), # ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…ÙˆØ²ÙˆÙ†Ø© Ù‡Ù†Ø§
            'strategy_name': 'Conservative_Weighted', # ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ù„ÙŠØ¹ÙƒØ³ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„
            'signal_details': signal_details, # ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø´Ø±ÙˆØ· Ø§Ù„Ù…Ø­Ù‚Ù‚Ø© ÙˆØ£ÙˆØ²Ø§Ù†Ù‡Ø§
            'volume_15m': volume_recent,
            'trade_value': TRADE_VALUE,
            'total_possible_score': float(f"{self.total_possible_score:.2f}") # Ø¥Ø¶Ø§ÙØ© Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙƒÙ†Ø©
        }

        logger.info(f"âœ… [Strategy {self.symbol}] Ø¥Ø´Ø§Ø±Ø© Ø´Ø±Ø§Ø¡ Ù…Ø¤ÙƒØ¯Ø©. Ø§Ù„Ø³Ø¹Ø±: {current_price:.6f}, Score: {current_score:.2f}/{self.total_possible_score:.2f}, ATR: {current_atr:.6f}, Volume: {volume_recent:,.0f}")
        return signal_output

# ---------------------- Ø¯ÙˆØ§Ù„ Telegram ----------------------
def send_telegram_message(target_chat_id: str, text: str, reply_markup: Optional[Dict] = None, parse_mode: str = 'Markdown', disable_web_page_preview: bool = True, timeout: int = 20) -> Optional[Dict]:
    """Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ø¹Ø¨Ø± Telegram Bot API Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£ÙØ¶Ù„ Ù„Ù„Ø£Ø®Ø·Ø§Ø¡."""
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {
        'chat_id': str(target_chat_id),
        'text': text,
        'parse_mode': parse_mode,
        'disable_web_page_preview': disable_web_page_preview
    }
    if reply_markup:
        try:
            payload['reply_markup'] = json.dumps(convert_np_values(reply_markup))
        except (TypeError, ValueError) as json_err:
             logger.error(f"âŒ [Telegram] ÙØ´Ù„ ØªØ­ÙˆÙŠÙ„ reply_markup Ø¥Ù„Ù‰ JSON: {json_err} - Markup: {reply_markup}")
             return None

    logger.debug(f"â„¹ï¸ [Telegram] Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ø¥Ù„Ù‰ {target_chat_id}...")
    try:
        response = requests.post(url, json=payload, timeout=timeout)
        response.raise_for_status()
        logger.info(f"âœ… [Telegram] ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù„Ù‰ {target_chat_id}.")
        return response.json()
    except requests.exceptions.Timeout:
         logger.error(f"âŒ [Telegram] ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¥Ù„Ù‰ {target_chat_id} (Timeout).")
         return None
    except requests.exceptions.HTTPError as http_err:
        logger.error(f"âŒ [Telegram] ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¥Ù„Ù‰ {target_chat_id} (HTTP Error: {http_err.response.status_code}).")
        try:
            error_details = http_err.response.json()
            logger.error(f"âŒ [Telegram] ØªÙØ§ØµÙŠÙ„ Ø®Ø·Ø£ API: {error_details}")
        except json.JSONDecodeError:
            logger.error(f"âŒ [Telegram] Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† ÙÙƒ ØªØ´ÙÙŠØ± Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø®Ø·Ø£: {http_err.response.text}")
        return None
    except requests.exceptions.RequestException as req_err:
        logger.error(f"âŒ [Telegram] ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¥Ù„Ù‰ {target_chat_id} (Request Error): {req_err}")
        return None
    except Exception as e:
         logger.error(f"âŒ [Telegram] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø©: {e}", exc_info=True)
         return None

def send_telegram_alert(signal_data: Dict[str, Any], timeframe: str) -> None:
    """ØªÙ†Ø³ÙŠÙ‚ ÙˆØ¥Ø±Ø³Ø§Ù„ ØªÙ†Ø¨ÙŠÙ‡ Ø¥Ø´Ø§Ø±Ø© ØªØ¯Ø§ÙˆÙ„ Ø¬Ø¯ÙŠØ¯Ø© Ø¥Ù„Ù‰ Telegram Ù…Ø¹ Ø¹Ø±Ø¶ Ø§Ù„Ø¯Ø±Ø¬Ø©."""
    logger.debug(f"â„¹ï¸ [Telegram Alert] ØªÙ†Ø³ÙŠÙ‚ ÙˆØ¥Ø±Ø³Ø§Ù„ ØªÙ†Ø¨ÙŠÙ‡ Ù„Ù„Ø¥Ø´Ø§Ø±Ø©: {signal_data.get('symbol', 'N/A')}")
    try:
        entry_price = float(signal_data['entry_price'])
        target_price = float(signal_data['initial_target'])
        stop_loss_price = float(signal_data['initial_stop_loss'])
        symbol = signal_data['symbol']
        strategy_name = signal_data.get('strategy_name', 'N/A')
        signal_score = signal_data.get('r2_score', 0.0) # Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…ÙˆØ²ÙˆÙ†Ø©
        total_possible_score = signal_data.get('total_possible_score', 10.0) # Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù‚Ø¯ ØªØ­ØªØ§Ø¬ Ù„Ù„ØªØ¹Ø¯ÙŠÙ„
        volume_15m = signal_data.get('volume_15m', 0.0)
        trade_value_signal = signal_data.get('trade_value', TRADE_VALUE)

        profit_pct = ((target_price / entry_price) - 1) * 100 if entry_price > 0 else 0
        loss_pct = ((stop_loss_price / entry_price) - 1) * 100 if entry_price > 0 else 0
        profit_usdt = trade_value_signal * (profit_pct / 100)
        loss_usdt = abs(trade_value_signal * (loss_pct / 100))

        timestamp_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        safe_symbol = symbol.replace('_', '\\_').replace('*', '\\*').replace('[', '\\[').replace('`', '\\`')

        fear_greed = get_fear_greed_index()
        btc_trend = get_btc_trend_4h()

        # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù…Ø¹ Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…ÙˆØ²ÙˆÙ†Ø©
        message = (
            f"ğŸ’¡ *Ø¥Ø´Ø§Ø±Ø© ØªØ¯Ø§ÙˆÙ„ Ø¬Ø¯ÙŠØ¯Ø© ({strategy_name.replace('_', ' ').title()})* ğŸ’¡\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"ğŸª™ **Ø§Ù„Ø²ÙˆØ¬:** `{safe_symbol}`\n"
            f"ğŸ“ˆ **Ù†ÙˆØ¹ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©:** Ø´Ø±Ø§Ø¡ (Long)\n"
            f"ğŸ•°ï¸ **Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ:** {timeframe}\n"
            # --- ØªØ¹Ø¯ÙŠÙ„ Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø¯Ø±Ø¬Ø© ---
            f"ğŸ“Š **Ù‚ÙˆØ© Ø§Ù„Ø¥Ø´Ø§Ø±Ø© (Score):** *{signal_score:.1f} / {total_possible_score:.1f}*\n"
            f"ğŸ’§ **Ø³ÙŠÙˆÙ„Ø© (15 Ø¯Ù‚ÙŠÙ‚Ø©):** {volume_15m:,.0f} USDT\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"â¡ï¸ **Ø³Ø¹Ø± Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù…Ù‚ØªØ±Ø­:** `${entry_price:,.8g}`\n"
            f"ğŸ¯ **Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø£ÙˆÙ„ÙŠ:** `${target_price:,.8g}` ({profit_pct:+.2f}% / â‰ˆ ${profit_usdt:+.2f})\n"
            f"ğŸ›‘ **ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠ:** `${stop_loss_price:,.8g}` ({loss_pct:.2f}% / â‰ˆ ${loss_usdt:.2f})\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"ğŸ˜¨/ğŸ¤‘ **Ù…Ø¤Ø´Ø± Ø§Ù„Ø®ÙˆÙ ÙˆØ§Ù„Ø·Ù…Ø¹:** {fear_greed}\n"
            f"â‚¿ **Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ† (4H):** {btc_trend}\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"â° {timestamp_str}"
        )

        reply_markup = {
            "inline_keyboard": [
                [{"text": "ğŸ“Š Ø¹Ø±Ø¶ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡", "callback_data": "get_report"}]
            ]
        }

        send_telegram_message(CHAT_ID, message, reply_markup=reply_markup, parse_mode='Markdown')

    except KeyError as ke:
        logger.error(f"âŒ [Telegram Alert] Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø´Ø§Ø±Ø© ØºÙŠØ± ÙƒØ§Ù…Ù„Ø© Ù„Ù„Ø²ÙˆØ¬ {signal_data.get('symbol', 'N/A')}: Ù…ÙØªØ§Ø­ Ù…ÙÙ‚ÙˆØ¯ {ke}", exc_info=True)
    except Exception as e:
        logger.error(f"âŒ [Telegram Alert] ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ ØªÙ†Ø¨ÙŠÙ‡ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù„Ù„Ø²ÙˆØ¬ {signal_data.get('symbol', 'N/A')}: {e}", exc_info=True)

def send_tracking_notification(details: Dict[str, Any]) -> None:
    """ØªÙ†Ø³ÙŠÙ‚ ÙˆØ¥Ø±Ø³Ø§Ù„ ØªÙ†Ø¨ÙŠÙ‡Ø§Øª ØªÙ„ÙŠØ¬Ø±Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø© Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„ØªØªØ¨Ø¹."""
    symbol = details.get('symbol', 'N/A')
    signal_id = details.get('id', 'N/A')
    notification_type = details.get('type', 'unknown')
    message = ""
    safe_symbol = symbol.replace('_', '\\_').replace('*', '\\*').replace('[', '\\[').replace('`', '\\`')
    closing_price = details.get('closing_price', 0.0)
    profit_pct = details.get('profit_pct', 0.0)
    current_price = details.get('current_price', 0.0)
    atr_value = details.get('atr_value', 0.0)
    new_stop_loss = details.get('new_stop_loss', 0.0)
    old_stop_loss = details.get('old_stop_loss', 0.0)

    logger.debug(f"â„¹ï¸ [Notification] ØªÙ†Ø³ÙŠÙ‚ Ø¥Ø´Ø¹Ø§Ø± ØªØªØ¨Ø¹: ID={signal_id}, Type={notification_type}, Symbol={symbol}")

    if notification_type == 'target_hit':
        message = (
            f"âœ… *Ø§Ù„Ù‡Ø¯Ù ØªØ­Ù‚Ù‚ (ID: {signal_id})*\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"ğŸª™ **Ø§Ù„Ø²ÙˆØ¬:** `{safe_symbol}`\n"
            f"ğŸ¯ **Ø³Ø¹Ø± Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ (Ø§Ù„Ù‡Ø¯Ù):** `${closing_price:,.8g}`\n"
            f"ğŸ’° **Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„Ù…Ø­Ù‚Ù‚:** {profit_pct:+.2f}%"
        )
    elif notification_type == 'stop_loss_hit':
        sl_type_msg = details.get('sl_type', 'Ø¨Ø®Ø³Ø§Ø±Ø© âŒ') # Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø­Ø³ÙˆØ¨Ø© Ù…Ù† Ø¯Ø§Ù„Ø© Ø§Ù„ØªØªØ¨Ø¹
        message = (
            f"ğŸ›‘ *ÙˆØµÙ„ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© (ID: {signal_id})*\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"ğŸª™ **Ø§Ù„Ø²ÙˆØ¬:** `{safe_symbol}`\n"
            f"ğŸš« **Ø³Ø¹Ø± Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ (Ø§Ù„ÙˆÙ‚Ù):** `${closing_price:,.8g}`\n"
            f"ğŸ“‰ **Ø§Ù„Ù†ØªÙŠØ¬Ø©:** {profit_pct:.2f}% ({sl_type_msg})"
        )
    elif notification_type == 'trailing_activated':
        activation_profit_pct = details.get('activation_profit_pct', TRAILING_STOP_ACTIVATION_PROFIT_PCT * 100)
        message = (
            f"â¬†ï¸ *ØªÙØ¹ÙŠÙ„ Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ (ID: {signal_id})*\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"ğŸª™ **Ø§Ù„Ø²ÙˆØ¬:** `{safe_symbol}`\n"
            f"ğŸ“ˆ **Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ (Ø¹Ù†Ø¯ Ø§Ù„ØªÙØ¹ÙŠÙ„):** `${current_price:,.8g}` (Ø±Ø¨Ø­ > {activation_profit_pct:.1f}%)\n"
            f"ğŸ“Š **Ù‚ÙŠÙ…Ø© ATR ({ENTRY_ATR_PERIOD}):** `{atr_value:,.8g}` (Ø§Ù„Ù…Ø¶Ø§Ø¹Ù: {TRAILING_STOP_ATR_MULTIPLIER})\n"
            f"ğŸ›¡ï¸ **ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯:** `${new_stop_loss:,.8g}`"
        )
    elif notification_type == 'trailing_updated':
        trigger_price_increase_pct = details.get('trigger_price_increase_pct', TRAILING_STOP_MOVE_INCREMENT_PCT * 100)
        message = (
            f"â¡ï¸ *ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ (ID: {signal_id})*\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"ğŸª™ **Ø§Ù„Ø²ÙˆØ¬:** `{safe_symbol}`\n"
            f"ğŸ“ˆ **Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ (Ø¹Ù†Ø¯ Ø§Ù„ØªØ­Ø¯ÙŠØ«):** `${current_price:,.8g}` (+{trigger_price_increase_pct:.1f}% Ù…Ù†Ø° Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«)\n"
            f"ğŸ“Š **Ù‚ÙŠÙ…Ø© ATR ({ENTRY_ATR_PERIOD}):** `{atr_value:,.8g}` (Ø§Ù„Ù…Ø¶Ø§Ø¹Ù: {TRAILING_STOP_ATR_MULTIPLIER})\n"
            f"ğŸ”’ **Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ø³Ø§Ø¨Ù‚:** `${old_stop_loss:,.8g}`\n"
            f"ğŸ›¡ï¸ **ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯:** `${new_stop_loss:,.8g}`"
        )
    else:
        logger.warning(f"âš ï¸ [Notification] Ù†ÙˆØ¹ ØªÙ†Ø¨ÙŠÙ‡ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ: {notification_type} Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {details}")
        return # Ù„Ø§ ØªØ±Ø³Ù„ Ø´ÙŠØ¦Ù‹Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†ÙˆØ¹ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ

    if message:
        send_telegram_message(CHAT_ID, message, parse_mode='Markdown')

# ---------------------- Ø¯ÙˆØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø¥Ø¯Ø±Ø§Ø¬ ÙˆØªØ­Ø¯ÙŠØ«) ----------------------
def insert_signal_into_db(signal: Dict[str, Any]) -> bool:
    """Ø¥Ø¯Ø±Ø§Ø¬ Ø¥Ø´Ø§Ø±Ø© Ø¬Ø¯ÙŠØ¯Ø© ÙÙŠ Ø¬Ø¯ÙˆÙ„ signals Ù…Ø¹ Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…ÙˆØ²ÙˆÙ†Ø©."""
    if not check_db_connection() or not conn:
        logger.error(f"âŒ [DB Insert] ÙØ´Ù„ Ø¥Ø¯Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© {signal.get('symbol', 'N/A')} Ø¨Ø³Ø¨Ø¨ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§ØªØµØ§Ù„ DB.")
        return False

    symbol = signal.get('symbol', 'N/A')
    logger.debug(f"â„¹ï¸ [DB Insert] Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¯Ø±Ø§Ø¬ Ø¥Ø´Ø§Ø±Ø© Ù„Ù„Ø²ÙˆØ¬ {symbol}...")
    try:
        signal_prepared = convert_np_values(signal)
        # ØªØ­ÙˆÙŠÙ„ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø¥Ù„Ù‰ JSON (ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ù‡Ø§ Ù„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ù†ÙˆØ§Ø¹ numpy)
        signal_details_json = json.dumps(signal_prepared.get('signal_details', {}))

        with conn.cursor() as cur_ins:
            insert_query = sql.SQL("""
                INSERT INTO signals
                 (symbol, entry_price, initial_target, initial_stop_loss, current_target, current_stop_loss,
                 r2_score, strategy_name, signal_details, last_trailing_update_price, volume_15m)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);
            """)
            cur_ins.execute(insert_query, (
                signal_prepared['symbol'],
                signal_prepared['entry_price'],
                signal_prepared['initial_target'],
                signal_prepared['initial_stop_loss'],
                signal_prepared['current_target'],
                signal_prepared['current_stop_loss'],
                signal_prepared.get('r2_score'), # Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…ÙˆØ²ÙˆÙ†Ø©
                signal_prepared.get('strategy_name', 'unknown'),
                signal_details_json,
                None, # last_trailing_update_price
                signal_prepared.get('volume_15m')
            ))
        conn.commit()
        logger.info(f"âœ… [DB Insert] ØªÙ… Ø¥Ø¯Ø±Ø§Ø¬ Ø¥Ø´Ø§Ø±Ø© Ù„Ù„Ø²ÙˆØ¬ {symbol} ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Score: {signal_prepared.get('r2_score')}).")
        return True
    except psycopg2.Error as db_err:
        logger.error(f"âŒ [DB Insert] Ø®Ø·Ø£ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù†Ø¯ Ø¥Ø¯Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù„Ù„Ø²ÙˆØ¬ {symbol}: {db_err}")
        if conn: conn.rollback()
        return False
    except (TypeError, ValueError) as convert_err:
         logger.error(f"âŒ [DB Insert] Ø®Ø·Ø£ ØªØ­ÙˆÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø¯Ø±Ø§Ø¬ Ù„Ù„Ø²ÙˆØ¬ {symbol}: {convert_err} - Signal Data: {signal}")
         if conn: conn.rollback()
         return False
    except Exception as e:
        logger.error(f"âŒ [DB Insert] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø¥Ø¯Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù„Ù„Ø²ÙˆØ¬ {symbol}: {e}", exc_info=True)
        if conn: conn.rollback()
        return False

# ---------------------- Ø¯Ø§Ù„Ø© ØªØªØ¨Ø¹ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø© ----------------------
def track_signals() -> None:
    """ØªØªØ¨Ø¹ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©ØŒ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ù‡Ø¯Ø§Ù ÙˆÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©ØŒ ÙˆØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ."""
    logger.info("â„¹ï¸ [Tracker] Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© ØªØªØ¨Ø¹ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©...")
    while True:
        active_signals_summary: List[str] = []
        processed_in_cycle = 0
        try:
            if not check_db_connection() or not conn:
                logger.warning("âš ï¸ [Tracker] ØªØ®Ø·ÙŠ Ø¯ÙˆØ±Ø© Ø§Ù„ØªØªØ¨Ø¹ Ø¨Ø³Ø¨Ø¨ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§ØªØµØ§Ù„ DB.")
                time.sleep(15) # Ø§Ù†ØªØ¸Ø§Ø± Ø£Ø·ÙˆÙ„ Ù‚Ù„ÙŠÙ„Ø§Ù‹ Ù‚Ø¨Ù„ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©
                continue

            # Ø§Ø³ØªØ®Ø¯Ø§Ù… cursor Ù…Ø¹ context manager Ù„Ø¬Ù„Ø¨ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©
            with conn.cursor() as track_cur: # ÙŠØ³ØªØ®Ø¯Ù… RealDictCursor
                 track_cur.execute("""
                    SELECT id, symbol, entry_price, initial_stop_loss, current_target, current_stop_loss,
                           is_trailing_active, last_trailing_update_price
                    FROM signals
                    WHERE achieved_target = FALSE AND hit_stop_loss = FALSE;
                """)
                 open_signals: List[Dict] = track_cur.fetchall()

            if not open_signals:
                # logger.debug("â„¹ï¸ [Tracker] Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø´Ø§Ø±Ø§Øª Ù…ÙØªÙˆØ­Ø© Ù„Ù„ØªØªØ¨Ø¹.")
                time.sleep(10) # Ø§Ù†ØªØ¸Ø± Ø£Ù‚Ù„ Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù‡Ù†Ø§Ùƒ Ø¥Ø´Ø§Ø±Ø§Øª
                continue

            logger.debug(f"â„¹ï¸ [Tracker] ØªØªØ¨Ø¹ {len(open_signals)} Ø¥Ø´Ø§Ø±Ø© Ù…ÙØªÙˆØ­Ø©...")

            for signal_row in open_signals:
                signal_id = signal_row['id']
                symbol = signal_row['symbol']
                processed_in_cycle += 1
                update_executed = False # Ù„ØªØªØ¨Ø¹ Ù…Ø§ Ø¥Ø°Ø§ ØªÙ… ØªØ­Ø¯ÙŠØ« Ù‡Ø°Ù‡ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© ÙÙŠ Ø§Ù„Ø¯ÙˆØ±Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©

                try:
                    # Ø§Ø³ØªØ®Ù„Ø§Øµ ÙˆØªØ­ÙˆÙŠÙ„ Ø¢Ù…Ù† Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
                    entry_price = float(signal_row['entry_price'])
                    initial_stop_loss = float(signal_row['initial_stop_loss'])
                    current_target = float(signal_row['current_target'])
                    current_stop_loss = float(signal_row['current_stop_loss'])
                    is_trailing_active = signal_row['is_trailing_active']
                    last_update_px = signal_row['last_trailing_update_price']
                    last_trailing_update_price = float(last_update_px) if last_update_px is not None else None

                    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª WebSocket Ticker
                    current_price = ticker_data.get(symbol)

                    if current_price is None:
                         logger.warning(f"âš ï¸ [Tracker] {symbol}(ID:{signal_id}): Ù„Ø§ ÙŠØªÙˆÙØ± Ø³Ø¹Ø± Ø­Ø§Ù„ÙŠ ÙÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ticker.")
                         continue # ØªØ®Ø·ÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø¯ÙˆØ±Ø©

                    active_signals_summary.append(f"{symbol}({signal_id}): P={current_price:.4f} T={current_target:.4f} SL={current_stop_loss:.4f} Trail={'On' if is_trailing_active else 'Off'}")

                    update_query: Optional[sql.SQL] = None
                    update_params: Tuple = ()
                    log_message: Optional[str] = None
                    notification_details: Dict[str, Any] = {'symbol': symbol, 'id': signal_id}

                    # --- Ù…Ù†Ø·Ù‚ Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆØ§Ù„ØªØ­Ø¯ÙŠØ« ---
                    # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ù‡Ø¯Ù
                    if current_price >= current_target:
                        profit_pct = ((current_target / entry_price) - 1) * 100 if entry_price > 0 else 0
                        update_query = sql.SQL("UPDATE signals SET achieved_target = TRUE, closing_price = %s, closed_at = NOW(), profit_percentage = %s WHERE id = %s;")
                        update_params = (current_target, profit_pct, signal_id)
                        log_message = f"ğŸ¯ [Tracker] {symbol}(ID:{signal_id}): ÙˆØµÙ„ Ø§Ù„Ù‡Ø¯Ù Ø¹Ù†Ø¯ {current_target:.8g} (Ø±Ø¨Ø­: {profit_pct:+.2f}%)."
                        notification_details.update({'type': 'target_hit', 'closing_price': current_target, 'profit_pct': profit_pct})
                        update_executed = True

                    # 2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙˆØµÙˆÙ„ Ù„ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© (ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‡Ø¯Ù)
                    elif current_price <= current_stop_loss:
                        loss_pct = ((current_stop_loss / entry_price) - 1) * 100 if entry_price > 0 else 0
                        profitable_sl = current_stop_loss > entry_price
                        sl_type_msg = "Ø¨Ø±Ø¨Ø­ âœ…" if profitable_sl else "Ø¨Ø®Ø³Ø§Ø±Ø© âŒ"
                        update_query = sql.SQL("UPDATE signals SET hit_stop_loss = TRUE, closing_price = %s, closed_at = NOW(), profit_percentage = %s, profitable_stop_loss = %s WHERE id = %s;")
                        update_params = (current_stop_loss, loss_pct, profitable_sl, signal_id)
                        log_message = f"ğŸ”» [Tracker] {symbol}(ID:{signal_id}): ÙˆØµÙ„ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© ({sl_type_msg}) Ø¹Ù†Ø¯ {current_stop_loss:.8g} (Ù†Ø³Ø¨Ø©: {loss_pct:.2f}%)."
                        notification_details.update({'type': 'stop_loss_hit', 'closing_price': current_stop_loss, 'profit_pct': loss_pct, 'sl_type': sl_type_msg})
                        update_executed = True

                    # 3. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙØ¹ÙŠÙ„ Ø£Ùˆ ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ (ÙÙ‚Ø· Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø¶Ø±Ø¨ Ø§Ù„Ù‡Ø¯Ù Ø£Ùˆ Ø§Ù„ÙˆÙ‚Ù)
                    else:
                        activation_threshold_price = entry_price * (1 + TRAILING_STOP_ACTIVATION_PROFIT_PCT)
                        # Ø£. ØªÙØ¹ÙŠÙ„ Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ
                        if not is_trailing_active and current_price >= activation_threshold_price:
                            logger.info(f"â„¹ï¸ [Tracker] {symbol}(ID:{signal_id}): Ø§Ù„Ø³Ø¹Ø± {current_price:.8g} ÙˆØµÙ„ Ù„Ø¹ØªØ¨Ø© ØªÙØ¹ÙŠÙ„ Ø§Ù„ÙˆÙ‚Ù ({activation_threshold_price:.8g}). Ø¬Ù„Ø¨ ATR...")
                            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ Ø§Ù„Ù…Ø­Ø¯Ø¯ Ù„Ù„ØªØªØ¨Ø¹
                            df_atr = fetch_historical_data(symbol, interval=SIGNAL_TRACKING_TIMEFRAME, days=SIGNAL_TRACKING_LOOKBACK_DAYS)
                            if df_atr is not None and not df_atr.empty:
                                # Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙØªØ±Ø© ATR Ø§Ù„Ù…Ø®ØµØµØ© Ù„Ù„Ø¯Ø®ÙˆÙ„/Ø§Ù„ØªØªØ¨Ø¹
                                df_atr = calculate_atr_indicator(df_atr, period=ENTRY_ATR_PERIOD)
                                if not df_atr.empty and 'atr' in df_atr.columns and pd.notna(df_atr['atr'].iloc[-1]):
                                    current_atr_val = df_atr['atr'].iloc[-1]
                                    if current_atr_val > 0:
                                         new_stop_loss_calc = current_price - (TRAILING_STOP_ATR_MULTIPLIER * current_atr_val)
                                         new_stop_loss = max(new_stop_loss_calc, current_stop_loss, entry_price * (1 + 0.005)) # Ù†Ø¶Ù…Ù† Ø±Ø¨Ø­ Ø¨Ø³ÙŠØ· Ø¬Ø¯Ø§Ù‹ Ø£Ùˆ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ø­Ø§Ù„ÙŠ

                                         if new_stop_loss > current_stop_loss: # ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø£Ø¹Ù„Ù‰ ÙØ¹Ù„Ø§Ù‹
                                            update_query = sql.SQL("UPDATE signals SET is_trailing_active = TRUE, current_stop_loss = %s, last_trailing_update_price = %s WHERE id = %s;")
                                            update_params = (new_stop_loss, current_price, signal_id)
                                            log_message = f"â¬†ï¸âœ… [Tracker] {symbol}(ID:{signal_id}): ØªÙØ¹ÙŠÙ„ Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ. Ø§Ù„Ø³Ø¹Ø±={current_price:.8g}, ATR={current_atr_val:.8g}. Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯: {new_stop_loss:.8g}"
                                            notification_details.update({'type': 'trailing_activated', 'current_price': current_price, 'atr_value': current_atr_val, 'new_stop_loss': new_stop_loss, 'activation_profit_pct': TRAILING_STOP_ACTIVATION_PROFIT_PCT * 100})
                                            update_executed = True
                                         else:
                                            logger.debug(f"â„¹ï¸ [Tracker] {symbol}(ID:{signal_id}): Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ Ø§Ù„Ù…Ø­Ø³ÙˆØ¨ ({new_stop_loss:.8g}) Ù„ÙŠØ³ Ø£Ø¹Ù„Ù‰ Ù…Ù† Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ø­Ø§Ù„ÙŠ ({current_stop_loss:.8g}). Ù„Ù† ÙŠØªÙ… Ø§Ù„ØªÙØ¹ÙŠÙ„.")
                                    else: logger.warning(f"âš ï¸ [Tracker] {symbol}(ID:{signal_id}): Ù‚ÙŠÙ…Ø© ATR ØºÙŠØ± ØµØ§Ù„Ø­Ø© ({current_atr_val}) Ù„ØªÙØ¹ÙŠÙ„ Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ.")
                                else: logger.warning(f"âš ï¸ [Tracker] {symbol}(ID:{signal_id}): Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø­Ø³Ø§Ø¨ ATR Ù„ØªÙØ¹ÙŠÙ„ Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ.")
                            else: logger.warning(f"âš ï¸ [Tracker] {symbol}(ID:{signal_id}): Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø­Ø³Ø§Ø¨ ATR Ù„ØªÙØ¹ÙŠÙ„ Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ.")

                        # Ø¨. ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ
                        elif is_trailing_active and last_trailing_update_price is not None:
                            update_threshold_price = last_trailing_update_price * (1 + TRAILING_STOP_MOVE_INCREMENT_PCT)
                            if current_price >= update_threshold_price:
                                logger.info(f"â„¹ï¸ [Tracker] {symbol}(ID:{signal_id}): Ø§Ù„Ø³Ø¹Ø± {current_price:.8g} ÙˆØµÙ„ Ù„Ø¹ØªØ¨Ø© ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙˆÙ‚Ù ({update_threshold_price:.8g}). Ø¬Ù„Ø¨ ATR...")
                                df_recent = fetch_historical_data(symbol, interval=SIGNAL_TRACKING_TIMEFRAME, days=SIGNAL_TRACKING_LOOKBACK_DAYS)
                                if df_recent is not None and not df_recent.empty:
                                    df_recent = calculate_atr_indicator(df_recent, period=ENTRY_ATR_PERIOD)
                                    if not df_recent.empty and 'atr' in df_recent.columns and pd.notna(df_recent['atr'].iloc[-1]):
                                         current_atr_val_update = df_recent['atr'].iloc[-1]
                                         if current_atr_val_update > 0:
                                             potential_new_stop_loss = current_price - (TRAILING_STOP_ATR_MULTIPLIER * current_atr_val_update)
                                             if potential_new_stop_loss > current_stop_loss:
                                                new_stop_loss_update = potential_new_stop_loss
                                                update_query = sql.SQL("UPDATE signals SET current_stop_loss = %s, last_trailing_update_price = %s WHERE id = %s;")
                                                update_params = (new_stop_loss_update, current_price, signal_id)
                                                log_message = f"â¡ï¸ğŸ”¼ [Tracker] {symbol}(ID:{signal_id}): ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ. Ø§Ù„Ø³Ø¹Ø±={current_price:.8g}, ATR={current_atr_val_update:.8g}. Ø§Ù„Ù‚Ø¯ÙŠÙ…={current_stop_loss:.8g}, Ø§Ù„Ø¬Ø¯ÙŠØ¯: {new_stop_loss_update:.8g}"
                                                notification_details.update({'type': 'trailing_updated', 'current_price': current_price, 'atr_value': current_atr_val_update, 'old_stop_loss': current_stop_loss, 'new_stop_loss': new_stop_loss_update, 'trigger_price_increase_pct': TRAILING_STOP_MOVE_INCREMENT_PCT * 100})
                                                update_executed = True
                                             else:
                                                 logger.debug(f"â„¹ï¸ [Tracker] {symbol}(ID:{signal_id}): Ø§Ù„ÙˆÙ‚Ù Ø§Ù„Ù…ØªØ­Ø±Ùƒ Ø§Ù„Ù…Ø­Ø³ÙˆØ¨ ({potential_new_stop_loss:.8g}) Ù„ÙŠØ³ Ø£Ø¹Ù„Ù‰ Ù…Ù† Ø§Ù„Ø­Ø§Ù„ÙŠ ({current_stop_loss:.8g}). Ù„Ù† ÙŠØªÙ… Ø§Ù„ØªØ­Ø¯ÙŠØ«.")
                                         else: logger.warning(f"âš ï¸ [Tracker] {symbol}(ID:{signal_id}): Ù‚ÙŠÙ…Ø© ATR ØºÙŠØ± ØµØ§Ù„Ø­Ø© ({current_atr_val_update}) Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙˆÙ‚Ù.")
                                    else: logger.warning(f"âš ï¸ [Tracker] {symbol}(ID:{signal_id}): Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø­Ø³Ø§Ø¨ ATR Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙˆÙ‚Ù.")
                                else: logger.warning(f"âš ï¸ [Tracker] {symbol}(ID:{signal_id}): Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø­Ø³Ø§Ø¨ ATR Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙˆÙ‚Ù.")

                    # --- ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ­Ø¯ÙŠØ« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡ ---
                    if update_executed and update_query:
                        try:
                             with conn.cursor() as update_cur:
                                  update_cur.execute(update_query, update_params)
                             conn.commit()
                             if log_message: logger.info(log_message)
                             if notification_details.get('type'):
                                send_tracking_notification(notification_details)
                        except psycopg2.Error as db_err:
                            logger.error(f"âŒ [Tracker] {symbol}(ID:{signal_id}): Ø®Ø·Ø£ DB Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ø¯ÙŠØ«: {db_err}")
                            if conn: conn.rollback()
                        except Exception as exec_err:
                            logger.error(f"âŒ [Tracker] {symbol}(ID:{signal_id}): Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ­Ø¯ÙŠØ«/Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±: {exec_err}", exc_info=True)
                            if conn: conn.rollback()

                except (TypeError, ValueError) as convert_err:
                    logger.error(f"âŒ [Tracker] {symbol}(ID:{signal_id}): Ø®Ø·Ø£ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ù‚ÙŠÙ… Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©: {convert_err}")
                    continue
                except Exception as inner_loop_err:
                     logger.error(f"âŒ [Tracker] {symbol}(ID:{signal_id}): Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¥Ø´Ø§Ø±Ø©: {inner_loop_err}", exc_info=True)
                     continue

            if active_signals_summary:
                logger.debug(f"â„¹ï¸ [Tracker] Ø­Ø§Ù„Ø© Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø¯ÙˆØ±Ø© ({processed_in_cycle} Ù…Ø¹Ø§Ù„Ø¬): {'; '.join(active_signals_summary)}")

            time.sleep(3) # Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø¨ÙŠÙ† Ø¯ÙˆØ±Ø§Øª Ø§Ù„ØªØªØ¨Ø¹

        except psycopg2.Error as db_cycle_err:
             logger.error(f"âŒ [Tracker] Ø®Ø·Ø£ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø¯ÙˆØ±Ø© Ø§Ù„ØªØªØ¨Ø¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: {db_cycle_err}. Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„...")
             if conn: conn.rollback()
             time.sleep(30)
             check_db_connection()
        except Exception as cycle_err:
            logger.error(f"âŒ [Tracker] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø¯ÙˆØ±Ø© ØªØªØ¨Ø¹ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª: {cycle_err}", exc_info=True)
            time.sleep(30)


# ---------------------- Ø®Ø¯Ù…Ø© Flask (Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù„Ù„Ù€ Webhook) ----------------------
app = Flask(__name__)

@app.route('/')
def home() -> Response:
    """ØµÙØ­Ø© Ø±Ø¦ÙŠØ³ÙŠØ© Ø¨Ø³ÙŠØ·Ø© Ù„Ø¥Ø¸Ù‡Ø§Ø± Ø£Ù† Ø§Ù„Ø¨ÙˆØª ÙŠØ¹Ù…Ù„."""
    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    ws_alive = ws_thread.is_alive() if 'ws_thread' in globals() and ws_thread else False
    tracker_alive = tracker_thread.is_alive() if 'tracker_thread' in globals() and tracker_thread else False
    status = "running" if ws_alive and tracker_alive else "partially running"
    return Response(f"ğŸ“ˆ Crypto Signal Bot ({status}) - Last Check: {now}", status=200, mimetype='text/plain')

@app.route('/favicon.ico')
def favicon() -> Response:
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨ Ø£ÙŠÙ‚ÙˆÙ†Ø© Ø§Ù„Ù…ÙØ¶Ù„Ø© Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø®Ø·Ø£ 404 ÙÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª."""
    return Response(status=204) # No Content

@app.route('/webhook', methods=['POST'])
def webhook() -> Tuple[str, int]:
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„ÙˆØ§Ø±Ø¯Ø© Ù…Ù† Telegram (Ù…Ø«Ù„ Ø¶ØºØ· Ø§Ù„Ø£Ø²Ø±Ø§Ø± ÙˆØ§Ù„Ø£ÙˆØ§Ù…Ø±)."""
    if not request.is_json:
        logger.warning("âš ï¸ [Flask] Received non-JSON webhook request.")
        return "Invalid request format", 400 # Bad Request

    try:
        data = request.get_json()
        logger.debug(f"â„¹ï¸ [Flask] Received webhook data: {json.dumps(data)[:200]}...") # ØªØ³Ø¬ÙŠÙ„ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙ‚Ø·

        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø¯ÙˆØ¯ Ø§Ù„Ø£Ø²Ø±Ø§Ø± (Callback Queries)
        if 'callback_query' in data:
            callback_query = data['callback_query']
            callback_id = callback_query['id']
            callback_data = callback_query.get('data')
            message_info = callback_query.get('message')
            if not message_info or not callback_data:
                 logger.warning(f"âš ï¸ [Flask] Callback query (ID: {callback_id}) missing message or data.")
                 try:
                     ack_url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/answerCallbackQuery"
                     requests.post(ack_url, json={'callback_query_id': callback_id}, timeout=5)
                 except Exception as ack_err:
                     logger.warning(f"âš ï¸ [Flask] Failed to acknowledge invalid callback query {callback_id}: {ack_err}")
                 return "OK", 200

            chat_id_callback = message_info['chat']['id']
            message_id = message_info['message_id']
            user_info = callback_query.get('from', {})
            user_id = user_info.get('id')
            username = user_info.get('username', 'N/A')

            logger.info(f"â„¹ï¸ [Flask] Received callback query: Data='{callback_data}', User={username}({user_id}), Chat={chat_id_callback}")

            # Ø¥Ø±Ø³Ø§Ù„ ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø§Ø³ØªÙ„Ø§Ù… Ø¨Ø³Ø±Ø¹Ø©
            try:
                ack_url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/answerCallbackQuery"
                requests.post(ack_url, json={'callback_query_id': callback_id}, timeout=5)
            except Exception as ack_err:
                 logger.warning(f"âš ï¸ [Flask] Failed to acknowledge callback query {callback_id}: {ack_err}")

            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªÙ„Ù…Ø© Ù…Ù† Ø§Ù„Ø²Ø±
            if callback_data == "get_report":
                report_thread = Thread(target=lambda: send_telegram_message(chat_id_callback, generate_performance_report(), parse_mode='Markdown'))
                report_thread.start()
            else:
                logger.warning(f"âš ï¸ [Flask] Received unhandled callback data: '{callback_data}'")


        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ù†ØµÙŠØ© (Ø§Ù„Ø£ÙˆØ§Ù…Ø±)
        elif 'message' in data:
            message_data = data['message']
            chat_info = message_data.get('chat')
            user_info = message_data.get('from', {})
            text_msg = message_data.get('text', '').strip()

            if not chat_info or not text_msg:
                 logger.debug("â„¹ï¸ [Flask] Received message without chat info or text.")
                 return "OK", 200

            chat_id_msg = chat_info['id']
            user_id = user_info.get('id')
            username = user_info.get('username', 'N/A')

            logger.info(f"â„¹ï¸ [Flask] Received message: Text='{text_msg}', User={username}({user_id}), Chat={chat_id_msg}")

            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©
            if text_msg.lower() == '/report':
                 report_thread = Thread(target=lambda: send_telegram_message(chat_id_msg, generate_performance_report(), parse_mode='Markdown'))
                 report_thread.start()
            elif text_msg.lower() == '/status':
                 status_thread = Thread(target=handle_status_command, args=(chat_id_msg,))
                 status_thread.start()

        else:
            logger.debug("â„¹ï¸ [Flask] Received webhook data without 'callback_query' or 'message'.")

        return "OK", 200
    except Exception as e:
         logger.error(f"âŒ [Flask] Error processing webhook: {e}", exc_info=True)
         return "Internal Server Error", 500

def handle_status_command(chat_id_msg: int) -> None:
    """Ø¯Ø§Ù„Ø© Ù…Ù†ÙØµÙ„Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ù…Ø± /status Ù„ØªØ¬Ù†Ø¨ Ø­Ø¸Ø± Webhook."""
    logger.info(f"â„¹ï¸ [Flask Status] Handling /status command for chat {chat_id_msg}")
    status_msg = "â³ Ø¬Ø§Ø±Ù Ø¬Ù„Ø¨ Ø§Ù„Ø­Ø§Ù„Ø©..."
    msg_sent = send_telegram_message(chat_id_msg, status_msg)
    if not (msg_sent and msg_sent.get('ok')):
         logger.error(f"âŒ [Flask Status] Failed to send initial status message to {chat_id_msg}")
         return

    message_id_to_edit = msg_sent['result']['message_id']
    try:
        open_count = 0
        if check_db_connection() and conn:
            with conn.cursor() as status_cur:
                status_cur.execute("SELECT COUNT(*) AS count FROM signals WHERE achieved_target = FALSE AND hit_stop_loss = FALSE;")
                open_count = (status_cur.fetchone() or {}).get('count', 0)

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„ÙŠÙ‡Ø§
        ws_status = 'Ù†Ø´Ø· âœ…' if 'ws_thread' in globals() and ws_thread and ws_thread.is_alive() else 'ØºÙŠØ± Ù†Ø´Ø· âŒ'
        tracker_status = 'Ù†Ø´Ø· âœ…' if 'tracker_thread' in globals() and tracker_thread and tracker_thread.is_alive() else 'ØºÙŠØ± Ù†Ø´Ø· âŒ'
        final_status_msg = (
            f"ğŸ¤– *Ø­Ø§Ù„Ø© Ø§Ù„Ø¨ÙˆØª:*\n"
            f"- ØªØªØ¨Ø¹ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± (WS): {ws_status}\n"
            f"- ØªØªØ¨Ø¹ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª: {tracker_status}\n"
            f"- Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø©: *{open_count}* / {MAX_OPEN_TRADES}\n"
            f"- ÙˆÙ‚Øª Ø§Ù„Ø®Ø§Ø¯Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ: {datetime.now().strftime('%H:%M:%S')}"
        )
        # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
        edit_url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/editMessageText"
        edit_payload = {
            'chat_id': chat_id_msg,
             'message_id': message_id_to_edit,
            'text': final_status_msg,
            'parse_mode': 'Markdown'
        }
        response = requests.post(edit_url, json=edit_payload, timeout=10)
        response.raise_for_status()
        logger.info(f"âœ… [Flask Status] Status updated for chat {chat_id_msg}")

    except Exception as status_err:
        logger.error(f"âŒ [Flask Status] Error getting/editing status details for chat {chat_id_msg}: {status_err}", exc_info=True)
        send_telegram_message(chat_id_msg, "âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø­Ø§Ù„Ø©.")


def run_flask() -> None:
    """ØªØ´ØºÙŠÙ„ ØªØ·Ø¨ÙŠÙ‚ Flask Ù„Ø³Ù…Ø§Ø¹ Ø§Ù„Ù€ Webhook Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø§Ø¯Ù… Ø¥Ù†ØªØ§Ø¬ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ù‹Ø§."""
    if not WEBHOOK_URL:
        logger.info("â„¹ï¸ [Flask] Webhook URL not configured. Flask server will not start.")
        return

    host = "0.0.0.0"
    port = int(config('PORT', default=10000)) # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ØªØºÙŠØ± Ø¨ÙŠØ¦Ø© PORT Ø£Ùˆ Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
    logger.info(f"â„¹ï¸ [Flask] Starting Flask app on {host}:{port}...")
    try:
        from waitress import serve
        logger.info("âœ… [Flask] Using 'waitress' server.")
        serve(app, host=host, port=port, threads=6)
    except ImportError:
         logger.warning("âš ï¸ [Flask] 'waitress' not installed. Falling back to Flask development server (NOT recommended for production).")
         try:
             app.run(host=host, port=port)
         except Exception as flask_run_err:
              logger.critical(f"âŒ [Flask] Failed to start development server: {flask_run_err}", exc_info=True)
    except Exception as serve_err:
         logger.critical(f"âŒ [Flask] Failed to start server (waitress?): {serve_err}", exc_info=True)

# ---------------------- Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙˆØ¯Ø§Ù„Ø© Ø§Ù„ÙØ­Øµ ----------------------
def main_loop() -> None:
    """Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„ÙØ­Øµ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª."""
    symbols_to_scan = get_crypto_symbols()
    if not symbols_to_scan:
        logger.critical("âŒ [Main] Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø£Ùˆ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£ÙŠ Ø±Ù…ÙˆØ² ØµØ§Ù„Ø­Ø©. Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©.")
        return

    logger.info(f"âœ… [Main] ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(symbols_to_scan)} Ø±Ù…Ø² ØµØ§Ù„Ø­ Ù„Ù„ÙØ­Øµ.")
    last_full_scan_time = time.time()

    while True:
        try:
            scan_start_time = time.time()
            logger.info("+" + "-"*60 + "+")
            logger.info(f"ğŸ”„ [Main] Ø¨Ø¯Ø¡ Ø¯ÙˆØ±Ø© ÙØ­Øµ Ø§Ù„Ø³ÙˆÙ‚ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            logger.info("+" + "-"*60 + "+")

            if not check_db_connection() or not conn:
                logger.error("âŒ [Main] ØªØ®Ø·ÙŠ Ø¯ÙˆØ±Ø© Ø§Ù„ÙØ­Øµ Ø¨Ø³Ø¨Ø¨ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
                time.sleep(60)
                continue

            # 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø© Ø­Ø§Ù„ÙŠÙ‹Ø§
            open_count = 0
            try:
                 with conn.cursor() as cur_check:
                    cur_check.execute("SELECT COUNT(*) AS count FROM signals WHERE achieved_target = FALSE AND hit_stop_loss = FALSE;")
                    open_count = (cur_check.fetchone() or {}).get('count', 0)
            except psycopg2.Error as db_err:
                 logger.error(f"âŒ [Main] Ø®Ø·Ø£ DB Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©: {db_err}. ØªØ®Ø·ÙŠ Ø§Ù„Ø¯ÙˆØ±Ø©.")
                 if conn: conn.rollback()
                 time.sleep(60)
                 continue

            logger.info(f"â„¹ï¸ [Main] Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø© Ø­Ø§Ù„ÙŠÙ‹Ø§: {open_count} / {MAX_OPEN_TRADES}")
            if open_count >= MAX_OPEN_TRADES:
                logger.info(f"âš ï¸ [Main] ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©. Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±...")
                time.sleep(60)
                continue

            # 2. Ø§Ù„Ù…Ø±ÙˆØ± Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ù…ÙˆØ² ÙˆÙØ­ØµÙ‡Ø§
            processed_in_loop = 0
            signals_generated_in_loop = 0
            slots_available = MAX_OPEN_TRADES - open_count

            for symbol in symbols_to_scan:
                 if slots_available <= 0:
                      logger.info(f"â„¹ï¸ [Main] ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ ({MAX_OPEN_TRADES}) Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ÙØ­Øµ. Ø¥ÙŠÙ‚Ø§Ù ÙØ­Øµ Ø§Ù„Ø±Ù…ÙˆØ² Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø¯ÙˆØ±Ø©.")
                      break

                 processed_in_loop += 1
                 logger.debug(f"ğŸ” [Main] ÙØ­Øµ {symbol} ({processed_in_loop}/{len(symbols_to_scan)})...")

                 try:
                    # Ø£. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¥Ø´Ø§Ø±Ø© Ù…ÙØªÙˆØ­Ø© Ø¨Ø§Ù„ÙØ¹Ù„ Ù„Ù‡Ø°Ø§ Ø§Ù„Ø±Ù…Ø²
                    with conn.cursor() as symbol_cur:
                        symbol_cur.execute("SELECT 1 FROM signals WHERE symbol = %s AND achieved_target = FALSE AND hit_stop_loss = FALSE LIMIT 1;", (symbol,))
                        if symbol_cur.fetchone():
                            continue

                    # Ø¨. Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©
                    df_hist = fetch_historical_data(symbol, interval=SIGNAL_GENERATION_TIMEFRAME, days=SIGNAL_GENERATION_LOOKBACK_DAYS)
                    if df_hist is None or df_hist.empty:
                        continue

                    # Ø¬. ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©
                    strategy = ConservativeTradingStrategy(symbol) # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…Ø¹Ø¯Ù„Ø©
                    df_indicators = strategy.populate_indicators(df_hist)
                    if df_indicators is None:
                        continue

                    potential_signal = strategy.generate_buy_signal(df_indicators)

                    # Ø¯. Ø¥Ø¯Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© ÙˆØ¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡
                    if potential_signal:
                        logger.info(f"âœ¨ [Main] ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¥Ø´Ø§Ø±Ø© Ù…Ø­ØªÙ…Ù„Ø© Ù„Ù€ {symbol}! (Score: {potential_signal.get('r2_score', 0):.2f}) Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙˆØ¥Ø¯Ø±Ø§Ø¬...")
                        with conn.cursor() as final_check_cur:
                             final_check_cur.execute("SELECT COUNT(*) AS count FROM signals WHERE achieved_target = FALSE AND hit_stop_loss = FALSE;")
                             final_open_count = (final_check_cur.fetchone() or {}).get('count', 0)

                             if final_open_count < MAX_OPEN_TRADES:
                                 if insert_signal_into_db(potential_signal):
                                     send_telegram_alert(potential_signal, SIGNAL_GENERATION_TIMEFRAME)
                                     signals_generated_in_loop += 1
                                     slots_available -= 1
                                     time.sleep(2)
                                 else:
                                     logger.error(f"âŒ [Main] ÙØ´Ù„ Ø¥Ø¯Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù„Ù€ {symbol} ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
                             else:
                                 logger.warning(f"âš ï¸ [Main] ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ ({final_open_count}) Ù‚Ø¨Ù„ Ø¥Ø¯Ø±Ø§Ø¬ Ø¥Ø´Ø§Ø±Ø© {symbol}. ØªÙ… ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©.")
                                 break

                 except psycopg2.Error as db_loop_err:
                      logger.error(f"âŒ [Main] Ø®Ø·Ø£ DB Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ù…Ø² {symbol}: {db_loop_err}. Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ù„Ù„ØªØ§Ù„ÙŠ...")
                      if conn: conn.rollback()
                      continue
                 except Exception as symbol_proc_err:
                      logger.error(f"âŒ [Main] Ø®Ø·Ø£ Ø¹Ø§Ù… Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ù…Ø² {symbol}: {symbol_proc_err}", exc_info=True)
                      continue

                 time.sleep(0.3)

            # 3. Ø§Ù†ØªØ¸Ø§Ø± Ù‚Ø¨Ù„ Ø¨Ø¯Ø¡ Ø§Ù„Ø¯ÙˆØ±Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©
            scan_duration = time.time() - scan_start_time
            logger.info(f"ğŸ [Main] Ø§Ù†ØªÙ‡Ø§Ø¡ Ø¯ÙˆØ±Ø© Ø§Ù„ÙØ­Øµ. Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙˆÙ„Ø¯Ø©: {signals_generated_in_loop}. Ù…Ø¯Ø© Ø§Ù„ÙØ­Øµ: {scan_duration:.2f} Ø«Ø§Ù†ÙŠØ©.")
            wait_time = max(60, 300 - scan_duration) # Ø§Ù†ØªØ¸Ø§Ø± 5 Ø¯Ù‚Ø§Ø¦Ù‚ Ø¥Ø¬Ù…Ø§Ù„Ø§Ù‹ Ø£Ùˆ Ø¯Ù‚ÙŠÙ‚Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„
            logger.info(f"â³ [Main] Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± {wait_time:.1f} Ø«Ø§Ù†ÙŠØ© Ù„Ù„Ø¯ÙˆØ±Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©...")
            time.sleep(wait_time)

        except KeyboardInterrupt:
             logger.info("ğŸ›‘ [Main] ØªÙ… Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø·Ù„Ø¨ Ø¥ÙŠÙ‚Ø§Ù (KeyboardInterrupt). Ø¥ØºÙ„Ø§Ù‚...")
             break
        except psycopg2.Error as db_main_err:
             logger.error(f"âŒ [Main] Ø®Ø·Ø£ ÙØ§Ø¯Ø­ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: {db_main_err}. Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„...")
             if conn: conn.rollback()
             time.sleep(60)
             try:
                 init_db()
             except Exception as recon_err:
                 logger.critical(f"âŒ [Main] ÙØ´Ù„Øª Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {recon_err}. Ø§Ù„Ø®Ø±ÙˆØ¬...")
                 break
        except Exception as main_err:
            logger.error(f"âŒ [Main] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: {main_err}", exc_info=True)
            logger.info("â„¹ï¸ [Main] Ø§Ù†ØªØ¸Ø§Ø± 120 Ø«Ø§Ù†ÙŠØ© Ù‚Ø¨Ù„ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©...")
            time.sleep(120)

def cleanup_resources() -> None:
    """Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù…Ø«Ù„ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."""
    global conn
    logger.info("â„¹ï¸ [Cleanup] Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯...")
    if conn:
        try:
            conn.close()
            logger.info("âœ… [DB] ØªÙ… Ø¥ØºÙ„Ø§Ù‚ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
        except Exception as close_err:
            logger.error(f"âš ï¸ [DB] Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¥ØºÙ„Ø§Ù‚ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {close_err}")
    logger.info("âœ… [Cleanup] ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯.")


# ---------------------- Ù†Ù‚Ø·Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ----------------------
if __name__ == "__main__":
    logger.info("ğŸš€ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø¨ÙˆØª Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„ØªØ¯Ø§ÙˆÙ„...")
    logger.info(f"Local Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | UTC Time: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')}")

    # ØªÙ‡ÙŠØ¦Ø© Threads Ù„ØªÙƒÙˆÙ† Ù…ØªØ§Ø­Ø© ÙƒÙ…ØªØºÙŠØ±Ø§Øª Ø¹Ø§Ù…Ø©
    ws_thread: Optional[Thread] = None
    tracker_thread: Optional[Thread] = None
    flask_thread: Optional[Thread] = None

    try:
        # 1. ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„Ø§Ù‹
        init_db()

        # 2. Ø¨Ø¯Ø¡ WebSocket Ticker
        ws_thread = Thread(target=run_ticker_socket_manager, daemon=True, name="WebSocketThread")
        ws_thread.start()
        logger.info("âœ… [Main] ØªÙ… Ø¨Ø¯Ø¡ Ø®ÙŠØ· WebSocket Ticker.")
        logger.info("â„¹ï¸ [Main] Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± 5 Ø«ÙˆØ§Ù†Ù Ù„ØªÙ‡ÙŠØ¦Ø© WebSocket...")
        time.sleep(5)
        if not ticker_data:
             logger.warning("âš ï¸ [Main] Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„ÙŠØ© Ù…Ù† WebSocket Ø¨Ø¹Ø¯ 5 Ø«ÙˆØ§Ù†Ù.")
        else:
             logger.info(f"âœ… [Main] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„ÙŠØ© Ù…Ù† WebSocket Ù„Ù€ {len(ticker_data)} Ø±Ù…Ø².")


        # 3. Ø¨Ø¯Ø¡ Ù…ØªØªØ¨Ø¹ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª
        tracker_thread = Thread(target=track_signals, daemon=True, name="TrackerThread")
        tracker_thread.start()
        logger.info("âœ… [Main] ØªÙ… Ø¨Ø¯Ø¡ Ø®ÙŠØ· ØªØªØ¨Ø¹ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª.")

        # 4. Ø¨Ø¯Ø¡ Ø®Ø§Ø¯Ù… Flask (Ø¥Ø°Ø§ ØªÙ… ØªÙƒÙˆÙŠÙ† Webhook)
        if WEBHOOK_URL:
            flask_thread = Thread(target=run_flask, daemon=True, name="FlaskThread")
            flask_thread.start()
            logger.info("âœ… [Main] ØªÙ… Ø¨Ø¯Ø¡ Ø®ÙŠØ· Flask Webhook.")
        else:
             logger.info("â„¹ï¸ [Main] Ù„Ù… ÙŠØªÙ… ØªÙƒÙˆÙŠÙ† Webhook URLØŒ Ù„Ù† ÙŠØªÙ… Ø¨Ø¯Ø¡ Ø®Ø§Ø¯Ù… Flask.")

        # 5. Ø¨Ø¯Ø¡ Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
        main_loop()

    except Exception as startup_err:
        logger.critical(f"âŒ [Main] Ø­Ø¯Ø« Ø®Ø·Ø£ ÙØ§Ø¯Ø­ Ø£Ø«Ù†Ø§Ø¡ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø£Ùˆ ÙÙŠ Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: {startup_err}", exc_info=True)
    finally:
        logger.info("ğŸ›‘ [Main] Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ ÙÙŠ Ø·ÙˆØ± Ø§Ù„Ø¥ØºÙ„Ø§Ù‚...")
        # send_telegram_message(CHAT_ID, "âš ï¸ ØªÙ†Ø¨ÙŠÙ‡: Ø¨ÙˆØª Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ù‚ÙŠØ¯ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¢Ù†.") # ÙŠÙ…ÙƒÙ† Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚ Ù„Ø¥Ø±Ø³Ø§Ù„ ØªÙ†Ø¨ÙŠÙ‡ Ø¹Ù†Ø¯ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ù
        cleanup_resources()
        logger.info("ğŸ‘‹ [Main] ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø¨ÙˆØª Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„ØªØ¯Ø§ÙˆÙ„.")
        os._exit(0)
