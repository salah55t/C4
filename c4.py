import time
import os
import json
import logging
import requests
import numpy as np
import pandas as pd
import psycopg2
import pickle # Added for ML model deserialization
from psycopg2 import sql, OperationalError, InterfaceError
from psycopg2.extras import RealDictCursor
from binance.client import Client
from binance import ThreadedWebsocketManager
from binance.exceptions import BinanceAPIException, BinanceRequestException
from flask import Flask, request, Response
from threading import Thread
from datetime import datetime, timedelta
from decouple import config
from typing import List, Dict, Optional, Tuple, Any, Union

# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ----------------------
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\
    handlers=[
        logging.FileHandler('crypto_bot_elliott_fib.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('CryptoBot')

# ---------------------- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ© ----------------------
try:
    API_KEY: str = config('BINANCE_API_KEY')
    API_SECRET: str = config('BINANCE_API_SECRET')
    TELEGRAM_TOKEN: str = config('TELEGRAM_BOT_TOKEN')
    CHAT_ID: str = config('TELEGRAM_CHAT_ID')
    DB_URL: str = config('DATABASE_URL')
    # WEBHOOK_URL is optional, but Flask will always run for Render compatibility
    WEBHOOK_URL: Optional[str] = config('WEBHOOK_URL', default=None)
except Exception as e:
     logger.critical(f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©: {e}")
     exit(1)

logger.info(f"Binance API Key: {'Available' if API_KEY else 'Not available'}")
logger.info(f"Telegram Token: {TELEGRAM_TOKEN[:10]}...{'*' * (len(TELEGRAM_TOKEN)-10)}")
logger.info(f"Telegram Chat ID: {CHAT_ID}")
logger.info(f"Database URL: {'Available' if DB_URL else 'Not available'}")
logger.info(f"Webhook URL: {WEBHOOK_URL if WEBHOOK_URL else 'Not specified'} (Flask will always run for Render)")

# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø«ÙˆØ§Ø¨Øª ÙˆØ§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© ----------------------
TRADE_VALUE: float = 10.0
MAX_OPEN_TRADES: int = 5
SIGNAL_GENERATION_TIMEFRAME: str = '15m' # ØªÙ… Ø§Ù„ØªØºÙŠÙŠØ± Ø¥Ù„Ù‰ 15 Ø¯Ù‚ÙŠÙ‚Ø©
SIGNAL_GENERATION_LOOKBACK_DAYS: int = 3
SIGNAL_TRACKING_TIMEFRAME: str = '15m' # ØªÙ… Ø§Ù„ØªØºÙŠÙŠØ± Ø¥Ù„Ù‰ 15 Ø¯Ù‚ÙŠÙ‚Ø©
SIGNAL_TRACKING_LOOKBACK_DAYS: int = 1

# Indicator Parameters (Only those needed for ML features or essential filters)
RSI_PERIOD: int = 9 # Still needed for RSI Momentum
RSI_OVERSOLD: int = 30 # Not directly used for signal, but good to keep for context if needed later
RSI_OVERBOUGHT: int = 70 # Not directly used for signal, but good to keep for context if needed later
VOLUME_LOOKBACK_CANDLES: int = 1 # Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ù…Ø¹Ø§Øª Ù„Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø­Ø¬Ù… (1 Ø´Ù…Ø¹Ø© * 15 Ø¯Ù‚ÙŠÙ‚Ø© = 15 Ø¯Ù‚ÙŠÙ‚Ø©)
RSI_MOMENTUM_LOOKBACK_CANDLES: int = 2 # Ø¹Ø¯Ø¯ Ø§Ù„Ø´Ù…Ø¹Ø§Øª Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ²Ø§ÙŠØ¯ RSI Ù„Ù„Ø²Ø®Ù…

ENTRY_ATR_PERIOD: int = 10 # Still needed for target calculation and Supertrend
ENTRY_ATR_MULTIPLIER: float = 2 # Still needed for target calculation

SUPERTRAND_PERIOD: int = 10 # ÙØªØ±Ø© Supertrend
SUPERTRAND_MULTIPLIER: float = 3.0 # Ù…Ø¶Ø§Ø¹Ù Supertrend

MIN_PROFIT_MARGIN_PCT: float = 1.0 # Essential filter
MIN_VOLUME_15M_USDT: float = 80000.0 # Essential filter

TARGET_APPROACH_THRESHOLD_PCT: float = 0.005

BINANCE_FEE_RATE: float = 0.001

BASE_ML_MODEL_NAME: str = 'DecisionTree_Scalping_V1' # Must match the base name used in ml.py

# Global variables
conn: Optional[psycopg2.extensions.connection] = None
cur: Optional[psycopg2.extensions.cursor] = None
client: Optional[Client] = None
ticker_data: Dict[str, float] = {}
ml_models: Dict[str, Any] = {} # Global dictionary to hold loaded ML models, keyed by symbol

# ---------------------- Binance Client Setup ----------------------
try:
    logger.info("â„¹ï¸ [Binance] ØªÙ‡ÙŠØ¦Ø© Ø¹Ù…ÙŠÙ„ Binance...")
    client = Client(API_KEY, API_SECRET)
    client.ping()
    server_time = client.get_server_time()
    logger.info(f"âœ… [Binance] ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø¹Ù…ÙŠÙ„ Binance. ÙˆÙ‚Øª Ø§Ù„Ø®Ø§Ø¯Ù…: {datetime.fromtimestamp(server_time['serverTime']/1000)}")
except BinanceRequestException as req_err:
     logger.critical(f"âŒ [Binance] Ø®Ø·Ø£ ÙÙŠ Ø·Ù„Ø¨ Binance (Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„Ø´Ø¨ÙƒØ© Ø£Ùˆ Ø§Ù„Ø·Ù„Ø¨): {req_err}")
     exit(1)
except BinanceAPIException as api_err:
     logger.critical(f"âŒ [Binance] Ø®Ø·Ø£ ÙÙŠ ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª Binance (Ù…ÙØ§ØªÙŠØ­ ØºÙŠØ± ØµØ§Ù„Ø­Ø© Ø£Ùˆ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…): {api_err}")
     exit(1)
except Exception as e:
    logger.critical(f"âŒ [Binance] ÙØ´Ù„ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ø¹Ù…ÙŠÙ„ Binance: {e}")
    exit(1)

# ---------------------- Additional Indicator Functions ----------------------
def get_fear_greed_index() -> str:
    """Fetches the Fear & Greed Index from alternative.me and translates classification to Arabic."""
    classification_translation_ar = {
        "Extreme Fear": "Ø®ÙˆÙ Ø´Ø¯ÙŠØ¯", "Fear": "Ø®ÙˆÙ", "Neutral": "Ù…Ø­Ø§ÙŠØ¯",
        "Greed": "Ø¬Ø´Ø¹", "Extreme Greed": "Ø¬Ø´Ø¹ Ø´Ø¯ÙŠØ¯",
    }
    url = "https://api.alternative.me/fng/" # Corrected URL
    logger.debug(f"â„¹ï¸ [Indicators] Ø¬Ù„Ø¨ Ù…Ø¤Ø´Ø± Ø§Ù„Ø®ÙˆÙ ÙˆØ§Ù„Ø¬Ø´Ø¹ Ù…Ù† {url}...")
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        data = response.json()
        value = int(data["data"][0]["value"])
        classification_en = data["data"][0]["value_classification"]
        classification_ar = classification_translation_ar.get(classification_en, classification_en)
        logger.debug(f"âœ… [Indicators] Ù…Ø¤Ø´Ø± Ø§Ù„Ø®ÙˆÙ ÙˆØ§Ù„Ø¬Ø´Ø¹: {value} ({classification_ar})")
        return f"{value} ({classification_ar})"
    except requests.exceptions.RequestException as e:
         logger.error(f"âŒ [Indicators] Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø´Ø¨ÙƒØ© Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ù…Ø¤Ø´Ø± Ø§Ù„Ø®ÙˆÙ ÙˆØ§Ù„Ø¬Ø´Ø¹: {e}")
         return "N/A (Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø´Ø¨ÙƒØ©)"
    except (KeyError, IndexError, ValueError, json.JSONDecodeError) as e:
        logger.error(f"âŒ [Indicators] Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù…Ø¤Ø´Ø± Ø§Ù„Ø®ÙˆÙ ÙˆØ§Ù„Ø¬Ø´Ø¹: {e}")
        return "N/A (Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª)"
    except Exception as e:
        logger.error(f"âŒ [Indicators] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ù…Ø¤Ø´Ø± Ø§Ù„Ø®ÙˆÙ ÙˆØ§Ù„Ø¬Ø´Ø¹: {e}", exc_info=True)
        return "N/A (Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ)"

def fetch_historical_data(symbol: str, interval: str, days: int) -> Optional[pd.DataFrame]:
    """
    Fetches historical candlestick data from Binance for a specified number of days.
    This function relies on python-binance's get_historical_klines to handle
    internal pagination for large data ranges.
    """
    if not client:
        logger.error("âŒ [Data] Ø¹Ù…ÙŠÙ„ Binance ØºÙŠØ± Ù…Ù‡ÙŠØ£ Ù„Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
        return None
    try:
        # Calculate the start date for the entire data range needed
        start_dt = datetime.utcnow() - timedelta(days=days + 1)
        start_str_overall = start_dt.strftime("%Y-%m-%d %H:%M:%S")

        logger.debug(f"â„¹ï¸ [Data] Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª {interval} Ù„Ù€ {symbol} Ù…Ù† {start_str_overall} Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†...")

        # Map interval string to Binance client constant
        binance_interval = None
        if interval == '15m':
            binance_interval = Client.KLINE_INTERVAL_15MINUTE
        elif interval == '5m':
            binance_interval = Client.KLINE_INTERVAL_5MINUTE
        elif interval == '1h':
            binance_interval = Client.KLINE_INTERVAL_1HOUR
        elif interval == '4h':
            binance_interval = Client.KLINE_INTERVAL_4HOUR
        elif interval == '1d':
            binance_interval = Client.KLINE_INTERVAL_1DAY
        else:
            logger.error(f"âŒ [Data] ÙØªØ±Ø© Ø²Ù…Ù†ÙŠØ© ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©: {interval}")
            return None

        # Call get_historical_klines for the entire period.
        # The python-binance library is designed to handle internal pagination
        # if the requested range exceeds the API's single-request limit (e.g., 1000 klines).
        klines = client.get_historical_klines(symbol, binance_interval, start_str_overall)

        if not klines:
            logger.warning(f"âš ï¸ [Data] Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ§Ø±ÙŠØ®ÙŠØ© ({interval}) Ù„Ù€ {symbol} Ù„Ù„ÙØªØ±Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©.")
            return None

        df = pd.DataFrame(klines, columns=[
            'timestamp', 'open', 'high', 'low', 'close', 'volume',
            'close_time', 'quote_volume', 'trades', 'taker_buy_base', 'taker_buy_quote', 'ignore'
        ])

        numeric_cols = ['open', 'high', 'low', 'close', 'volume']
        for col in numeric_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce')

        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('timestamp', inplace=True)
        df = df[numeric_cols]
        initial_len = len(df)
        df.dropna(subset=numeric_cols, inplace=True)

        if len(df) < initial_len:
            logger.debug(f"â„¹ï¸ [Data] {symbol}: ØªÙ… Ø¥Ø³Ù‚Ø§Ø· {initial_len - len(df)} ØµÙÙ‹Ø§ Ø¨Ø³Ø¨Ø¨ Ù‚ÙŠÙ… NaN ÙÙŠ Ø¨ÙŠØ§Ù†Ø§Øª OHLCV.")

        if df.empty:
            logger.warning(f"âš ï¸ [Data] DataFrame Ù„Ù€ {symbol} ÙØ§Ø±Øº Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ù‚ÙŠÙ… NaN Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©.")
            return None

        # Sort by index (timestamp) to ensure chronological order
        df.sort_index(inplace=True)

        logger.debug(f"âœ… [Data] ØªÙ… Ø¬Ù„Ø¨ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© {len(df)} Ø´Ù…Ø¹Ø© ØªØ§Ø±ÙŠØ®ÙŠØ© ({interval}) Ù„Ù€ {symbol}.")
        return df

    except BinanceAPIException as api_err:
         logger.error(f"âŒ [Data] Ø®Ø·Ø£ ÙÙŠ Binance API Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù€ {symbol}: {api_err}")
         return None
    except BinanceRequestException as req_err:
         logger.error(f"âŒ [Data] Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø·Ù„Ø¨ Ø£Ùˆ Ø§Ù„Ø´Ø¨ÙƒØ© Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù€ {symbol}: {req_err}")
         return None
    except Exception as e:
        logger.error(f"âŒ [Data] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„Ù€ {symbol}: {e}", exc_info=True)
        return None


def calculate_ema(series: pd.Series, span: int) -> pd.Series:
    """Calculates Exponential Moving Average (EMA)."""
    if series is None or series.isnull().all() or len(series) < span:
        return pd.Series(index=series.index if series is not None else None, dtype=float)
    return series.ewm(span=span, adjust=False).mean()

def calculate_rsi_indicator(df: pd.DataFrame, period: int = RSI_PERIOD) -> pd.DataFrame:
    """Calculates Relative Strength Index (RSI)."""
    df = df.copy()
    if 'close' not in df.columns or df['close'].isnull().all():
        logger.warning("âš ï¸ [Indicator RSI] Ø¹Ù…ÙˆØ¯ 'close' Ù…ÙÙ‚ÙˆØ¯ Ø£Ùˆ ÙØ§Ø±Øº.")
        df['rsi'] = np.nan
        return df
    if len(df) < period:
        logger.warning(f"âš ï¸ [Indicator RSI] Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© ({len(df)} < {period}) Ù„Ø­Ø³Ø§Ø¨ RSI.")
        df['rsi'] = np.nan
        return df

    delta = df['close'].diff()
    gain = delta.clip(lower=0)
    loss = -delta.clip(upper=0)

    avg_gain = gain.ewm(com=period - 1, adjust=False).mean()
    avg_loss = loss.ewm(com=period - 1, adjust=False).mean()

    rs = avg_gain / avg_loss.replace(0, np.nan)

    rsi_series = 100 - (100 / (1 + rs))
    df['rsi'] = rsi_series.ffill().fillna(50)

    return df

def calculate_atr_indicator(df: pd.DataFrame, period: int = ENTRY_ATR_PERIOD) -> pd.DataFrame:
    """Calculates Average True Range (ATR)."""
    df = df.copy()
    required_cols = ['high', 'low', 'close']
    if not all(col in df.columns for col in required_cols) or df[required_cols].isnull().all().any():
        logger.warning("âš ï¸ [Indicator ATR] Ø£Ø¹Ù…Ø¯Ø© 'high', 'low', 'close' Ù…ÙÙ‚ÙˆØ¯Ø© Ø£Ùˆ ÙØ§Ø±ØºØ©.")
        df['atr'] = np.nan
        return df
    if len(df) < period + 1:
        logger.warning(f"âš ï¸ [Indicator ATR] Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© ({len(df)} < {period + 1}) Ù„Ø­Ø³Ø§Ø¨ ATR.")
        df['atr'] = np.nan
        return df

    high_low = df['high'] - df['low']
    high_close_prev = (df['high'] - df['close'].shift(1)).abs()
    low_close_prev = (df['low'] - df['close'].shift(1)).abs()

    tr = pd.concat([high_low, high_close_prev, low_close_prev], axis=1).max(axis=1, skipna=False)

    df['atr'] = tr.ewm(span=period, adjust=False).mean()
    return df

def calculate_supertrend(df: pd.DataFrame, period: int = SUPERTRAND_PERIOD, multiplier: float = SUPERTRAND_MULTIPLIER) -> pd.DataFrame:
    """Calculates the Supertrend indicator."""
    df = df.copy()
    required_cols = ['high', 'low', 'close']
    if not all(col in df.columns for col in required_cols) or df[required_cols].isnull().all().any():
        logger.warning("âš ï¸ [Indicator Supertrend] Ø£Ø¹Ù…Ø¯Ø© 'high', 'low', 'close' Ù…ÙÙ‚ÙˆØ¯Ø© Ø£Ùˆ ÙØ§Ø±ØºØ©. Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø­Ø³Ø§Ø¨ Supertrend.")
        df['supertrend'] = np.nan
        df['supertrend_direction'] = 0 # Neutral if cannot calculate
        return df

    # Ensure ATR is already calculated
    if 'atr' not in df.columns:
        df = calculate_atr_indicator(df, period=period) # Use Supertrend period for ATR if not already calculated
        if 'atr' not in df.columns or df['atr'].isnull().all().any():
            logger.warning("âš ï¸ [Indicator Supertrend] ÙØ´Ù„ Ø­Ø³Ø§Ø¨ ATR. Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø­Ø³Ø§Ø¨ Supertrend.")
            df['supertrend'] = np.nan
            df['supertrend_direction'] = 0
            return df

    # Calculate Basic Upper and Lower Bands
    df['basic_upper_band'] = ((df['high'] + df['low']) / 2) + (multiplier * df['atr'])
    df['basic_lower_band'] = ((df['high'] + df['low']) / 2) - (multiplier * df['atr'])

    # Initialize Final Upper and Lower Bands
    df['final_upper_band'] = 0.0
    df['final_lower_band'] = 0.0

    # Initialize Supertrend and Direction
    df['supertrend'] = 0.0
    df['supertrend_direction'] = 0 # 1 for uptrend, -1 for downtrend, 0 for neutral/flat

    # Determine Supertrend value and direction
    for i in range(1, len(df)):
        # Final Upper Band
        if df['basic_upper_band'].iloc[i] < df['final_upper_band'].iloc[i-1] or \
           df['close'].iloc[i-1] > df['final_upper_band'].iloc[i-1]:
            df.loc[df.index[i], 'final_upper_band'] = df['basic_upper_band'].iloc[i]
        else:
            df.loc[df.index[i], 'final_upper_band'] = df['final_upper_band'].iloc[i-1]

        # Final Lower Band
        if df['basic_lower_band'].iloc[i] > df['final_lower_band'].iloc[i-1] or \
           df['close'].iloc[i-1] < df['final_lower_band'].iloc[i-1]:
            df.loc[df.index[i], 'final_lower_band'] = df['basic_lower_band'].iloc[i]
        else:
            df.loc[df.index[i], 'final_lower_band'] = df['final_lower_band'].iloc[i-1]

        # Supertrend logic
        if df['supertrend_direction'].iloc[i-1] == 1: # Previous was uptrend
            if df['close'].iloc[i] < df['final_upper_band'].iloc[i]:
                df.loc[df.index[i], 'supertrend'] = df['final_upper_band'].iloc[i]
                df.loc[df.index[i], 'supertrend_direction'] = -1 # Change to downtrend
            else:
                df.loc[df.index[i], 'supertrend'] = df['final_lower_band'].iloc[i]
                df.loc[df.index[i], 'supertrend_direction'] = 1 # Remain uptrend
        elif df['supertrend_direction'].iloc[i-1] == -1: # Previous was downtrend
            if df['close'].iloc[i] > df['final_lower_band'].iloc[i]:
                df.loc[df.index[i], 'supertrend'] = df['final_lower_band'].iloc[i]
                df.loc[df.index[i], 'supertrend_direction'] = 1 # Change to uptrend
            else:
                df.loc[df.index[i], 'supertrend'] = df['final_upper_band'].iloc[i]
                df.loc[df.index[i], 'supertrend_direction'] = -1 # Remain downtrend
        else: # Initial state or neutral
            if df['close'].iloc[i] > df['final_lower_band'].iloc[i]:
                df.loc[df.index[i], 'supertrend'] = df['final_lower_band'].iloc[i]
                df.loc[df.index[i], 'supertrend_direction'] = 1
            elif df['close'].iloc[i] < df['final_upper_band'].iloc[i]:
                df.loc[df.index[i], 'supertrend'] = df['final_upper_band'].iloc[i]
                df.loc[df.index[i], 'supertrend_direction'] = -1
            else:
                df.loc[df.index[i], 'supertrend'] = df['close'].iloc[i] # Fallback
                df.loc[df.index[i], 'supertrend_direction'] = 0


    # Drop temporary columns
    df.drop(columns=['basic_upper_band', 'basic_lower_band', 'final_upper_band', 'final_lower_band'], inplace=True, errors='ignore')
    logger.debug(f"âœ… [Indicator Supertrend] ØªÙ… Ø­Ø³Ø§Ø¨ Supertrend.")
    return df

# NEW: Function to calculate numerical Bitcoin trend feature (copied from ml.py)
def _calculate_btc_trend_feature(df_btc: pd.DataFrame) -> Optional[pd.Series]:
    """
    Calculates a numerical representation of Bitcoin's trend based on EMA20 and EMA50.
    Returns 1 for bullish (ØµØ¹ÙˆØ¯ÙŠ), -1 for bearish (Ù‡Ø¨ÙˆØ·ÙŠ), 0 for neutral/sideways (Ù…Ø­Ø§ÙŠØ¯/ØªØ°Ø¨Ø°Ø¨).
    """
    logger.debug("â„¹ï¸ [Indicators] Ø­Ø³Ø§Ø¨ Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ† Ù„Ù„Ù…ÙŠØ²Ø§Øª...")
    # Need enough data for EMA50, plus a few extra candles for robustness
    min_data_for_ema = 50 + 5 # 50 for EMA50, 5 buffer

    if df_btc is None or df_btc.empty or len(df_btc) < min_data_for_ema:
        logger.warning(f"âš ï¸ [Indicators] Ø¨ÙŠØ§Ù†Ø§Øª BTC/USDT ØºÙŠØ± ÙƒØ§ÙÙŠØ© ({len(df_btc) if df_btc is not None else 0} < {min_data_for_ema}) Ù„Ø­Ø³Ø§Ø¨ Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ† Ù„Ù„Ù…ÙŠØ²Ø§Øª.")
        # Return a series of zeros (neutral) with the original index if data is insufficient
        return pd.Series(index=df_btc.index if df_btc is not None else None, data=0.0)

    df_btc_copy = df_btc.copy()
    df_btc_copy['close'] = pd.to_numeric(df_btc_copy['close'], errors='coerce')
    df_btc_copy.dropna(subset=['close'], inplace=True)

    if len(df_btc_copy) < min_data_for_ema:
        logger.warning(f"âš ï¸ [Indicators] Ø¨ÙŠØ§Ù†Ø§Øª BTC/USDT ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ù‚ÙŠÙ… NaN Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§ØªØ¬Ø§Ù‡.")
        return pd.Series(index=df_btc.index, data=0.0) # Return neutral if not enough data after dropna

    ema20 = calculate_ema(df_btc_copy['close'], 20)
    ema50 = calculate_ema(df_btc_copy['close'], 50)

    # Combine EMAs and close into a single DataFrame for easier comparison
    ema_df = pd.DataFrame({'ema20': ema20, 'ema50': ema50, 'close': df_btc_copy['close']})
    ema_df.dropna(inplace=True) # Drop rows where any EMA or close is NaN

    if ema_df.empty:
        logger.warning("âš ï¸ [Indicators] DataFrame EMA ÙØ§Ø±Øº Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ù‚ÙŠÙ… NaN. Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø­Ø³Ø§Ø¨ Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ†.")
        return pd.Series(index=df_btc.index, data=0.0) # Return neutral if no valid EMA data

    # Initialize trend column with neutral (0.0)
    trend_series = pd.Series(index=ema_df.index, data=0.0)

    # Apply trend logic:
    # Bullish: current_close > ema20 > ema50
    trend_series[(ema_df['close'] > ema_df['ema20']) & (ema_df['ema20'] > ema_df['ema50'])] = 1.0
    # Bearish: current_close < ema20 < ema50
    trend_series[(ema_df['close'] < ema_df['ema20']) & (ema_df['ema20'] < ema_df['ema50'])] = -1.0

    # Reindex to original df_btc index and fill any remaining NaNs with 0 (neutral)
    # This ensures the series has the same index as the altcoin DataFrame for merging
    final_trend_series = trend_series.reindex(df_btc.index).fillna(0.0)
    logger.debug(f"âœ… [Indicators] ØªÙ… Ø­Ø³Ø§Ø¨ Ù…ÙŠØ²Ø© Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ†. Ø£Ù…Ø«Ù„Ø©: {final_trend_series.tail().tolist()}")
    return final_trend_series

# Removed get_btc_trend_4h as it's no longer used as a direct filter, but as an ML feature.
# def get_btc_trend_4h() -> str:
#     """Calculates Bitcoin trend on 4-hour timeframe using EMA20 and EMA50."""
#     logger.debug("â„¹ï¸ [Indicators] Ø­Ø³Ø§Ø¨ Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ† Ø¹Ù„Ù‰ 4 Ø³Ø§Ø¹Ø§Øª...")
#     try:
#         df = fetch_historical_data("BTCUSDT", interval=Client.KLINE_INTERVAL_4HOUR, days=10)
#         if df is None or df.empty or len(df) < 50 + 1:
#             logger.warning("âš ï¸ [Indicators] Ø¨ÙŠØ§Ù†Ø§Øª BTC/USDT 4H ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§ØªØ¬Ø§Ù‡.")
#             return "N/A (Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ©)"

#         df['close'] = pd.to_numeric(df['close'], errors='coerce')
#         df.dropna(subset=['close'], inplace=True)
#         if len(df) < 50:
#              logger.warning("âš ï¸ [Indicators] Ø¨ÙŠØ§Ù†Ø§Øª BTC/USDT 4H ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ù‚ÙŠÙ… NaN.")
#              return "N/A (Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ©)"

#         ema20 = calculate_ema(df['close'], 20).iloc[-1]
#         ema50 = calculate_ema(df['close'], 50).iloc[-1]
#         current_close = df['close'].iloc[-1]

#         if pd.isna(ema20) or pd.isna(ema50) or pd.isna(current_close):
#             logger.warning("âš ï¸ [Indicators] Ù‚ÙŠÙ… EMA Ø£Ùˆ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ Ù„Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ† Ù‡ÙŠ NaN.")
#             return "N/A (Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­Ø³Ø§Ø¨)"

#         diff_ema20_pct = abs(current_close - ema20) / current_close if current_close > 0 else 0

#         if current_close > ema20 > ema50:
#             trend = "ØµØ¹ÙˆØ¯ ğŸ“ˆ"
#         elif current_close < ema20 < ema50:
#             trend = "Ù‡Ø¨ÙˆØ· ğŸ“‰"
#         elif diff_ema20_pct < 0.005:
#             trend = "Ø§Ø³ØªÙ‚Ø±Ø§Ø± ğŸ”„"
#         else:
#             trend = "ØªØ°Ø¨Ø°Ø¨ ğŸ”€"

#         logger.debug(f"âœ… [Indicators] Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ† 4H: {trend}")
#         return trend
#     except Exception as e:
#         logger.error(f"âŒ [Indicators] Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ† Ø¹Ù„Ù‰ 4 Ø³Ø§Ø¹Ø§Øª: {e}", exc_info=True)
#         return "N/A (Ø®Ø·Ø£)"

# ---------------------- Database Connection Setup ----------------------
def init_db(retries: int = 5, delay: int = 5) -> None:
    """Initializes database connection and creates tables if they don't exist."""
    global conn, cur
    logger.info("[DB] Ø¨Ø¯Ø¡ ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    for attempt in range(retries):
        try:
            logger.info(f"[DB] Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}/{retries})...")
            conn = psycopg2.connect(DB_URL, connect_timeout=10, cursor_factory=RealDictCursor)
            conn.autocommit = False
            cur = conn.cursor()
            logger.info("âœ… [DB] ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­.")

            # --- Create or update signals table (Modified schema) ---
            logger.info("[DB] Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù†/Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ 'signals'...")
            cur.execute("""
                CREATE TABLE IF NOT EXISTS signals (
                    id SERIAL PRIMARY KEY,
                    symbol TEXT NOT NULL,
                    entry_price DOUBLE PRECISION NOT NULL,
                    initial_target DOUBLE PRECISION NOT NULL,
                    current_target DOUBLE PRECISION NOT NULL,
                    r2_score DOUBLE PRECISION,
                    volume_15m DOUBLE PRECISION,
                    achieved_target BOOLEAN DEFAULT FALSE,
                    closing_price DOUBLE PRECISION,
                    closed_at TIMESTAMP,
                    sent_at TIMESTAMP DEFAULT NOW(),
                    entry_time TIMESTAMP DEFAULT NOW(),
                    time_to_target INTERVAL,
                    profit_percentage DOUBLE PRECISION,
                    strategy_name TEXT,
                    signal_details JSONB
                );""")
            conn.commit()
            logger.info("âœ… [DB] Ø¬Ø¯ÙˆÙ„ 'signals' Ù…ÙˆØ¬ÙˆØ¯ Ø£Ùˆ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡.")

            # --- Create ml_models table (NEW) ---
            logger.info("[DB] Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù†/Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ 'ml_models'...")
            cur.execute("""
                CREATE TABLE IF NOT EXISTS ml_models (
                    id SERIAL PRIMARY KEY,
                    model_name TEXT NOT NULL UNIQUE,
                    model_data BYTEA NOT NULL,
                    trained_at TIMESTAMP DEFAULT NOW(),
                    metrics JSONB
                );""")
            conn.commit()
            logger.info("âœ… [DB] Ø¬Ø¯ÙˆÙ„ 'ml_models' Ù…ÙˆØ¬ÙˆØ¯ Ø£Ùˆ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡.")

            # --- Create market_dominance table (if it doesn't exist) ---
            logger.info("[DB] Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù†/Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ 'market_dominance'...")
            cur.execute("""
                CREATE TABLE IF NOT EXISTS market_dominance (
                    id SERIAL PRIMARY KEY,
                    recorded_at TIMESTAMP DEFAULT NOW(),
                    btc_dominance DOUBLE PRECISION,
                    eth_dominance DOUBLE PRECISION
                );
            """)
            conn.commit()
            logger.info("âœ… [DB] Ø¬Ø¯ÙˆÙ„ 'market_dominance' Ù…ÙˆØ¬ÙˆØ¯ Ø£Ùˆ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡.")

            logger.info("âœ… [DB] ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­.")
            return

        except OperationalError as op_err:
            logger.error(f"âŒ [DB] Ø®Ø·Ø£ ØªØ´ØºÙŠÙ„ÙŠ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ (Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}): {op_err}")
            if conn: conn.rollback()
            if attempt == retries - 1:
                 logger.critical("âŒ [DB] ÙØ´Ù„Øª Ø¬Ù…ÙŠØ¹ Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
                 raise op_err
            time.sleep(delay)
        except Exception as e:
            logger.critical(f"âŒ [DB] ÙØ´Ù„ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}): {e}", exc_info=True)
            if conn: conn.rollback()
            if attempt == retries - 1:
                 logger.critical("âŒ [DB] ÙØ´Ù„Øª Ø¬Ù…ÙŠØ¹ Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
                 raise e
            time.sleep(delay)

    logger.critical("âŒ [DB] ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯ Ø¹Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø§Øª.")
    exit(1)


def check_db_connection() -> bool:
    """Checks database connection status and re-initializes if necessary."""
    global conn, cur
    try:
        if conn is None or conn.closed != 0:
            logger.warning("âš ï¸ [DB] Ø§Ù„Ø§ØªØµØ§Ù„ Ù…ØºÙ„Ù‚ Ø£Ùˆ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙ‡ÙŠØ¦Ø©...")
            init_db()
            return True
        else:
             with conn.cursor() as check_cur:
                  check_cur.execute("SELECT 1;")
                  check_cur.fetchone()
             return True
    except (OperationalError, InterfaceError) as e:
        logger.error(f"âŒ [DB] ÙÙ‚Ø¯Ø§Ù† Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ({e}). Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙ‡ÙŠØ¦Ø©...")
        try:
             init_db()
             return True
        except Exception as recon_err:
            logger.error(f"âŒ [DB] ÙØ´Ù„Øª Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø¹Ø¯ ÙÙ‚Ø¯Ø§Ù† Ø§Ù„Ø§ØªØµØ§Ù„: {recon_err}")
            return False
    except Exception as e:
        logger.error(f"âŒ [DB] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„: {e}", exc_info=True)
        try:
            init_db()
            return True
        except Exception as recon_err:
             logger.error(f"âŒ [DB] ÙØ´Ù„Øª Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø¹Ø¯ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {recon_err}")
             return False

def load_ml_model_from_db(symbol: str) -> Optional[Any]:
    """Loads the latest trained ML model for a specific symbol from the database."""
    global ml_models
    model_name = f"{BASE_ML_MODEL_NAME}_{symbol}"

    if model_name in ml_models:
        logger.debug(f"â„¹ï¸ [ML Model] Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ '{model_name}' Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©.")
        return ml_models[model_name]

    if not check_db_connection() or not conn:
        logger.error(f"âŒ [ML Model] Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ML Ù„Ù€ {symbol} Ø¨Ø³Ø¨Ø¨ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
        return None

    try:
        with conn.cursor() as db_cur:
            db_cur.execute("SELECT model_data FROM ml_models WHERE model_name = %s ORDER BY trained_at DESC LIMIT 1;", (model_name,))
            result = db_cur.fetchone()
            if result and result['model_data']:
                model = pickle.loads(result['model_data'])
                ml_models[model_name] = model # Store in global dictionary
                logger.info(f"âœ… [ML Model] ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ML '{model_name}' Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­.")
                return model
            else:
                logger.warning(f"âš ï¸ [ML Model] Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ ML Ø¨Ø§Ø³Ù… '{model_name}' ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. ÙŠØ±Ø¬Ù‰ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙˆÙ„Ø§Ù‹.")
                return None
    except psycopg2.Error as db_err:
        logger.error(f"âŒ [ML Model] Ø®Ø·Ø£ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ML Ù„Ù€ {symbol}: {db_err}", exc_info=True)
        return None
    except pickle.UnpicklingError as unpickle_err:
        logger.error(f"âŒ [ML Model] Ø®Ø·Ø£ ÙÙŠ ÙÙƒ ØªØ³Ù„Ø³Ù„ Ù†Ù…ÙˆØ°Ø¬ ML Ù„Ù€ {symbol}: {unpickle_err}. Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªØ§Ù„ÙÙ‹Ø§ Ø£Ùˆ ØªÙ… Ø­ÙØ¸Ù‡ Ø¨Ø¥ØµØ¯Ø§Ø± Ù…Ø®ØªÙ„Ù.", exc_info=True)
        return None
    except Exception as e:
        logger.error(f"âŒ [ML Model] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ML Ù„Ù€ {symbol}: {e}", exc_info=True)
        return None


def convert_np_values(obj: Any) -> Any:
    """Converts NumPy data types to native Python types for JSON and DB compatibility."""
    if isinstance(obj, dict):
        return {k: convert_np_values(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [convert_np_values(item) for item in obj]
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, (np.integer, np.int_)):
        return int(obj)
    elif isinstance(obj, (np.floating, np.float64)):
        return float(obj)
    elif isinstance(obj, (np.bool_)):
        return bool(obj)
    elif pd.isna(obj):
        return None
    else:
        return obj

# ---------------------- WebSocket Management for Ticker Prices ----------------------
def handle_ticker_message(msg: Union[List[Dict[str, Any]], Dict[str, Any]]) -> None:
    """Handles incoming WebSocket messages for mini-ticker prices."""
    global ticker_data
    try:
        if isinstance(msg, list):
            for ticker_item in msg:
                symbol = ticker_item.get('s')
                price_str = ticker_item.get('c')
                if symbol and 'USDT' in symbol and price_str:
                    try:
                        ticker_data[symbol] = float(price_str)
                    except ValueError:
                         logger.warning(f"âš ï¸ [WS] Ù‚ÙŠÙ…Ø© Ø³Ø¹Ø± ØºÙŠØ± ØµØ§Ù„Ø­Ø© Ù„Ù„Ø±Ù…Ø² {symbol}: '{price_str}'")
        elif isinstance(msg, dict):
             if msg.get('e') == 'error':
                 logger.error(f"âŒ [WS] Ø±Ø³Ø§Ù„Ø© Ø®Ø·Ø£ Ù…Ù† WebSocket: {msg.get('m', 'Ù„Ø§ ØªÙˆØ¬Ø¯ ØªÙØ§ØµÙŠÙ„ Ø®Ø·Ø£')}")
             elif msg.get('stream') and msg.get('data'):
                 for ticker_item in msg.get('data', []):
                    symbol = ticker_item.get('s')
                    price_str = ticker_item.get('c')
                    if symbol and 'USDT' in symbol and price_str:
                        try:
                            ticker_data[symbol] = float(price_str)
                        except ValueError:
                             logger.warning(f"âš ï¸ [WS] Ù‚ÙŠÙ…Ø© Ø³Ø¹Ø± ØºÙŠØ± ØµØ§Ù„Ø­Ø© Ù„Ù„Ø±Ù…Ø² {symbol} ÙÙŠ Ø§Ù„Ø¨Ø« Ø§Ù„Ù…Ø¬Ù…Ø¹: '{price_str}'")
        else:
             logger.warning(f"âš ï¸ [WS] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø±Ø³Ø§Ù„Ø© WebSocket Ø¨ØªÙ†Ø³ÙŠÙ‚ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {type(msg)}")

    except Exception as e:
        logger.error(f"âŒ [WS] Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªÙŠÙƒØ±: {e}", exc_info=True)


def run_ticker_socket_manager() -> None:
    """Runs and manages the WebSocket connection for mini-ticker."""
    while True:
        try:
            logger.info("â„¹ï¸ [WS] Ø¨Ø¯Ø¡ Ø¥Ø¯Ø§Ø±Ø© WebSocket Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„ØªÙŠÙƒØ±...")
            twm = ThreadedWebsocketManager(api_key=API_KEY, api_secret=API_SECRET)
            twm.start()

            stream_name = twm.start_miniticker_socket(callback=handle_ticker_message)
            logger.info(f"âœ… [WS] ØªÙ… Ø¨Ø¯Ø¡ Ø¨Ø« WebSocket: {stream_name}")

            twm.join()
            logger.warning("âš ï¸ [WS] ØªÙˆÙ‚ÙØª Ø¥Ø¯Ø§Ø±Ø© WebSocket. Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ´ØºÙŠÙ„...")

        except Exception as e:
            logger.error(f"âŒ [WS] Ø®Ø·Ø£ ÙØ§Ø¯Ø­ ÙÙŠ Ø¥Ø¯Ø§Ø±Ø© WebSocket: {e}. Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ ÙÙŠ 15 Ø«Ø§Ù†ÙŠØ©...", exc_info=True)

        time.sleep(15)

# ---------------------- Other Helper Functions (Volume) ----------------------
def fetch_recent_volume(symbol: str, interval: str = SIGNAL_GENERATION_TIMEFRAME, num_candles: int = VOLUME_LOOKBACK_CANDLES) -> float:
    """Fetches the trading volume in USDT for the last `num_candles` of the specified `interval`."""
    if not client:
         logger.error(f"âŒ [Data Volume] Ø¹Ù…ÙŠÙ„ Binance ØºÙŠØ± Ù…Ù‡ÙŠØ£ Ù„Ø¬Ù„Ø¨ Ø§Ù„Ø­Ø¬Ù… Ù„Ù€ {symbol}.")
         return 0.0
    try:
        logger.debug(f"â„¹ï¸ [Data Volume] Ø¬Ù„Ø¨ Ø­Ø¬Ù… Ø¢Ø®Ø± {num_candles} Ø´Ù…Ø¹Ø§Øª {interval} Ù„Ù€ {symbol}...")

        # Map interval string to Binance client constant
        binance_interval = None
        if interval == '15m':
            binance_interval = Client.KLINE_INTERVAL_15MINUTE
        elif interval == '5m':
            binance_interval = Client.KLINE_INTERVAL_5MINUTE
        elif interval == '1h':
            binance_interval = Client.KLINE_INTERVAL_1HOUR
        elif interval == '4h':
            binance_interval = Client.KLINE_INTERVAL_4HOUR
        elif interval == '1d':
            binance_interval = Client.KLINE_INTERVAL_1DAY
        else:
            logger.error(f"âŒ [Data Volume] ÙØªØ±Ø© Ø²Ù…Ù†ÙŠØ© ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©: {interval}")
            return 0.0

        klines = client.get_klines(symbol=symbol, interval=binance_interval, limit=num_candles)
        if not klines or len(klines) < num_candles:
             logger.warning(f"âš ï¸ [Data Volume] Ø¨ÙŠØ§Ù†Ø§Øª {interval} ØºÙŠØ± ÙƒØ§ÙÙŠØ© (Ø£Ù‚Ù„ Ù…Ù† {num_candles} Ø´Ù…Ø¹Ø©) Ù„Ù€ {symbol}.")
             return 0.0

        # k[7] is the quote asset volume (e.g., USDT volume)
        volume_usdt = sum(float(k[7]) for k in klines if len(k) > 7 and k[7])
        logger.debug(f"âœ… [Data Volume] Ø³ÙŠÙˆÙ„Ø© Ø¢Ø®Ø± {num_candles} Ø´Ù…Ø¹Ø§Øª {interval} Ù„Ù€ {symbol}: {volume_usdt:.2f} USDT")
        return volume_usdt
    except (BinanceAPIException, BinanceRequestException) as binance_err:
         logger.error(f"âŒ [Data Volume] Ø®Ø·Ø£ ÙÙŠ Binance API Ø£Ùˆ Ø§Ù„Ø´Ø¨ÙƒØ© Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ø§Ù„Ø­Ø¬Ù… Ù„Ù€ {symbol}: {binance_err}")
         return 0.0
    except Exception as e:
        logger.error(f"âŒ [Data Volume] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ø§Ù„Ø­Ø¬Ù… Ù„Ù€ {symbol}: {e}", exc_info=True)
        return 0.0

# ---------------------- Reading and Validating Symbols List ----------------------
def get_crypto_symbols(filename: str = 'crypto_list.txt') -> List[str]:
    """
    Reads the list of currency symbols from a text file, then validates them
    as valid USDT pairs available for Spot trading on Binance.
    """
    raw_symbols: List[str] = []
    logger.info(f"â„¹ï¸ [Data] Ù‚Ø±Ø§Ø¡Ø© Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ù…ÙˆØ² Ù…Ù† Ø§Ù„Ù…Ù„Ù '{filename}'...")
    try:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        file_path = os.path.join(script_dir, filename)

        if not os.path.exists(file_path):
            file_path = os.path.abspath(filename)
            if not os.path.exists(file_path):
                 logger.error(f"âŒ [Data] Ø§Ù„Ù…Ù„Ù '{filename}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø³ÙƒØ±Ø¨Øª Ø£Ùˆ Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠ.")
                 return []
            else:
                 logger.warning(f"âš ï¸ [Data] Ø§Ù„Ù…Ù„Ù '{filename}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø³ÙƒØ±Ø¨Øª. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ù„Ù ÙÙŠ Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠ: '{file_path}'")

        with open(file_path, 'r', encoding='utf-8') as f:
            raw_symbols = [f"{line.strip().upper().replace('USDT', '')}USDT"
                           for line in f if line.strip() and not line.startswith('#')]
        raw_symbols = sorted(list(set(raw_symbols)))
        logger.info(f"â„¹ï¸ [Data] ØªÙ… Ù‚Ø±Ø§Ø¡Ø© {len(raw_symbols)} Ø±Ù…Ø²Ù‹Ø§ Ù…Ø¨Ø¯Ø¦ÙŠÙ‹Ø§ Ù…Ù† '{file_path}'.")

    except FileNotFoundError:
         logger.error(f"âŒ [Data] Ø§Ù„Ù…Ù„Ù '{filename}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")
         return []
    except Exception as e:
        logger.error(f"âŒ [Data] Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù '{filename}': {e}", exc_info=True)
        return []

    if not raw_symbols:
         logger.warning("âš ï¸ [Data] Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ø£ÙˆÙ„ÙŠØ© ÙØ§Ø±ØºØ©.")
         return []

    if not client:
        logger.error("âŒ [Data Validation] Ø¹Ù…ÙŠÙ„ Binance ØºÙŠØ± Ù…Ù‡ÙŠØ£. Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ².")
        return raw_symbols

    try:
        logger.info("â„¹ï¸ [Data Validation] Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ² ÙˆØ­Ø§Ù„Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ù…Ù† Binance API...")
        exchange_info = client.get_exchange_info()
        valid_trading_usdt_symbols = {
            s['symbol'] for s in exchange_info['symbols']
            if s.get('quoteAsset') == 'USDT' and
               s.get('status') == 'TRADING' and
               s.get('isSpotTradingAllowed') is True
        }
        logger.info(f"â„¹ï¸ [Data Validation] ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(valid_trading_usdt_symbols)} Ø²ÙˆØ¬ ØªØ¯Ø§ÙˆÙ„ USDT ØµØ§Ù„Ø­ ÙÙŠ Spot Ø¹Ù„Ù‰ Binance.")
        validated_symbols = [symbol for symbol in raw_symbols if symbol in valid_trading_usdt_symbols]

        removed_count = len(raw_symbols) - len(validated_symbols)
        if removed_count > 0:
            removed_symbols = set(raw_symbols) - set(validated_symbols)
            logger.warning(f"âš ï¸ [Data Validation] ØªÙ… Ø¥Ø²Ø§Ù„Ø© {removed_count} Ø±Ù…Ø² ØªØ¯Ø§ÙˆÙ„ USDT ØºÙŠØ± ØµØ§Ù„Ø­ Ø£Ùˆ ØºÙŠØ± Ù…ØªØ§Ø­ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©: {', '.join(removed_symbols)}")

        logger.info(f"âœ… [Data Validation] ØªÙ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ². Ø§Ø³ØªØ®Ø¯Ø§Ù… {len(validated_symbols)} Ø±Ù…Ø²Ù‹Ø§ ØµØ§Ù„Ø­Ù‹Ø§.")
        return validated_symbols

    except (BinanceAPIException, BinanceRequestException) as binance_err:
         logger.error(f"âŒ [Data Validation] Ø®Ø·Ø£ ÙÙŠ Binance API Ø£Ùˆ Ø§Ù„Ø´Ø¨ÙƒØ© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ²: {binance_err}")
         logger.warning("âš ï¸ [Data Validation] Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø¨Ø¯ÙˆÙ† Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Binance.")
         return raw_symbols
    except Exception as api_err:
         logger.error(f"âŒ [Data Validation] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø±Ù…ÙˆØ² Binance: {api_err}", exc_info=True)
         logger.warning("âš ï¸ [Data Validation] Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø¨Ø¯ÙˆÙ† Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Binance.")
         return raw_symbols

# ---------------------- Comprehensive Performance Report Generation Function ----------------------
def generate_performance_report() -> str:
    """Generates a comprehensive performance report from the database in Arabic, including recent closed trades and USD profit/loss."""
    logger.info("â„¹ï¸ [Report] Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡...")
    if not check_db_connection() or not conn or not cur:
        logger.error("âŒ [Report] Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±ØŒ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
        return "âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±ØŒ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."
    try:
        with conn.cursor() as report_cur:
            report_cur.execute("SELECT id, symbol, entry_price, entry_time FROM signals WHERE achieved_target = FALSE ORDER BY entry_time DESC;")
            open_signals = report_cur.fetchall()
            open_signals_count = len(open_signals)

            report_cur.execute("""
                SELECT
                    COUNT(*) AS total_closed,
                    COUNT(*) FILTER (WHERE profit_percentage > 0) AS winning_signals,
                    COUNT(*) FILTER (WHERE profit_percentage <= 0) AS losing_signals,
                    COALESCE(SUM(profit_percentage) FILTER (WHERE profit_percentage > 0), 0) AS gross_profit_pct_sum,
                    COALESCE(SUM(profit_percentage) FILTER (WHERE profit_percentage <= 0), 0) AS gross_loss_pct_sum,
                    COALESCE(AVG(profit_percentage) FILTER (WHERE profit_percentage > 0), 0) AS avg_win_pct,
                    COALESCE(AVG(profit_percentage) FILTER (WHERE profit_percentage <= 0), 0) AS avg_loss_pct
                FROM signals
                WHERE achieved_target = TRUE;
            """)
            closed_stats = report_cur.fetchone() or {}

            total_closed = closed_stats.get('total_closed', 0)
            winning_signals = closed_stats.get('winning_signals', 0)
            losing_signals = closed_stats.get('losing_signals', 0)
            gross_profit_pct_sum = closed_stats.get('gross_profit_pct_sum', 0.0)
            gross_loss_pct_sum = closed_stats.get('gross_loss_pct_sum', 0.0)
            avg_win_pct = closed_stats.get('avg_win_pct', 0.0)
            avg_loss_pct = closed_stats.get('avg_loss_pct', 0.0)

            # Calculate USD profit/loss based on a fixed TRADE_VALUE
            gross_profit_usd = (gross_profit_pct_sum / 100.0) * TRADE_VALUE
            gross_loss_usd = (gross_loss_pct_sum / 100.0) * TRADE_VALUE

            # Total fees for all closed trades (entry and exit)
            total_fees_usd = total_closed * (TRADE_VALUE * BINANCE_FEE_RATE + (TRADE_VALUE * (1 + (avg_win_pct / 100.0 if avg_win_pct > 0 else 0))) * BINANCE_FEE_RATE)

            net_profit_usd = gross_profit_usd + gross_loss_usd - total_fees_usd # gross_loss_usd is already negative
            net_profit_pct = (net_profit_usd / (total_closed * TRADE_VALUE)) * 100 if total_closed * TRADE_VALUE > 0 else 0.0


            win_rate = (winning_signals / total_closed) * 100 if total_closed > 0 else 0.0
            profit_factor = float('inf') if gross_loss_pct_sum == 0 else (gross_profit_pct_sum / abs(gross_loss_pct_sum))

        report = (
            f"ğŸ“Š *ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø´Ø§Ù…Ù„:*\n"
            f"_(Ø§ÙØªØ±Ø§Ø¶ Ø­Ø¬Ù… Ø§Ù„ØµÙÙ‚Ø©: ${TRADE_VALUE:,.2f} ÙˆØ±Ø³ÙˆÙ… Binance: {BINANCE_FEE_RATE*100:.2f}% Ù„ÙƒÙ„ ØµÙÙ‚Ø©)_ \n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"ğŸ“ˆ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹: *{open_signals_count}*\n"
        )

        if open_signals:
            report += "  â€¢ Ø§Ù„ØªÙØ§ØµÙŠÙ„:\n"
            for signal in open_signals:
                safe_symbol = str(signal['symbol']).replace('_', '\\_').replace('*', '\\*').replace('[', '\\[').replace('`', '\\`')
                entry_time_str = signal['entry_time'].strftime('%Y-%m-%d %H:%M') if signal['entry_time'] else 'N/A'
                report += f"    - `{safe_symbol}` (Ø¯Ø®ÙˆÙ„: ${signal['entry_price']:.8g} | ÙØªØ­: {entry_time_str})\n"
        else:
            report += "  â€¢ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø´Ø§Ø±Ø§Øª Ù…ÙØªÙˆØ­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹.\n"

        report += (
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"ğŸ“‰ *Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø©:*\n"
            f"  â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ØºÙ„Ù‚Ø©: *{total_closed}*\n"
            f"  âœ… Ø¥Ø´Ø§Ø±Ø§Øª Ø±Ø§Ø¨Ø­Ø©: *{winning_signals}* ({win_rate:.2f}%)\n"
            f"  âŒ Ø¥Ø´Ø§Ø±Ø§Øª Ø®Ø§Ø³Ø±Ø©: *{losing_signals}*\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"ğŸ’° *Ø§Ù„Ø±Ø¨Ø­ÙŠØ© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©:*\n"
            f"  â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: *{gross_profit_pct_sum:+.2f}%* (â‰ˆ *${gross_profit_usd:+.2f}*)\n"
            f"  â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: *{gross_loss_pct_sum:+.2f}%* (â‰ˆ *${gross_loss_usd:+.2f}*)\n"
            f"  â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©: *${total_fees_usd:,.2f}*\n"
            f"  â€¢ *Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„ØµØ§ÙÙŠ:* *{net_profit_pct:+.2f}%* (â‰ˆ *${net_profit_usd:+.2f}*)\n"
            f"  â€¢ Ù…ØªÙˆØ³Ø· Ø§Ù„ØµÙÙ‚Ø© Ø§Ù„Ø±Ø§Ø¨Ø­Ø©: *{avg_win_pct:+.2f}%*\n"
            f"  â€¢ Ù…ØªÙˆØ³Ø· Ø§Ù„ØµÙÙ‚Ø© Ø§Ù„Ø®Ø§Ø³Ø±Ø©: *{avg_loss_pct:+.2f}%*\n"
            f"  â€¢ Ø¹Ø§Ù…Ù„ Ø§Ù„Ø±Ø¨Ø­: *{'âˆ' if profit_factor == float('inf') else f'{profit_factor:.2f}'}*\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"ğŸ•°ï¸ _Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ù…Ø­Ø¯Ø« Ø­ØªÙ‰: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}_"
        )

        logger.info("âœ… [Report] ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¨Ù†Ø¬Ø§Ø­.")
        return report

    except psycopg2.Error as db_err:
        logger.error(f"âŒ [Report] Ø®Ø·Ø£ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø«Ù†Ø§Ø¡ Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡: {db_err}")
        if conn: conn.rollback()
        return "âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø«Ù†Ø§Ø¡ Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡."
    except Exception as e:
        logger.error(f"âŒ [Report] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡: {e}", exc_info=True)
        return "âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡."

# ---------------------- Trading Strategy (Adjusted for ML-Only) -------------------

class ScalpingTradingStrategy:
    """Encapsulates the trading strategy logic, now relying solely on ML model prediction for buy signals."""

    def __init__(self, symbol: str):
        self.symbol = symbol
        self.ml_model = load_ml_model_from_db(symbol) # Load model specific to this symbol
        if self.ml_model is None:
            logger.warning(f"âš ï¸ [Strategy {self.symbol}] Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø© Ù„Ù€ {symbol}. Ù„Ù† ØªØªÙ…ÙƒÙ† Ø§Ù„Ø¥Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ù…Ù† ØªÙˆÙ„ÙŠØ¯ Ø¥Ø´Ø§Ø±Ø§Øª.")

        # Updated feature columns to include btc_trend_feature and supertrend_direction
        self.feature_columns_for_ml = [ # Features expected by the ML model
            'volume_15m_avg',
            'rsi_momentum_bullish',
            'btc_trend_feature', # NEW: Bitcoin trend feature
            'supertrend_direction' # NEW: Supertrend direction feature
        ]

    def populate_indicators(self, df: pd.DataFrame) -> Optional[pd.DataFrame]:
        """Calculates only the required indicators for the ML model's features."""
        logger.debug(f"â„¹ï¸ [Strategy {self.symbol}] Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ù„Ù†Ù…ÙˆØ°Ø¬ ML...")
        # min_len_required should reflect only indicators used for ML features
        # 50 + 5 for BTC EMA calculation, plus some buffer, plus Supertrend period
        min_len_required = max(RSI_PERIOD, RSI_MOMENTUM_LOOKBACK_CANDLES, VOLUME_LOOKBACK_CANDLES, ENTRY_ATR_PERIOD, SUPERTRAND_PERIOD, 55) + 5

        if len(df) < min_len_required:
            logger.warning(f"âš ï¸ [Strategy {self.symbol}] DataFrame Ù‚ØµÙŠØ± Ø¬Ø¯Ù‹Ø§ ({len(df)} < {min_len_required}) Ù„Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø±Ø§Øª ML.")
            return None

        try:
            df_calc = df.copy()
            # Calculate RSI as it's a prerequisite for rsi_momentum_bullish
            df_calc = calculate_rsi_indicator(df_calc, RSI_PERIOD)
            # Calculate ATR for target price calculation and Supertrend
            df_calc = calculate_atr_indicator(df_calc, ENTRY_ATR_PERIOD)
            # Calculate Supertrend
            df_calc = calculate_supertrend(df_calc, SUPERTRAND_PERIOD, SUPERTRAND_MULTIPLIER)


            # Ø¥Ø¶Ø§ÙØ© Ù…ÙŠØ²Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©: Ù…ØªÙˆØ³Ø· Ø­Ø¬Ù… Ø§Ù„Ø³ÙŠÙˆÙ„Ø© Ù„Ø¢Ø®Ø± 15 Ø¯Ù‚ÙŠÙ‚Ø© (1 Ø´Ù…Ø¹Ø© 15m)
            df_calc['volume_15m_avg'] = df_calc['volume'].rolling(window=VOLUME_LOOKBACK_CANDLES, min_periods=1).mean()

            # Ø¥Ø¶Ø§ÙØ© Ù…Ø¤Ø´Ø± Ø²Ø®Ù… ØµØ¹ÙˆØ¯ÙŠ (RSI Momentum)
            df_calc['rsi_momentum_bullish'] = 0
            if len(df_calc) >= RSI_MOMENTUM_LOOKBACK_CANDLES + 1:
                for i in range(RSI_MOMENTUM_LOOKBACK_CANDLES, len(df_calc)):
                    rsi_slice = df_calc['rsi'].iloc[i - RSI_MOMENTUM_LOOKBACK_CANDLES : i + 1]
                    if not rsi_slice.isnull().any() and np.all(np.diff(rsi_slice) > 0) and rsi_slice.iloc[-1] > 50:
                        df_calc.loc[df_calc.index[i], 'rsi_momentum_bullish'] = 1

            # --- NEW: Fetch and calculate BTC trend feature ---
            # Fetch BTC data for the same period and interval
            btc_df = fetch_historical_data("BTCUSDT", interval=SIGNAL_GENERATION_TIMEFRAME, days=SIGNAL_GENERATION_LOOKBACK_DAYS)
            btc_trend_series = None
            if btc_df is not None and not btc_df.empty:
                btc_trend_series = _calculate_btc_trend_feature(btc_df)
                if btc_trend_series is not None:
                    # Merge BTC trend with the current symbol's DataFrame based on timestamp index
                    df_calc = df_calc.merge(btc_trend_series.rename('btc_trend_feature'),
                                            left_index=True, right_index=True, how='left')
                    df_calc['btc_trend_feature'] = df_calc['btc_trend_feature'].fillna(0.0)
                    logger.debug(f"â„¹ï¸ [Strategy {self.symbol}] ØªÙ… Ø¯Ù…Ø¬ Ù…ÙŠØ²Ø© Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ†.")
                else:
                    logger.warning(f"âš ï¸ [Strategy {self.symbol}] ÙØ´Ù„ Ø­Ø³Ø§Ø¨ Ù…ÙŠØ²Ø© Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ†. Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… 0 ÙƒÙ‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù€ 'btc_trend_feature'.")
                    df_calc['btc_trend_feature'] = 0.0
            else:
                logger.warning(f"âš ï¸ [Strategy {self.symbol}] ÙØ´Ù„ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ†. Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… 0 ÙƒÙ‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù€ 'btc_trend_feature'.")
                df_calc['btc_trend_feature'] = 0.0


            # Ensure all feature columns for ML exist and are numeric
            for col in self.feature_columns_for_ml:
                if col not in df_calc.columns:
                    logger.warning(f"âš ï¸ [Strategy {self.symbol}] Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…ÙŠØ²Ø© Ø§Ù„Ù…ÙÙ‚ÙˆØ¯ Ù„Ù†Ù…ÙˆØ°Ø¬ ML: {col}")
                    df_calc[col] = np.nan # Add missing column as NaN
                else:
                    df_calc[col] = pd.to_numeric(df_calc[col], errors='coerce')

            initial_len = len(df_calc)
            # Use all required columns for dropna, including ML features and ATR for target
            all_required_cols = list(set(self.feature_columns_for_ml + [
                'open', 'high', 'low', 'close', 'volume', 'atr', 'supertrend' # 'supertrend' for debugging, not strictly for ML features
            ]))
            df_cleaned = df_calc.dropna(subset=all_required_cols).copy()
            dropped_count = initial_len - len(df_cleaned)

            if dropped_count > 0:
                 logger.debug(f"â„¹ï¸ [Strategy {self.symbol}] ØªÙ… Ø¥Ø³Ù‚Ø§Ø· {dropped_count} ØµÙÙ‹Ø§ Ø¨Ø³Ø¨Ø¨ Ù‚ÙŠÙ… NaN ÙÙŠ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª.")
            if df_cleaned.empty:
                logger.warning(f"âš ï¸ [Strategy {self.symbol}] DataFrame ÙØ§Ø±Øº Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ù‚ÙŠÙ… NaN Ù„Ù„Ù…Ø¤Ø´Ø±Ø§Øª.")
                return None

            latest = df_cleaned.iloc[-1]
            logger.debug(f"âœ… [Strategy {self.symbol}] ØªÙ… Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø±Ø§Øª ML. Ø£Ø­Ø¯Ø« Ø­Ø¬Ù… 15 Ø¯Ù‚ÙŠÙ‚Ø©: {latest.get('volume_15m_avg', np.nan):.2f}, RSI Momentum: {latest.get('rsi_momentum_bullish', np.nan)}, BTC Trend: {latest.get('btc_trend_feature', np.nan)}, ATR: {latest.get('atr', np.nan):.4f}, Supertrend Direction: {latest.get('supertrend_direction', np.nan)}")
            return df_cleaned

        except KeyError as ke:
             logger.error(f"âŒ [Strategy {self.symbol}] Ø®Ø·Ø£: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ Ù…Ø·Ù„ÙˆØ¨ Ø£Ø«Ù†Ø§Ø¡ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±: {ke}", exc_info=True)
             return None
        except Exception as e:
            logger.error(f"âŒ [Strategy {self.symbol}] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±: {e}", exc_info=True)
            return None


    def generate_buy_signal(self, df_processed: pd.DataFrame) -> Optional[Dict[str, Any]]:
        """
        Generates a buy signal based solely on the ML model's bullish prediction,
        followed by essential filters (volume, profit margin).
        """
        logger.debug(f"â„¹ï¸ [Strategy {self.symbol}] Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø´Ø§Ø±Ø© Ø´Ø±Ø§Ø¡ (ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ ML ÙÙ‚Ø·)...")

        min_signal_data_len = max(VOLUME_LOOKBACK_CANDLES, RSI_MOMENTUM_LOOKBACK_CANDLES, ENTRY_ATR_PERIOD, SUPERTRAND_PERIOD, 55) + 1 # Adjusted for BTC trend feature and Supertrend
        if df_processed is None or df_processed.empty or len(df_processed) < min_signal_data_len:
            logger.warning(f"âš ï¸ [Strategy {self.symbol}] DataFrame ÙØ§Ø±Øº Ø£Ùˆ Ù‚ØµÙŠØ± Ø¬Ø¯Ù‹Ø§ (<{min_signal_data_len})ØŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø´Ø§Ø±Ø©.")
            return None

        # Ensure all required columns for signal generation, including ML features, are present
        required_cols_for_signal = list(set(self.feature_columns_for_ml + [
            'close', 'atr' # 'close' is used for ATR and other historical calculations, but not for current price
        ]))
        missing_cols = [col for col in required_cols_for_signal if col not in df_processed.columns]
        if missing_cols:
            logger.warning(f"âš ï¸ [Strategy {self.symbol}] DataFrame ÙŠÙØªÙ‚Ø¯ Ø£Ø¹Ù…Ø¯Ø© Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„Ø¥Ø´Ø§Ø±Ø©: {missing_cols}.")
            return None

        last_row = df_processed.iloc[-1]

        # --- Get current real-time price from ticker_data ---
        current_price = ticker_data.get(self.symbol)
        if current_price is None:
            logger.warning(f"âš ï¸ [Strategy {self.symbol}] Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ ØºÙŠØ± Ù…ØªØ§Ø­ Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠÙƒØ±. Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø´Ø§Ø±Ø©.")
            return None

        if last_row[self.feature_columns_for_ml].isnull().values.any() or pd.isna(last_row.get('atr')):
             logger.warning(f"âš ï¸ [Strategy {self.symbol}] Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚ÙŠÙ… NaN ÙÙŠ Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©. Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø´Ø§Ø±Ø©.")
             return None

        signal_details = {} # Initialize signal_details

        # --- ML Model Prediction (Primary decision maker) ---
        ml_prediction_result_text = "N/A (Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø­Ù…Ù„)"
        ml_is_bullish = False

        if self.ml_model: # Use self.ml_model which is loaded per symbol
            try:
                # Ensure the order of features for prediction matches the training order
                features_for_prediction = pd.DataFrame([last_row[self.feature_columns_for_ml].values], columns=self.feature_columns_for_ml)
                ml_pred = self.ml_model.predict(features_for_prediction)[0]
                if ml_pred == 1: # If ML model predicts upward movement
                    ml_is_bullish = True
                    ml_prediction_result_text = 'ØµØ¹ÙˆØ¯ÙŠ âœ…'
                    logger.info(f"âœ¨ [Strategy {self.symbol}] ØªÙ†Ø¨Ø¤ Ù†Ù…ÙˆØ°Ø¬ ML ØµØ¹ÙˆØ¯ÙŠ.")
                else:
                    ml_prediction_result_text = 'Ù‡Ø§Ø¨Ø· âŒ'
                    logger.info(f"â„¹ï¸ [Strategy {self.symbol}] ØªÙ†Ø¨Ø¤ Ù†Ù…ÙˆØ°Ø¬ ML Ù‡Ø§Ø¨Ø·. ØªÙ… Ø±ÙØ¶ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©.")
            except Exception as ml_err:
                logger.error(f"âŒ [Strategy {self.symbol}] Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¨Ø¤ Ù†Ù…ÙˆØ°Ø¬ ML: {ml_err}", exc_info=True)
                ml_prediction_result_text = "Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤ (0)"
        
        signal_details['ML_Prediction'] = ml_prediction_result_text
        # Add the actual btc_trend_feature value to signal_details for logging/reporting
        signal_details['BTC_Trend_Feature_Value'] = last_row.get('btc_trend_feature', 0.0)
        signal_details['Supertrend_Direction_Value'] = last_row.get('supertrend_direction', 0)


        # If ML model is not bullish or failed, no signal
        if not ml_is_bullish:
            return None
        
        # --- Volume Check (Essential filter) ---
        volume_recent = fetch_recent_volume(self.symbol, interval=SIGNAL_GENERATION_TIMEFRAME, num_candles=VOLUME_LOOKBACK_CANDLES)
        if volume_recent < MIN_VOLUME_15M_USDT:
            logger.info(f"â„¹ï¸ [Strategy {self.symbol}] Ø§Ù„Ø³ÙŠÙˆÙ„Ø© ({volume_recent:,.0f} USDT) Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ({MIN_VOLUME_15M_USDT:,.0f} USDT). ØªÙ… Ø±ÙØ¶ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©.")
            signal_details['Volume_Check'] = f'ÙØ´Ù„: Ø³ÙŠÙˆÙ„Ø© ØºÙŠØ± ÙƒØ§ÙÙŠØ© ({volume_recent:,.0f} USDT)'
            return None
        else:
            signal_details['Volume_Check'] = f'Ù†Ø¬Ø§Ø­: Ø³ÙŠÙˆÙ„Ø© ÙƒØ§ÙÙŠØ© ({volume_recent:,.0f} USDT)'


        current_atr = last_row.get('atr')

        if pd.isna(current_atr) or current_atr <= 0:
             logger.warning(f"âš ï¸ [Strategy {self.symbol}] Ù‚ÙŠÙ…Ø© ATR ØºÙŠØ± ØµØ§Ù„Ø­Ø© ({current_atr}) Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù‡Ø¯Ù. Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø´Ø§Ø±Ø©.")
             return None

        target_multiplier = ENTRY_ATR_MULTIPLIER
        initial_target = current_price + (target_multiplier * current_atr)

        profit_margin_pct = ((initial_target / current_price) - 1) * 100 if current_price > 0 else 0
        if profit_margin_pct < MIN_PROFIT_MARGIN_PCT:
            logger.info(f"â„¹ï¸ [Strategy {self.symbol}] Ù‡Ø§Ù…Ø´ Ø§Ù„Ø±Ø¨Ø­ ({profit_margin_pct:.2f}%) Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ({MIN_PROFIT_MARGIN_PCT:.2f}%). ØªÙ… Ø±ÙØ¶ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©.")
            signal_details['Profit_Margin_Check'] = f'ÙØ´Ù„: Ù‡Ø§Ù…Ø´ Ø±Ø¨Ø­ ØºÙŠØ± ÙƒØ§ÙÙ ({profit_margin_pct:.2f}%)'
            return None
        else:
            signal_details['Profit_Margin_Check'] = f'Ù†Ø¬Ø§Ø­: Ù‡Ø§Ù…Ø´ Ø±Ø¨Ø­ ÙƒØ§ÙÙ ({profit_margin_pct:.2f}%)'


        signal_output = {
            'symbol': self.symbol,
            'entry_price': float(f"{current_price:.8g}"),
            'initial_target': float(f"{initial_target:.8g}"),
            'current_target': float(f"{initial_target:.8g}"),
            'r2_score': 1.0, # Placeholder score as it's ML-driven now
            'strategy_name': 'Scalping_ML_Only', # Updated strategy name
            'signal_details': signal_details,
            'volume_15m': volume_recent,
            'trade_value': TRADE_VALUE,
            'total_possible_score': 1.0 # Placeholder
        }

        logger.info(f"âœ… [Strategy {self.symbol}] ØªÙ… ØªØ£ÙƒÙŠØ¯ Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø´Ø±Ø§Ø¡ (ML ÙÙ‚Ø·). Ø§Ù„Ø³Ø¹Ø±: {current_price:.6f}, ATR: {current_atr:.6f}, Ø§Ù„Ø­Ø¬Ù…: {volume_recent:,.0f}, ØªÙ†Ø¨Ø¤ ML: {ml_prediction_result_text}, BTC Trend Feature: {last_row.get('btc_trend_feature', 0.0)}, Supertrend Direction: {last_row.get('supertrend_direction', 0)}")
        return signal_output


# ---------------------- Telegram Functions ----------------------
def send_telegram_message(target_chat_id: str, text: str, reply_markup: Optional[Dict] = None, parse_mode: str = 'Markdown', disable_web_page_preview: bool = True, timeout: int = 20) -> Optional[Dict]:
    """Sends a message via Telegram Bot API with improved error handling."""
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {
        'chat_id': str(target_chat_id),
        'text': text,
        'parse_mode': parse_mode,
        'disable_web_page_preview': disable_web_page_preview
    }
    if reply_markup:
        try:
            payload['reply_markup'] = json.dumps(convert_np_values(reply_markup))
        except (TypeError, ValueError) as json_err:
             logger.error(f"âŒ [Telegram] ÙØ´Ù„ ØªØ­ÙˆÙŠÙ„ reply_markup Ø¥Ù„Ù‰ JSON: {json_err} - Markup: {reply_markup}")
             return None

    logger.debug(f"â„¹ï¸ [Telegram] Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ø¥Ù„Ù‰ {target_chat_id}...")
    try:
        response = requests.post(url, json=payload, timeout=timeout)
        response.raise_for_status()
        logger.info(f"âœ… [Telegram] ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù„Ù‰ {target_chat_id}.")
        return response.json()
    except requests.exceptions.Timeout:
         logger.error(f"âŒ [Telegram] ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¥Ù„Ù‰ {target_chat_id} (Ù…Ù‡Ù„Ø©).")
         return None
    except requests.exceptions.HTTPError as http_err:
        logger.error(f"âŒ [Telegram] ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¥Ù„Ù‰ {target_chat_id} (Ø®Ø·Ø£ HTTP: {http_err.response.status_code}).")
        try:
            error_details = http_err.response.json()
            logger.error(f"âŒ [Telegram] ØªÙØ§ØµÙŠÙ„ Ø®Ø·Ø£ API: {error_details}")
        except json.JSONDecodeError:
            logger.error(f"âŒ [Telegram] ØªØ¹Ø°Ø± ÙÙƒ ØªØ´ÙÙŠØ± Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø®Ø·Ø£: {http_err.response.text}")
        return None
    except requests.exceptions.RequestException as req_err:
        logger.error(f"âŒ [Telegram] ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¥Ù„Ù‰ {target_chat_id} (Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø·Ù„Ø¨): {req_err}")
        return None
    except Exception as e:
         logger.error(f"âŒ [Telegram] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø©: {e}", exc_info=True)
         return None

def send_telegram_alert(signal_data: Dict[str, Any], timeframe: str) -> None:
    """Formats and sends a new trading signal alert to Telegram in Arabic, displaying the ML prediction."""
    logger.debug(f"â„¹ï¸ [Telegram Alert] ØªÙ†Ø³ÙŠÙ‚ ÙˆØ¥Ø±Ø³Ø§Ù„ ØªÙ†Ø¨ÙŠÙ‡ Ù„Ù„Ø¥Ø´Ø§Ø±Ø©: {signal_data.get('symbol', 'N/A')}")
    try:
        entry_price = float(signal_data['entry_price'])
        target_price = float(signal_data['initial_target'])
        symbol = signal_data['symbol']
        strategy_name = signal_data.get('strategy_name', 'N/A')
        volume_15m = signal_data.get('volume_15m', 0.0)
        trade_value_signal = signal_data.get('trade_value', TRADE_VALUE)
        signal_details = signal_data.get('signal_details', {})

        profit_pct = ((target_price / entry_price) - 1) * 100 if entry_price > 0 else 0

        entry_fee = trade_value_signal * BINANCE_FEE_RATE
        exit_value = trade_value_signal * (1 + profit_pct / 100.0)
        exit_fee = exit_value * BINANCE_FEE_RATE
        total_trade_fees = entry_fee + exit_fee

        profit_usdt_gross = trade_value_signal * (profit_pct / 100)
        profit_usdt_net = profit_usdt_gross - total_trade_fees

        timestamp_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        safe_symbol = symbol.replace('_', '\\_').replace('*', '\\*').replace('[', '\\[').replace('`', '\\`')

        fear_greed = get_fear_greed_index()
        ml_prediction_status = signal_details.get('ML_Prediction', 'N/A')
        btc_trend_feature_value = signal_details.get('BTC_Trend_Feature_Value', 0.0)
        btc_trend_display = "ØµØ¹ÙˆØ¯ÙŠ ğŸ“ˆ" if btc_trend_feature_value == 1.0 else ("Ù‡Ø¨ÙˆØ·ÙŠ ğŸ“‰" if btc_trend_feature_value == -1.0 else "Ù…Ø­Ø§ÙŠØ¯ ğŸ”„")
        supertrend_direction_value = signal_details.get('Supertrend_Direction_Value', 0)
        supertrend_display = "ØµØ¹ÙˆØ¯ÙŠ â¬†ï¸" if supertrend_direction_value == 1 else ("Ù‡Ø¨ÙˆØ·ÙŠ â¬‡ï¸" if supertrend_direction_value == -1 else "Ù…Ø­Ø§ÙŠØ¯ â†”ï¸")


        message = (
            f"ğŸ’¡ *Ø¥Ø´Ø§Ø±Ø© ØªØ¯Ø§ÙˆÙ„ Ø¬Ø¯ÙŠØ¯Ø© (ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ ML ÙÙ‚Ø·)* ğŸ’¡\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"ğŸª™ **Ø§Ù„Ø²ÙˆØ¬:** `{safe_symbol}`\n"
            f"ğŸ“ˆ **Ù†ÙˆØ¹ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©:** Ø´Ø±Ø§Ø¡ (Ø·ÙˆÙŠÙ„)\n"
            f"ğŸ•°ï¸ **Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø²Ù…Ù†ÙŠ:** {timeframe}\n"
            f"ğŸ’§ **Ø§Ù„Ø³ÙŠÙˆÙ„Ø© (Ø¢Ø®Ø± 15 Ø¯Ù‚ÙŠÙ‚Ø©):** {volume_15m:,.0f} USDT\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"â¡ï¸ **Ø³Ø¹Ø± Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù…Ù‚ØªØ±Ø­:** `${entry_price:,.8g}`\n"
            f"ğŸ¯ **Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø£ÙˆÙ„ÙŠ:** `${target_price:,.8g}`\n"
            f"ğŸ’° **Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ (Ø¥Ø¬Ù…Ø§Ù„ÙŠ):** ({profit_pct:+.2f}% / â‰ˆ ${profit_usdt_gross:+.2f})\n"
            f"ğŸ’¸ **Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©:** ${total_trade_fees:,.2f}\n"
            f"ğŸ“ˆ **Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„ØµØ§ÙÙŠ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:** ${profit_usdt_net:+.2f}\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"ğŸ¤– *ØªÙ†Ø¨Ø¤ Ù†Ù…ÙˆØ°Ø¬ ML:* *{ml_prediction_status}*\n"
            f"âœ… *Ø§Ù„Ø´Ø±ÙˆØ· Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ© Ø§Ù„Ù…Ø­Ù‚Ù‚Ø©:*\n"
            f"  - ÙØ­Øµ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©: {signal_details.get('Volume_Check', 'N/A')}\n"
            f"  - ÙØ­Øµ Ù‡Ø§Ù…Ø´ Ø§Ù„Ø±Ø¨Ø­: {signal_details.get('Profit_Margin_Check', 'N/A')}\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"ğŸ˜¨/ğŸ¤‘ **Ù…Ø¤Ø´Ø± Ø§Ù„Ø®ÙˆÙ ÙˆØ§Ù„Ø¬Ø´Ø¹:** {fear_greed}\n"
            f"â‚¿ **Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ† (Ù…ÙŠØ²Ø© ML):** {btc_trend_display}\n"
            f"ğŸ“Š **Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³ÙˆØ¨Ø± ØªØ±Ù†Ø¯ (Ù…ÙŠØ²Ø© ML):** {supertrend_display}\n" # NEW: Supertrend display
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"â° {timestamp_str}"
        )

        reply_markup = {
            "inline_keyboard": [
                [{"text": "ğŸ“Š Ø¹Ø±Ø¶ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡", "callback_data": "get_report"}]
            ]
        }

        send_telegram_message(CHAT_ID, message, reply_markup=reply_markup, parse_mode='Markdown')

    except KeyError as ke:
        logger.error(f"âŒ [Telegram Alert] Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø´Ø§Ø±Ø© ØºÙŠØ± Ù…ÙƒØªÙ…Ù„Ø© Ù„Ù„Ø±Ù…Ø² {signal_data.get('symbol', 'N/A')}: Ù…ÙØªØ§Ø­ Ù…ÙÙ‚ÙˆØ¯ {ke}", exc_info=True)
    except Exception as e:
        logger.error(f"âŒ [Telegram Alert] ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ ØªÙ†Ø¨ÙŠÙ‡ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù„Ù„Ø±Ù…Ø² {signal_data.get('symbol', 'N/A')}: {e}", exc_info=True)

def send_tracking_notification(details: Dict[str, Any]) -> None:
    """Formats and sends enhanced Telegram notifications for tracking events in Arabic."""
    symbol = details.get('symbol', 'N/A')
    signal_id = details.get('id', 'N/A')
    notification_type = details.get('type', 'unknown')
    message = ""
    safe_symbol = symbol.replace('_', '\\_').replace('*', '\\*').replace('[', '\\[').replace('`', '\\`')
    closing_price = details.get('closing_price', 0.0)
    profit_pct = details.get('profit_pct', 0.0)
    current_price = details.get('current_price', 0.0)
    time_to_target = details.get('time_to_target', 'N/A')
    old_target = details.get('old_target', 0.0)
    new_target = details.get('new_target', 0.0)


    logger.debug(f"â„¹ï¸ [Notification] ØªÙ†Ø³ÙŠÙ‚ Ø¥Ø´Ø¹Ø§Ø± Ø§Ù„ØªØªØ¨Ø¹: ID={signal_id}, Type={notification_type}, Symbol={symbol}")

    if notification_type == 'target_hit':
        message = (
            f"âœ… *ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù‡Ø¯Ù (ID: {signal_id})*\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"ğŸª™ **Ø§Ù„Ø²ÙˆØ¬:** `{safe_symbol}`\n"
            f"ğŸ¯ **Ø³Ø¹Ø± Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ (Ø§Ù„Ù‡Ø¯Ù):** `${closing_price:,.8g}`\n"
            f"ğŸ’° **Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„Ù…Ø­Ù‚Ù‚:** {profit_pct:+.2f}%\n"
            f"â±ï¸ **Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø³ØªØºØ±Ù‚:** {time_to_target}"
        )
    elif notification_type == 'target_updated':
         message = (
             f"â†—ï¸ *ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù‡Ø¯Ù (ID: {signal_id})*\n"
             f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
             f"ğŸª™ **Ø§Ù„Ø²ÙˆØ¬:** `{safe_symbol}`\n"
             f"ğŸ“ˆ **Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ:** `${current_price:,.8g}`\n"
             f"ğŸ¯ **Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø³Ø§Ø¨Ù‚:** `${old_target:,.8g}`\n"
             f"ğŸ¯ **Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯:** `${new_target:,.8g}`\n"
             f"â„¹ï¸ *ØªÙ… Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ø³ØªÙ…Ø±Ø§Ø± Ø§Ù„Ø²Ø®Ù… Ø§Ù„ØµØ¹ÙˆØ¯ÙŠ.*"
         )
    else:
        logger.warning(f"âš ï¸ [Notification] Ù†ÙˆØ¹ Ø¥Ø´Ø¹Ø§Ø± ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ: {notification_type} Ù„Ù„ØªÙØ§ØµÙŠÙ„: {details}")
        return

    if message:
        send_telegram_message(CHAT_ID, message, parse_mode='Markdown')

# ---------------------- Database Functions (Insert and Update) ----------------------
def insert_signal_into_db(signal: Dict[str, Any]) -> bool:
    """Inserts a new signal into the signals table with the weighted score and entry time."""
    if not check_db_connection() or not conn:
        logger.error(f"âŒ [DB Insert] ÙØ´Ù„ Ø¥Ø¯Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© {signal.get('symbol', 'N/A')} Ø¨Ø³Ø¨Ø¨ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
        return False

    symbol = signal.get('symbol', 'N/A')
    logger.debug(f"â„¹ï¸ [DB Insert] Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¯Ø±Ø§Ø¬ Ø¥Ø´Ø§Ø±Ø© Ù„Ù€ {symbol}...")
    try:
        signal_prepared = convert_np_values(signal)
        signal_details_json = json.dumps(signal_prepared.get('signal_details', {}))

        with conn.cursor() as cur_ins:
            insert_query = sql.SQL("""
                INSERT INTO signals
                 (symbol, entry_price, initial_target, current_target,
                 r2_score, strategy_name, signal_details, volume_15m, entry_time)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, NOW());
            """)
            cur_ins.execute(insert_query, (
                signal_prepared['symbol'],
                signal_prepared['entry_price'],
                signal_prepared['initial_target'],
                signal_prepared['current_target'],
                signal_prepared.get('r2_score'),
                signal_prepared.get('strategy_name', 'unknown'),
                signal_details_json,
                signal_prepared.get('volume_15m')
            ))
        conn.commit()
        logger.info(f"âœ… [DB Insert] ØªÙ… Ø¥Ø¯Ø±Ø§Ø¬ Ø¥Ø´Ø§Ø±Ø© Ù„Ù€ {symbol} ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø§Ù„Ø¯Ø±Ø¬Ø©: {signal_prepared.get('r2_score')}).")
        return True
    except psycopg2.Error as db_err:
        logger.error(f"âŒ [DB Insert] Ø®Ø·Ø£ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø«Ù†Ø§Ø¡ Ø¥Ø¯Ø±Ø§Ø¬ Ø¥Ø´Ø§Ø±Ø© Ù„Ù€ {symbol}: {db_err}")
        if conn: conn.rollback()
        return False
    except (TypeError, ValueError) as convert_err:
         logger.error(f"âŒ [DB Insert] Ø®Ø·Ø£ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø¯Ø±Ø§Ø¬ Ù„Ù€ {symbol}: {convert_err} - Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø´Ø§Ø±Ø©: {signal}")
         if conn: conn.rollback()
         return False
    except Exception as e:
        logger.error(f"âŒ [DB Insert] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø¥Ø¯Ø±Ø§Ø¬ Ø¥Ø´Ø§Ø±Ø© Ù„Ù€ {symbol}: {e}", exc_info=True)
        if conn: conn.rollback()
        return False

# ---------------------- Open Signal Tracking Function ----------------------
def track_signals() -> None:
    """Tracks open signals and checks targets. Calculates time to target upon hit."""
    logger.info("â„¹ï¸ [Tracker] Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© ØªØªØ¨Ø¹ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©...")
    while True:
        active_signals_summary: List[str] = []
        processed_in_cycle = 0
        try:
            if not check_db_connection() or not conn:
                logger.warning("âš ï¸ [Tracker] ØªØ®Ø·ÙŠ Ø¯ÙˆØ±Ø© Ø§Ù„ØªØªØ¨Ø¹ Ø¨Ø³Ø¨Ø¨ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
                time.sleep(15)
                continue

            with conn.cursor() as track_cur:
                 track_cur.execute("""
                    SELECT id, symbol, entry_price, initial_target, current_target, entry_time
                    FROM signals
                    WHERE achieved_target = FALSE;
                """)
                 open_signals: List[Dict] = track_cur.fetchall()

            if not open_signals:
                time.sleep(10)
                continue

            logger.debug(f"â„¹ï¸ [Tracker] ØªØªØ¨Ø¹ {len(open_signals)} Ø¥Ø´Ø§Ø±Ø© Ù…ÙØªÙˆØ­Ø©...")

            for signal_row in open_signals:
                signal_id = signal_row['id']
                symbol = signal_row['symbol']
                processed_in_cycle += 1
                update_executed = False

                try:
                    entry_price = float(signal_row['entry_price'])
                    entry_time = signal_row['entry_time']
                    current_target = float(signal_row['current_target'])

                    current_price = ticker_data.get(symbol)

                    if current_price is None:
                         logger.warning(f"âš ï¸ [Tracker] {symbol}(ID:{signal_id}): Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ ØºÙŠØ± Ù…ØªØ§Ø­ ÙÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠÙƒØ±.")
                         continue

                    active_signals_summary.append(f"{symbol}({signal_id}): P={current_price:.4f} T={current_target:.4f}")

                    update_query: Optional[sql.SQL] = None
                    update_params: Tuple = ()
                    log_message: Optional[str] = None
                    notification_details: Dict[str, Any] = {'symbol': symbol, 'id': signal_id, 'current_price': current_price}


                    # --- Check and Update Logic ---
                    # 1. Check for Target Hit
                    if current_price >= current_target:
                        profit_pct = ((current_target / entry_price) - 1) * 100 if entry_price > 0 else 0
                        closed_at = datetime.now()
                        time_to_target_duration = closed_at - entry_time if entry_time else timedelta(0)
                        time_to_target_str = str(time_to_target_duration)

                        update_query = sql.SQL("UPDATE signals SET achieved_target = TRUE, closing_price = %s, closed_at = %s, profit_percentage = %s, time_to_target = %s WHERE id = %s;")
                        update_params = (current_target, closed_at, profit_pct, time_to_target_duration, signal_id)
                        log_message = f"ğŸ¯ [Tracker] {symbol}(ID:{signal_id}): ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù‡Ø¯Ù Ø¹Ù†Ø¯ {current_target:.8g} (Ø§Ù„Ø±Ø¨Ø­: {profit_pct:+.2f}%, Ø§Ù„ÙˆÙ‚Øª: {time_to_target_str})."
                        notification_details.update({'type': 'target_hit', 'closing_price': current_target, 'profit_pct': profit_pct, 'time_to_target': time_to_target_str})
                        update_executed = True

                    # 2. Check for Target Extension (Only if Target not hit)
                    if not update_executed:
                        if current_price >= current_target * (1 - TARGET_APPROACH_THRESHOLD_PCT):
                             logger.debug(f"â„¹ï¸ [Tracker] {symbol}(ID:{signal_id}): Ø§Ù„Ø³Ø¹Ø± Ù‚Ø±ÙŠØ¨ Ù…Ù† Ø§Ù„Ù‡Ø¯Ù ({current_price:.8g} Ù…Ù‚Ø§Ø¨Ù„ {current_target:.8g}). Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±...")

                             df_continuation = fetch_historical_data(symbol, interval=SIGNAL_GENERATION_TIMEFRAME, days=SIGNAL_GENERATION_LOOKBACK_DAYS)

                             if df_continuation is not None and not df_continuation.empty:
                                 continuation_strategy = ScalpingTradingStrategy(symbol)
                                 # Ensure ML model is loaded for continuation strategy
                                 if continuation_strategy.ml_model is None:
                                     logger.warning(f"âš ï¸ [Tracker] {symbol}(ID:{signal_id}): Ù†Ù…ÙˆØ°Ø¬ ML ØºÙŠØ± Ù…Ø­Ù…Ù„ Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±. ØªØ®Ø·ÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù‡Ø¯Ù.")
                                     continue

                                 df_continuation_indicators = continuation_strategy.populate_indicators(df_continuation)

                                 if df_continuation_indicators is not None:
                                     # Pass the populated indicators to generate_buy_signal
                                     continuation_signal = continuation_strategy.generate_buy_signal(df_continuation_indicators)

                                     if continuation_signal:
                                         latest_row = df_continuation_indicators.iloc[-1]
                                         current_atr_for_new_target = latest_row.get('atr')

                                         if pd.notna(current_atr_for_new_target) and current_atr_for_new_target > 0:
                                             potential_new_target = current_price + (ENTRY_ATR_MULTIPLIER * current_atr_for_new_target)

                                             if potential_new_target > current_target:
                                                 old_target = current_target
                                                 new_target = potential_new_target
                                                 update_query = sql.SQL("UPDATE signals SET current_target = %s WHERE id = %s;")
                                                 update_params = (new_target, signal_id)
                                                 log_message = f"â†—ï¸ [Tracker] {symbol}(ID:{signal_id}): ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù‡Ø¯Ù Ù…Ù† {old_target:.8g} Ø¥Ù„Ù‰ {new_target:.8g} Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±."
                                                 notification_details.update({'type': 'target_updated', 'old_target': old_target, 'new_target': new_target})
                                                 update_executed = True
                                             else:
                                                 logger.debug(f"â„¹ï¸ [Tracker] {symbol}(ID:{signal_id}): ØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø¥Ø´Ø§Ø±Ø© Ø§Ø³ØªÙ…Ø±Ø§Ø±ØŒ Ù„ÙƒÙ† Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯ ({potential_new_target:.8g}) Ù„ÙŠØ³ Ø£Ø¹Ù„Ù‰ Ù…Ù† Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø­Ø§Ù„ÙŠ ({current_target:.8g}). Ø¹Ø¯Ù… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù‡Ø¯Ù.")
                                         else:
                                             logger.warning(f"âš ï¸ [Tracker] {symbol}(ID:{signal_id}): Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø­Ø³Ø§Ø¨ Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¨Ø³Ø¨Ø¨ ATR ØºÙŠØ± ØµØ§Ù„Ø­ ({current_atr_for_new_target}) Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±.")
                                     else:
                                         logger.debug(f"â„¹ï¸ [Tracker] {symbol}(ID:{signal_id}): Ø§Ù„Ø³Ø¹Ø± Ù‚Ø±ÙŠØ¨ Ù…Ù† Ø§Ù„Ù‡Ø¯ÙØŒ ÙˆÙ„ÙƒÙ† Ù„Ù… ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø´Ø§Ø±Ø© Ø§Ø³ØªÙ…Ø±Ø§Ø±.")
                                 else:
                                     logger.warning(f"âš ï¸ [Tracker] {symbol}(ID:{signal_id}): ÙØ´Ù„ ÙÙŠ Ù…Ù„Ø¡ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±.")
                             else:
                                 logger.warning(f"âš ï¸ [Tracker] {symbol}(ID:{signal_id}): Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±.")


                    if update_executed and update_query:
                        try:
                             with conn.cursor() as update_cur:
                                  update_cur.execute(update_query, update_params)
                             conn.commit()
                             if log_message: logger.info(log_message)
                             if notification_details.get('type'):
                                send_tracking_notification(notification_details)
                        except psycopg2.Error as db_err:
                            logger.error(f"âŒ [Tracker] {symbol}(ID:{signal_id}): Ø®Ø·Ø£ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ø¯ÙŠØ«: {db_err}")
                            if conn: conn.rollback()
                        except Exception as exec_err:
                            logger.error(f"âŒ [Tracker] {symbol}(ID:{signal_id}): Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ­Ø¯ÙŠØ«/Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±: {exec_err}", exc_info=True)
                            if conn: conn.rollback()

                except (TypeError, ValueError) as convert_err:
                    logger.error(f"âŒ [Tracker] {symbol}(ID:{signal_id}): Ø®Ø·Ø£ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ù‚ÙŠÙ… Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©: {convert_err}")
                    continue
                except Exception as inner_loop_err:
                     logger.error(f"âŒ [Tracker] {symbol}(ID:{signal_id}): Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¥Ø´Ø§Ø±Ø©: {inner_loop_err}", exc_info=True)
                     continue

            if active_signals_summary:
                logger.debug(f"â„¹ï¸ [Tracker] Ù†Ù‡Ø§ÙŠØ© Ø­Ø§Ù„Ø© Ø§Ù„Ø¯ÙˆØ±Ø© ({processed_in_cycle} Ù…Ø¹Ø§Ù„Ø¬Ø©): {'; '.join(active_signals_summary)}")

            time.sleep(3)

        except psycopg2.Error as db_cycle_err:
             logger.error(f"âŒ [Tracker] Ø®Ø·Ø£ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø¯ÙˆØ±Ø© Ø§Ù„ØªØªØ¨Ø¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: {db_cycle_err}. Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„...")
             if conn: conn.rollback()
             time.sleep(30)
             check_db_connection()
        except Exception as cycle_err:
            logger.error(f"âŒ [Tracker] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø¯ÙˆØ±Ø© ØªØªØ¨Ø¹ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©: {cycle_err}", exc_info=True)
            time.sleep(30)

def get_interval_minutes(interval: str) -> int:
    """Helper function to convert Binance interval string to minutes."""
    if interval.endswith('m'):
        return int(interval[:-1])
    elif interval.endswith('h'):
        return int(interval[:-1]) * 60
    elif interval.endswith('d'):
        return int(interval[:-1]) * 60 * 24
    return 0


# ---------------------- Flask Service (Optional for Webhook) ----------------------
app = Flask(__name__)

@app.route('/')
def home() -> Response:
    """Simple home page to show the bot is running."""
    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    ws_alive = ws_thread.is_alive() if 'ws_thread' in globals() and ws_thread else False
    tracker_alive = tracker_thread.is_alive() if 'tracker_thread' in globals() and tracker_thread else False
    main_bot_alive = main_bot_thread.is_alive() if 'main_bot_thread' in globals() and main_bot_thread else False
    status = "running" if ws_alive and tracker_alive and main_bot_alive else "partially running"
    return Response(f"ğŸ“ˆ Crypto Signal Bot ({status}) - Last Check: {now}", status=200, mimetype='text/plain')

@app.route('/favicon.ico')
def favicon() -> Response:
    """Handles favicon request to avoid 404 errors in logs."""
    return Response(status=204)

@app.route('/webhook', methods=['POST'])
def webhook() -> Tuple[str, int]:
    """Handles incoming requests from Telegram (like button presses and commands)."""
    # Only process webhook if WEBHOOK_URL is configured
    if not WEBHOOK_URL:
        logger.warning("âš ï¸ [Flask] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø·Ù„Ø¨ webhookØŒ ÙˆÙ„ÙƒÙ† WEBHOOK_URL ØºÙŠØ± Ù…Ù‡ÙŠØ£. ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø·Ù„Ø¨.")
        return "Webhook not configured", 200 # Return OK to Telegram to avoid repeated attempts

    if not request.is_json:
        logger.warning("âš ï¸ [Flask] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø·Ù„Ø¨ webhook ØºÙŠØ± JSON.")
        return "Invalid request format", 400

    try:
        data = request.get_json()
        logger.info(f"âœ… [Flask] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª webhook. Ø­Ø¬Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {len(json.dumps(data))} Ø¨Ø§ÙŠØª.")
        logger.debug(f"â„¹ï¸ [Flask] Ø¨ÙŠØ§Ù†Ø§Øª webhook Ø§Ù„ÙƒØ§Ù…Ù„Ø©: {json.dumps(data)}") # Log full payload for debugging


        if 'callback_query' in data:
            callback_query = data['callback_query']
            callback_id = callback_query['id']
            callback_data = callback_query.get('data')
            message_info = callback_query.get('message')

            logger.info(f"â„¹ï¸ [Flask] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø±Ø¯ Ø§ØªØµØ§Ù„ (Callback Query). ID: {callback_id}, Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: '{callback_data}'")

            if not message_info or not callback_data:
                 logger.warning(f"âš ï¸ [Flask] Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø±Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„ (ID: {callback_id}) ÙŠÙØªÙ‚Ø¯ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø£Ùˆ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. ØªØ¬Ø§Ù‡Ù„.")
                 try:
                     ack_url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/answerCallbackQuery"
                     requests.post(ack_url, json={'callback_query_id': callback_id}, timeout=5)
                 except Exception as ack_err:
                     logger.warning(f"âš ï¸ [Flask] ÙØ´Ù„ ØªØ£ÙƒÙŠØ¯ Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø±Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„ ØºÙŠØ± Ø§Ù„ØµØ§Ù„Ø­ {callback_id}: {ack_err}")
                 return "OK", 200
            chat_id_callback = message_info.get('chat', {}).get('id')
            if not chat_id_callback:
                 logger.warning(f"âš ï¸ [Flask] Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø±Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„ (ID: {callback_id}) ÙŠÙØªÙ‚Ø¯ Ù…Ø¹Ø±Ù Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©. ØªØ¬Ø§Ù‡Ù„.")
                 try:
                     ack_url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/answerCallbackQuery"
                     requests.post(ack_url, json={'callback_query_id': callback_id}, timeout=5)
                 except Exception as ack_err:
                     logger.warning(f"âš ï¸ [Flask] ÙØ´Ù„ ØªØ£ÙƒÙŠØ¯ Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø±Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„ ØºÙŠØ± Ø§Ù„ØµØ§Ù„Ø­ {callback_id}: {ack_err}")
                 return "OK", 200


            message_id = message_info['message_id']
            user_info = callback_query.get('from', {})
            user_id = user_info.get('id')
            username = user_info.get('username', 'N/A')

            logger.info(f"â„¹ï¸ [Flask] Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø±Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª='{callback_data}', Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…={username}({user_id}), Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©={chat_id_callback}")

            try:
                # Always acknowledge the callback query to remove the loading animation from the button
                ack_url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/answerCallbackQuery"
                requests.post(ack_url, json={'callback_query_id': callback_id}, timeout=5)
                logger.debug(f"âœ… [Flask] ØªÙ… ØªØ£ÙƒÙŠØ¯ Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø±Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„ {callback_id}.")
            except Exception as ack_err:
                 logger.warning(f"âš ï¸ [Flask] ÙØ´Ù„ ØªØ£ÙƒÙŠØ¯ Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø±Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„ {callback_id}: {ack_err}")

            if callback_data == "get_report":
                logger.info(f"â„¹ï¸ [Flask] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø·Ù„Ø¨ 'get_report' Ù…Ù† Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© {chat_id_callback}. Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±...")
                report_content = generate_performance_report()
                logger.info(f"âœ… [Flask] ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±. Ø·ÙˆÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {len(report_content)} Ø­Ø±Ù.")
                report_thread = Thread(target=lambda: send_telegram_message(chat_id_callback, report_content, parse_mode='Markdown'))
                report_thread.start()
                logger.info(f"âœ… [Flask] ØªÙ… Ø¨Ø¯Ø¡ Ø®ÙŠØ· Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ù„Ù„Ø¯Ø±Ø¯Ø´Ø© {chat_id_callback}.")
            else:
                logger.warning(f"âš ï¸ [Flask] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø±Ø¯ Ø§ØªØµØ§Ù„ ØºÙŠØ± Ù…Ø¹Ø§Ù„Ø¬Ø©: '{callback_data}'")


        elif 'message' in data:
            message_data = data['message']
            chat_info = message_data.get('chat')
            user_info = message_data.get('from', {})
            text_msg = message_data.get('text', '').strip()

            if not chat_info or not text_msg:
                 logger.debug("â„¹ï¸ [Flask] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø±Ø³Ø§Ù„Ø© Ø¨Ø¯ÙˆÙ† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø£Ùˆ Ø§Ù„Ù†Øµ.")
                 return "OK", 200

            chat_id_msg = chat_info['id']
            user_id = user_info.get('id')
            username = user_info.get('username', 'N/A')

            logger.info(f"â„¹ï¸ [Flask] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø±Ø³Ø§Ù„Ø©: Ø§Ù„Ù†Øµ='{text_msg}', Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…={username}({user_id}), Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©={chat_id_msg}")

            if text_msg.lower() == '/report':
                 report_thread = Thread(target=lambda: send_telegram_message(chat_id_msg, generate_performance_report(), parse_mode='Markdown'))
                 report_thread.start()
            elif text_msg.lower() == '/status':
                 status_thread = Thread(target=handle_status_command, args=(chat_id_msg,))
                 status_thread.start()

        else:
            logger.debug("â„¹ï¸ [Flask] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª webhook Ø¨Ø¯ÙˆÙ† 'callback_query' Ø£Ùˆ 'message'.")

        return "OK", 200
    except Exception as e:
         logger.error(f"âŒ [Flask] Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© webhook: {e}", exc_info=True)
         return "Internal Server Error", 500

def handle_status_command(chat_id_msg: int) -> None:
    """Separate function to handle /status command to avoid blocking the Webhook."""
    logger.info(f"â„¹ï¸ [Flask Status] Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ù…Ø± /status Ù„Ù„Ø¯Ø±Ø¯Ø´Ø© {chat_id_msg}")
    status_msg = "â³ Ø¬Ù„Ø¨ Ø§Ù„Ø­Ø§Ù„Ø©..."
    msg_sent = send_telegram_message(chat_id_msg, status_msg)
    if not (msg_sent and msg_sent.get('ok')):
         logger.error(f"âŒ [Flask Status] ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ø¥Ù„Ù‰ {chat_id_msg}")
         return
    message_id_to_edit = msg_sent['result']['message_id'] if msg_sent and msg_sent.get('result') else None

    if message_id_to_edit is None:
        logger.error(f"âŒ [Flask Status] ÙØ´Ù„ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ message_id Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø© ÙÙŠ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© {chat_id_msg}")
        return


    try:
        open_count = 0
        if check_db_connection() and conn:
            with conn.cursor() as status_cur:
                status_cur.execute("SELECT COUNT(*) AS count FROM signals WHERE achieved_target = FALSE;")
                open_count = (status_cur.fetchone() or {}).get('count', 0)

        ws_status = 'Ù†Ø´Ø· âœ…' if 'ws_thread' in globals() and ws_thread and ws_thread.is_alive() else 'ØºÙŠØ± Ù†Ø´Ø· âŒ'
        tracker_status = 'Ù†Ø´Ø· âœ…' if 'tracker_thread' in globals() and tracker_thread and tracker_thread.is_alive() else 'ØºÙŠØ± Ù†Ø´Ø· âŒ'
        main_bot_alive = 'Ù†Ø´Ø· âœ…' if 'main_bot_thread' in globals() and main_bot_thread and main_bot_thread.is_alive() else 'ØºÙŠØ± Ù†Ø´Ø· âŒ'
        final_status_msg = (
            f"ğŸ¤– *Ø­Ø§Ù„Ø© Ø§Ù„Ø¨ÙˆØª:*\n"
            f"- ØªØªØ¨Ø¹ Ø§Ù„Ø£Ø³Ø¹Ø§Ø± (WS): {ws_status}\n"
            f"- ØªØªØ¨Ø¹ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª: {tracker_status}\n"
            f"- Ø­Ù„Ù‚Ø© Ø§Ù„Ø¨ÙˆØª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: {main_bot_alive}\n" # Added main bot loop status
            f"- Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø©: *{open_count}* / {MAX_OPEN_TRADES}\n"
            f"- ÙˆÙ‚Øª Ø§Ù„Ø®Ø§Ø¯Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ: {datetime.now().strftime('%H:%M:%S')}"
        )
        edit_url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/editMessageText"
        edit_payload = {
            'chat_id': chat_id_msg,
             'message_id': message_id_to_edit,
            'text': final_status_msg,
            'parse_mode': 'Markdown'
        }
        response = requests.post(edit_url, json=edit_payload, timeout=10)
        response.raise_for_status()
        logger.info(f"âœ… [Flask Status] ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø© Ù„Ù„Ø¯Ø±Ø¯Ø´Ø© {chat_id_msg}")

    except Exception as status_err:
        logger.error(f"âŒ [Flask Status] Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨/ØªØ¹Ø¯ÙŠÙ„ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø­Ø§Ù„Ø© Ù„Ù„Ø¯Ø±Ø¯Ø´Ø© {chat_id_msg}: {status_err}", exc_info=True)
        send_telegram_message(chat_id_msg, "âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø­Ø§Ù„Ø©.")


def run_flask() -> None:
    """Runs the Flask application to listen for the Webhook using a production server if available."""
    host = "0.0.0.0"
    port = int(os.environ.get('PORT', 10000)) # Use PORT environment variable or default value
    logger.info(f"â„¹ï¸ [Flask] Ø¨Ø¯Ø¡ ØªØ·Ø¨ÙŠÙ‚ Flask Ø¹Ù„Ù‰ {host}:{port}...")
    try:
        from waitress import serve
        logger.info("âœ… [Flask] Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø§Ø¯Ù… 'waitress'.")
        serve(app, host=host, port=port, threads=6)
    except ImportError:
         logger.warning("âš ï¸ [Flask] 'waitress' ØºÙŠØ± Ù…Ø«Ø¨Øª. Ø§Ù„Ø±Ø¬ÙˆØ¹ Ø¥Ù„Ù‰ Ø®Ø§Ø¯Ù… ØªØ·ÙˆÙŠØ± Flask (Ù„Ø§ ÙŠÙˆØµÙ‰ Ø¨Ù‡ Ù„Ù„Ø¥Ù†ØªØ§Ø¬).")
         try:
             app.run(host=host, port=port)
         except Exception as flask_run_err:
              logger.critical(f"âŒ [Flask] ÙØ´Ù„ Ø¨Ø¯Ø¡ Ø®Ø§Ø¯Ù… Ø§Ù„ØªØ·ÙˆÙŠØ±: {flask_run_err}", exc_info=True)
    except Exception as serve_err:
         logger.critical(f"âŒ [Flask] ÙØ´Ù„ Ø¨Ø¯Ø¡ Ø§Ù„Ø®Ø§Ø¯Ù… (waitressØŸ): {serve_err}", exc_info=True)

# ---------------------- Main Loop and Check Function ----------------------
def main_loop() -> None:
    """Main loop to scan pairs and generate signals."""
    symbols_to_scan = get_crypto_symbols()
    if not symbols_to_scan:
        logger.critical("âŒ [Main] Ù„Ø§ ØªÙˆØ¬Ø¯ Ø±Ù…ÙˆØ² ØµØ§Ù„Ø­Ø© ØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡Ø§ Ø£Ùˆ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù†Ù‡Ø§. Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ù…ØªØ§Ø¨Ù…Ø©.")
        return

    logger.info(f"âœ… [Main] ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(symbols_to_scan)} Ø±Ù…Ø²Ù‹Ø§ ØµØ§Ù„Ø­Ù‹Ø§ Ù„Ù„Ù…Ø³Ø­.")
    last_full_scan_time = time.time()

    while True:
        try:
            scan_start_time = time.time()
            logger.info("+" + "-"*60 + "+")
            logger.info(f"ğŸ”„ [Main] Ø¨Ø¯Ø¡ Ø¯ÙˆØ±Ø© Ù…Ø³Ø­ Ø§Ù„Ø³ÙˆÙ‚ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            logger.info("+" + "-"*60 + "+")

            if not check_db_connection() or not conn:
                logger.error("âŒ [Main] ØªØ®Ø·ÙŠ Ø¯ÙˆØ±Ø© Ø§Ù„Ù…Ø³Ø­ Ø¨Ø³Ø¨Ø¨ ÙØ´Ù„ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
                time.sleep(60)
                continue

            open_count = 0
            try:
                 with conn.cursor() as cur_check:
                    cur_check.execute("SELECT COUNT(*) AS count FROM signals WHERE achieved_target = FALSE;")
                    open_count = (cur_check.fetchone() or {}).get('count', 0)
            except psycopg2.Error as db_err:
                 logger.error(f"âŒ [Main] Ø®Ø·Ø£ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©: {db_err}. ØªØ®Ø·ÙŠ Ø§Ù„Ø¯ÙˆØ±Ø©.")
                 if conn: conn.rollback()
                 time.sleep(60)
                 continue

            logger.info(f"â„¹ï¸ [Main] Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹: {open_count} / {MAX_OPEN_TRADES}")
            if open_count >= MAX_OPEN_TRADES:
                logger.info(f"âš ï¸ [Main] ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©. Ø§Ù†ØªØ¸Ø§Ø±...")
                time.sleep(get_interval_minutes(SIGNAL_GENERATION_TIMEFRAME) * 60)
                continue

            processed_in_loop = 0
            signals_generated_in_loop = 0
            slots_available = MAX_OPEN_TRADES - open_count

            for symbol in symbols_to_scan:
                 if slots_available <= 0:
                      logger.info(f"â„¹ï¸ [Main] ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ ({MAX_OPEN_TRADES}) Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø³Ø­. Ø¥ÙŠÙ‚Ø§Ù Ù…Ø³Ø­ Ø§Ù„Ø±Ù…ÙˆØ² Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø¯ÙˆØ±Ø©.")
                      break

                 processed_in_loop += 1
                 logger.debug(f"ğŸ” [Main] Ù…Ø³Ø­ {symbol} ({processed_in_loop}/{len(symbols_to_scan)})...")

                 try:
                    with conn.cursor() as symbol_cur:
                        symbol_cur.execute("SELECT 1 FROM signals WHERE symbol = %s AND achieved_target = FALSE LIMIT 1;", (symbol,))
                        if symbol_cur.fetchone():
                            continue

                    df_hist = fetch_historical_data(symbol, interval=SIGNAL_GENERATION_TIMEFRAME, days=SIGNAL_GENERATION_LOOKBACK_DAYS)
                    if df_hist is None or df_hist.empty:
                        continue

                    strategy = ScalpingTradingStrategy(symbol) # ML model loaded here
                    # Check if ML model was loaded successfully for this symbol
                    if strategy.ml_model is None:
                        logger.warning(f"âš ï¸ [Main] ØªØ®Ø·ÙŠ {symbol} Ù„Ø£Ù† Ù†Ù…ÙˆØ°Ø¬ ML Ø§Ù„Ø®Ø§Øµ Ø¨Ù‡ Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡ Ø¨Ù†Ø¬Ø§Ø­.")
                        continue

                    df_indicators = strategy.populate_indicators(df_hist)
                    if df_indicators is None:
                        continue

                    potential_signal = strategy.generate_buy_signal(df_indicators)

                    if potential_signal:
                        logger.info(f"âœ¨ [Main] ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¥Ø´Ø§Ø±Ø© Ù…Ø­ØªÙ…Ù„Ø© Ù„Ù€ {symbol}! Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙˆØ§Ù„Ø¥Ø¯Ø±Ø§Ø¬...")
                        with conn.cursor() as final_check_cur:
                             final_check_cur.execute("SELECT COUNT(*) AS count FROM signals WHERE achieved_target = FALSE;")
                             final_open_count = (final_check_cur.fetchone() or {}).get('count', 0)

                             if final_open_count < MAX_OPEN_TRADES:
                                 if insert_signal_into_db(potential_signal):
                                     send_telegram_alert(potential_signal, SIGNAL_GENERATION_TIMEFRAME)
                                     signals_generated_in_loop += 1
                                     slots_available -= 1
                                     time.sleep(2)
                                 else:
                                     logger.error(f"âŒ [Main] ÙØ´Ù„ Ø¥Ø¯Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù„Ù€ {symbol} ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
                             else:
                                 logger.warning(f"âš ï¸ [Main] ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ ({final_open_count}) Ù‚Ø¨Ù„ Ø¥Ø¯Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù„Ù€ {symbol}. ØªÙ… ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©.")
                                 break

                 except psycopg2.Error as db_loop_err:
                      logger.error(f"âŒ [Main] Ø®Ø·Ø£ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ù…Ø² {symbol}: {db_loop_err}. Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ø§Ù„ØªØ§Ù„ÙŠ...")
                      if conn: conn.rollback()
                      continue
                 except Exception as symbol_proc_err:
                      logger.error(f"âŒ [Main] Ø®Ø·Ø£ Ø¹Ø§Ù… ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ù…Ø² {symbol}: {symbol_proc_err}", exc_info=True)
                      continue

                 time.sleep(0.1)

            scan_duration = time.time() - scan_start_time
            logger.info(f"ğŸ [Main] Ø§Ù†ØªÙ‡Øª Ø¯ÙˆØ±Ø© Ø§Ù„Ù…Ø³Ø­. Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§: {signals_generated_in_loop}. Ù…Ø¯Ø© Ø§Ù„Ù…Ø³Ø­: {scan_duration:.2f} Ø«Ø§Ù†ÙŠØ©.")
            frame_minutes = get_interval_minutes(SIGNAL_GENERATION_TIMEFRAME)
            wait_time = max(frame_minutes * 60, 120 - scan_duration)
            logger.info(f"â³ [Main] Ø§Ù†ØªØ¸Ø§Ø± {wait_time:.1f} Ø«Ø§Ù†ÙŠØ© Ù„Ù„Ø¯ÙˆØ±Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©...")
            time.sleep(wait_time)

        except KeyboardInterrupt:
             logger.info("ğŸ›‘ [Main] ØªÙ… Ø·Ù„Ø¨ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ù (KeyboardInterrupt). Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ´ØºÙŠÙ„...")
             break
        except psycopg2.Error as db_main_err:
             logger.error(f"âŒ [Main] Ø®Ø·Ø£ ÙØ§Ø¯Ø­ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: {db_main_err}. Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„...")
             if conn: conn.rollback()
             time.sleep(60)
             try:
                 init_db()
             except Exception as recon_err:
                 logger.critical(f"âŒ [Main] ÙØ´Ù„ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {recon_err}. Ø®Ø±ÙˆØ¬...")
                 break
        except Exception as main_err:
            logger.error(f"âŒ [Main] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: {main_err}", exc_info=True)
            logger.info("â„¹ï¸ [Main] Ø§Ù†ØªØ¸Ø§Ø± 120 Ø«Ø§Ù†ÙŠØ© Ù‚Ø¨Ù„ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©...")
            time.sleep(120)

def cleanup_resources() -> None:
    """Closes used resources like the database connection."""
    global conn
    logger.info("â„¹ï¸ [Cleanup] Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯...")
    if conn:
        try:
            conn.close()
            logger.info("âœ… [DB] ØªÙ… Ø¥ØºÙ„Ø§Ù‚ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
        except Exception as close_err:
            logger.error(f"âš ï¸ [DB] Ø®Ø·Ø£ ÙÙŠ Ø¥ØºÙ„Ø§Ù‚ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {close_err}")
    logger.info("âœ… [Cleanup] Ø§ÙƒØªÙ…Ù„ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯.")


# ---------------------- Main Entry Point ----------------------
if __name__ == "__main__":
    logger.info("ğŸš€ Ø¨Ø¯Ø¡ Ø¨ÙˆØª Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„ØªØ¯Ø§ÙˆÙ„...")
    logger.info(f"Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø­Ù„ÙŠ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | ÙˆÙ‚Øª UTC: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')}")

    ws_thread: Optional[Thread] = None
    tracker_thread: Optional[Thread] = None
    flask_thread: Optional[Thread] = None
    main_bot_thread: Optional[Thread] = None # New thread for main_loop

    try:
        # 1. Initialize the database first
        init_db()

        # 2. No longer load all ML models at startup. They will be loaded on demand per symbol.
        #    ml_model = load_ml_model_from_db()
        #    if ml_model is None:
        #        logger.warning("âš ï¸ [Main] Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø©. Ø³ØªØ¹Ù…Ù„ Ø§Ù„Ø¥Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø¨Ø¯ÙˆÙ† ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ ÙƒØ´Ø±Ø· ØªØ¬Ø§ÙˆØ².")

        # 3. Start WebSocket Ticker
        ws_thread = Thread(target=run_ticker_socket_manager, daemon=True, name="WebSocketThread")
        ws_thread.start()
        logger.info("âœ… [Main] ØªÙ… Ø¨Ø¯Ø¡ Ù…Ø¤Ø´Ø± WebSocket.")
        logger.info("â„¹ï¸ [Main] Ø§Ù†ØªØ¸Ø§Ø± 5 Ø«ÙˆØ§Ù†Ù Ù„ØªÙ‡ÙŠØ¦Ø© WebSocket...")
        time.sleep(5)
        if not ticker_data:
             logger.warning("âš ï¸ [Main] Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„ÙŠØ© Ù…Ù† WebSocket Ø¨Ø¹Ø¯ 5 Ø«ÙˆØ§Ù†Ù.")
        else:
             logger.info(f"âœ… [Main] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„ÙŠØ© Ù…Ù† WebSocket Ù„Ù€ {len(ticker_data)} Ø±Ù…Ø²Ù‹Ø§.")


        # 4. Start Signal Tracker
        tracker_thread = Thread(target=track_signals, daemon=True, name="TrackerThread")
        tracker_thread.start()
        logger.info("âœ… [Main] ØªÙ… Ø¨Ø¯Ø¡ Ù…Ø¤Ø´Ø± Ø§Ù„Ø¥Ø´Ø§Ø±Ø©.")

        # 5. Start the main bot logic in a separate thread
        main_bot_thread = Thread(target=main_loop, daemon=True, name="MainBotLoopThread")
        main_bot_thread.start()
        logger.info("âœ… [Main] ØªÙ… Ø¨Ø¯Ø¡ Ø­Ù„Ù‚Ø© Ø§Ù„Ø¨ÙˆØª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙÙŠ Ø®ÙŠØ· Ù…Ù†ÙØµÙ„.")

        # 6. Start Flask Server (ALWAYS run, daemon=False so it keeps the main program alive)
        flask_thread = Thread(target=run_flask, daemon=False, name="FlaskThread")
        flask_thread.start()
        logger.info("âœ… [Main] ØªÙ… Ø¨Ø¯Ø¡ Ø®Ø§Ø¯Ù… Flask.")

        # Wait for the Flask thread to finish (it usually won't unless there's an error)
        flask_thread.join()

    except Exception as startup_err:
        logger.critical(f"âŒ [Main] Ø­Ø¯Ø« Ø®Ø·Ø£ ÙØ§Ø¯Ø­ Ø£Ø«Ù†Ø§Ø¡ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø£Ùˆ ÙÙŠ Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: {startup_err}", exc_info=True)
    finally:
        logger.info("ğŸ›‘ [Main] ÙŠØªÙ… Ø¥ÙŠÙ‚Ø§Ù ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬...")
        cleanup_resources()
        logger.info("ğŸ‘‹ [Main] ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø¨ÙˆØª Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„ØªØ¯Ø§ÙˆÙ„.")
        os._exit(0)
