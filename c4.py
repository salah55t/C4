import time
import os
import json
import logging
import requests
import numpy as np
import pandas as pd
import psycopg2
import pickle
import redis
import re
import gc
import random
from decimal import Decimal, ROUND_DOWN
from urllib.parse import urlparse
from psycopg2 import sql, OperationalError, InterfaceError
from psycopg2.extras import RealDictCursor
from binance.client import Client
from binance import ThreadedWebsocketManager
from binance.exceptions import BinanceAPIException
from flask import Flask, request, Response, jsonify, render_template_string
from flask_cors import CORS
from threading import Thread, Lock
from datetime import datetime, timedelta, timezone
from decouple import config
from typing import List, Dict, Optional, Any, Set, Tuple
from sklearn.preprocessing import StandardScaler
from collections import deque
import warnings

# --- ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª ØºÙŠØ± Ø§Ù„Ù‡Ø§Ù…Ø© ---
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.simplefilter(action='ignore', category=UserWarning)

# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (Logging) - V27.5 (API Optimization) ----------------------
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('crypto_bot_v27_5_arabic_logs.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('CryptoBotV27.5')

# ---------------------- ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© ----------------------
try:
    API_KEY: str = config('BINANCE_API_KEY')
    API_SECRET: str = config('BINANCE_API_SECRET')
    TELEGRAM_TOKEN: str = config('TELEGRAM_BOT_TOKEN')
    CHAT_ID: str = config('TELEGRAM_CHAT_ID')
    DB_URL: str = config('DATABASE_URL')
    WEBHOOK_URL: Optional[str] = config('WEBHOOK_URL', default=None)
    REDIS_URL: str = config('REDIS_URL', default='redis://localhost:6379/0')
except Exception as e:
    logger.critical(f"âŒ ÙØ´Ù„ Ø­Ø§Ø³Ù… ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©: {e}")
    exit(1)

# ---------------------- Ù…Ù„ÙØ§Øª Ø§Ù„ÙÙ„Ø§ØªØ± Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© ----------------------
FILTER_PROFILES: Dict[str, Dict[str, Any]] = {
    "STRONG_UPTREND": {
        "description": "Ø§ØªØ¬Ø§Ù‡ ØµØ§Ø¹Ø¯ Ù‚ÙˆÙŠ (Ù…Ø³ØªØ®Ù„Øµ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª)", "strategy": "MOMENTUM",
        "filters": {
            "adx": 30.0, "rel_vol": 0.5, "rsi_range": (55, 95), "roc": 0.1, "slope": 0.01,
            "min_rrr": 1.5, "min_volatility_pct": 0.40, "min_btc_correlation": 0.5, "min_bid_ask_ratio": 1.2
        }},
    "UPTREND": {
        "description": "Ø§ØªØ¬Ø§Ù‡ ØµØ§Ø¹Ø¯ (Ù…Ø³ØªØ®Ù„Øµ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª)", "strategy": "MOMENTUM",
        "filters": {
            "adx": 22.0, "rel_vol": 0.3, "rsi_range": (50, 90), "roc": 0.0, "slope": 0.0,
            "min_rrr": 1.4, "min_volatility_pct": 0.30, "min_btc_correlation": 0.3, "min_bid_ask_ratio": 1.1
        }},
    "RANGING": {
        "description": "Ø§ØªØ¬Ø§Ù‡ Ø¹Ø±Ø¶ÙŠ/Ù…Ø­Ø§ÙŠØ¯", "strategy": "MOMENTUM",
        "filters": {
            "adx": 18.0, "rel_vol": 0.2, "rsi_range": (45, 75), "roc": 0.05, "slope": 0.0,
            "min_rrr": 1.5, "min_volatility_pct": 0.25, "min_btc_correlation": -0.2, "min_bid_ask_ratio": 1.2
        }},
    "DOWNTREND": {
        "description": "Ø§ØªØ¬Ø§Ù‡ Ù‡Ø§Ø¨Ø· (Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø§Ù†Ø¹ÙƒØ§Ø³)", "strategy": "REVERSAL",
        "filters": {
            "min_rrr": 2.0, "min_volatility_pct": 0.5, "min_btc_correlation": -0.5,
            "min_relative_volume": 1.5, "min_bid_ask_ratio": 1.5
        }},
    "STRONG_DOWNTREND": { "description": "Ø§ØªØ¬Ø§Ù‡ Ù‡Ø§Ø¨Ø· Ù‚ÙˆÙŠ (Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ù…ØªÙˆÙ‚Ù)", "strategy": "DISABLED", "filters": {} },
    "WEEKEND": {
        "description": "Ø³ÙŠÙˆÙ„Ø© Ù…Ù†Ø®ÙØ¶Ø© (Ø¹Ø·Ù„Ø© Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹)", "strategy": "MOMENTUM",
        "filters": {
            "adx": 17.0, "rel_vol": 0.2, "rsi_range": (40, 70), "roc": 0.1, "slope": 0.0,
            "min_rrr": 1.5, "min_volatility_pct": 0.25, "min_btc_correlation": -0.4, "min_bid_ask_ratio": 1.4
        }}
}

# ---------------------- Ø§Ù„Ø«ÙˆØ§Ø¨Øª ÙˆØ§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© ----------------------
is_trading_enabled: bool = False; trading_status_lock = Lock()
force_momentum_strategy: bool = False; force_momentum_lock = Lock()
RISK_PER_TRADE_PERCENT: float = 1.0
BASE_ML_MODEL_NAME: str = 'LightGBM_Scalping_V8_With_Momentum'
MODEL_FOLDER: str = 'V8'
SIGNAL_GENERATION_TIMEFRAME: str = '15m'
TIMEFRAMES_FOR_TREND_ANALYSIS: List[str] = ['15m', '1h', '4h']
SIGNAL_GENERATION_LOOKBACK_DAYS: int = 30
REDIS_PRICES_HASH_NAME: str = "crypto_bot_current_prices_v8"
TRADING_FEE_PERCENT: float = 0.1
STATS_TRADE_SIZE_USDT: float = 10.0
BTC_SYMBOL: str = 'BTCUSDT'
SYMBOL_PROCESSING_BATCH_SIZE: int = 50
ADX_PERIOD: int = 14; RSI_PERIOD: int = 14; ATR_PERIOD: int = 14
EMA_PERIODS: List[int] = [21, 50, 200]
REL_VOL_PERIOD: int = 30; MOMENTUM_PERIOD: int = 12; EMA_SLOPE_PERIOD: int = 5
MAX_OPEN_TRADES: int = 4
BUY_CONFIDENCE_THRESHOLD = 0.80
ATR_FALLBACK_SL_MULTIPLIER: float = 1.5
ATR_FALLBACK_TP_MULTIPLIER: float = 2.2
USE_TRAILING_STOP_LOSS: bool = True
TRAILING_ACTIVATION_PROFIT_PERCENT: float = 1.0
TRAILING_DISTANCE_PERCENT: float = 0.8
USE_PEAK_FILTER: bool = True
PEAK_LOOKBACK_PERIOD: int = 50
PEAK_DISTANCE_THRESHOLD_PCT: float = 0.995
DYNAMIC_FILTER_ANALYSIS_INTERVAL: int = 900
ORDER_BOOK_DEPTH_LIMIT: int = 100
ORDER_BOOK_WALL_MULTIPLIER: float = 10.0
ORDER_BOOK_ANALYSIS_RANGE_PCT: float = 0.02

# --- [Ø¬Ø¯ÙŠØ¯] Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© ---
DATA_CACHE_TTL_SECONDS: int = 60 * 10  # 10 Ø¯Ù‚Ø§Ø¦Ù‚
historical_data_cache: Dict[str, Dict[str, Any]] = {}
data_cache_lock = Lock()

# --- Ù…ØªØºÙŠØ±Ø§Øª Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø¸Ø± Ù…Ù† ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª ---
is_api_rate_limited: bool = False
rate_limit_lock = Lock()
rate_limit_until: float = 0

conn: Optional[psycopg2.extensions.connection] = None
client: Optional[Client] = None
redis_client: Optional[redis.Redis] = None
ml_models_cache: Dict[str, Any] = {}; exchange_info_map: Dict[str, Any] = {}
validated_symbols_to_scan: List[str] = []
open_signals_cache: Dict[str, Dict] = {}; signal_cache_lock = Lock()
notifications_cache = deque(maxlen=50); notifications_lock = Lock()
signals_pending_closure: Set[int] = set(); closure_lock = Lock()
rejection_logs_cache = deque(maxlen=100); rejection_logs_lock = Lock()
last_market_state_check = 0
current_market_state: Dict[str, Any] = {"trend_score": 0, "trend_label": "INITIALIZING", "details_by_tf": {}, "last_updated": None}; market_state_lock = Lock()
dynamic_filter_profile_cache: Dict[str, Any] = {}; last_dynamic_filter_analysis_time: float = 0; dynamic_filter_lock = Lock()

REJECTION_REASONS_AR = {
    "Filters Not Loaded": "Ø§Ù„ÙÙ„Ø§ØªØ± ØºÙŠØ± Ù…Ø­Ù…Ù„Ø©", "Low Volatility": "ØªÙ‚Ù„Ø¨ Ù…Ù†Ø®ÙØ¶ Ø¬Ø¯Ø§Ù‹", "BTC Correlation": "Ø§Ø±ØªØ¨Ø§Ø· Ø¶Ø¹ÙŠÙ Ø¨Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ†",
    "RRR Filter": "Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©/Ø§Ù„Ø¹Ø§Ø¦Ø¯ ØºÙŠØ± ÙƒØ§ÙÙŠØ©", "Peak Filter": "ÙÙ„ØªØ± Ø§Ù„Ù‚Ù…Ø© (Ø§Ù„Ø³Ø¹Ø± Ù‚Ø±ÙŠØ¨ Ù…Ù† Ø§Ù„Ù‚Ù…Ø©)", "Invalid ATR for TP/SL": "ATR ØºÙŠØ± ØµØ§Ù„Ø­ Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù",
    "Momentum ADX": "ÙÙ„ØªØ± Ø§Ù„Ø²Ø®Ù… (ADX Ø¶Ø¹ÙŠÙ)", "Momentum Rel Vol": "ÙÙ„ØªØ± Ø§Ù„Ø²Ø®Ù… (Ø­Ø¬Ù… Ù†Ø³Ø¨ÙŠ Ù…Ù†Ø®ÙØ¶)", "Momentum RSI": "ÙÙ„ØªØ± Ø§Ù„Ø²Ø®Ù… (RSI Ø®Ø§Ø±Ø¬ Ø§Ù„Ù†Ø·Ø§Ù‚)",
    "Momentum ROC": "ÙÙ„ØªØ± Ø§Ù„Ø²Ø®Ù… (ROC Ø³Ù„Ø¨ÙŠ Ø£Ùˆ Ø¶Ø¹ÙŠÙ)", "Momentum Slope": "ÙÙ„ØªØ± Ø§Ù„Ø²Ø®Ù… (Ù…ÙŠÙ„ EMA Ø³Ù„Ø¨ÙŠ)", "Reversal Volume Filter": "ÙÙˆÙ„ÙŠÙˆÙ… Ø§Ù„Ø§Ù†Ø¹ÙƒØ§Ø³ Ø¶Ø¹ÙŠÙ",
    "Reversal Signal Rejected by ML Model": "Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ø±ÙØ¶ Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø§Ù†Ø¹ÙƒØ§Ø³", "Invalid Position Size": "Ø­Ø¬Ù… Ø§Ù„ØµÙÙ‚Ø© ØºÙŠØ± ØµØ§Ù„Ø­ (Ø§Ù„ÙˆÙ‚Ù ØªØ­Øª Ø§Ù„Ø¯Ø®ÙˆÙ„)",
    "Lot Size Adjustment Failed": "ÙØ´Ù„ Ø¶Ø¨Ø· Ø­Ø¬Ù… Ø§Ù„Ø¹Ù‚Ø¯ (LOT_SIZE)", "Min Notional Filter": "Ù‚ÙŠÙ…Ø© Ø§Ù„ØµÙÙ‚Ø© Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰",
    "Insufficient Balance": "Ø§Ù„Ø±ØµÙŠØ¯ ØºÙŠØ± ÙƒØ§ÙÙ", "Order Book Fetch Failed": "ÙØ´Ù„ Ø¬Ù„Ø¨ Ø¯ÙØªØ± Ø§Ù„Ø·Ù„Ø¨Ø§Øª", "Order Book Imbalance": "Ø§Ø®ØªÙ„Ø§Ù„ ØªÙˆØ§Ø²Ù† Ø¯ÙØªØ± Ø§Ù„Ø·Ù„Ø¨Ø§Øª (Ø¶ØºØ· Ø¨ÙŠØ¹)",
    "Large Sell Wall Detected": "ØªÙ… ÙƒØ´Ù Ø¬Ø¯Ø§Ø± Ø¨ÙŠØ¹ Ø¶Ø®Ù…", "API Rate Limited": "ØªÙ… ØªØ¬Ø§ÙˆØ² Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø·Ù„Ø¨Ø§Øª (API)"
}


# --- Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ---
fng_cache: Dict[str, Any] = {"value": -1, "classification": "ÙØ´Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„", "last_updated": 0}
FNG_CACHE_DURATION: int = 3600

def get_fear_and_greed_index() -> Dict[str, Any]:
    global fng_cache
    now = time.time()
    if now - fng_cache["last_updated"] < FNG_CACHE_DURATION: return fng_cache
    logger.info("â„¹ï¸ [F&G Index] Fetching new Fear and Greed index data...")
    try:
        response = requests.get("https://api.alternative.me/fng/?limit=1", timeout=10)
        response.raise_for_status()
        data = response.json().get('data', [])
        if data:
            value, classification = int(data[0]['value']), data[0]['value_classification']
            fng_cache = {"value": value, "classification": classification, "last_updated": now}
            logger.info(f"âœ… [F&G Index] Updated: {value} ({classification})")
        else: raise ValueError("No data in F&G API response")
    except (requests.RequestException, ValueError) as e:
        logger.error(f"âŒ [F&G Index] Could not fetch F&G Index: {e}")
        if fng_cache["value"] == -1: fng_cache["last_updated"] = now
    return fng_cache

def get_session_state() -> Tuple[List[str], str, str]:
    now_utc = datetime.now(timezone.utc)
    current_time, current_weekday = now_utc.time(), now_utc.weekday()
    sessions = {"Tokyo": ("00:00", "09:00"), "London": ("08:00", "17:00"), "New York": ("13:00", "22:00")}
    active_sessions = [name for name, (start, end) in sessions.items() if datetime.strptime(start, "%H:%M").time() <= current_time < datetime.strptime(end, "%H:%M").time()]
    if current_weekday >= 5: return active_sessions, "WEEKEND", "Ø³ÙŠÙˆÙ„Ø© Ù…Ù†Ø®ÙØ¶Ø© (Ø¹Ø·Ù„Ø© Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹)"
    if "London" in active_sessions and "New York" in active_sessions: return active_sessions, "HIGH", "Ø³ÙŠÙˆÙ„Ø© Ù…Ø±ØªÙØ¹Ø© (ØªØ¯Ø§Ø®Ù„ Ù„Ù†Ø¯Ù† ÙˆÙ†ÙŠÙˆÙŠÙˆØ±Ùƒ)"
    if active_sessions: return active_sessions, "NORMAL", f"Ø³ÙŠÙˆÙ„Ø© Ø¹Ø§Ø¯ÙŠØ© ({', '.join(active_sessions)})"
    return active_sessions, "LOW", "Ø³ÙŠÙˆÙ„Ø© Ù…Ù†Ø®ÙØ¶Ø© (Ø®Ø§Ø±Ø¬ Ø³Ø§Ø¹Ø§Øª Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©)"

# --- Ù…Ù†Ø¸Ù… Ø°ÙƒÙŠ Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Binance API ÙˆØ§Ù„Ø­Ø¸Ø± ---
def handle_binance_api_errors(func):
    def wrapper(*args, **kwargs):
        global is_api_rate_limited, rate_limit_until
        with rate_limit_lock:
            if is_api_rate_limited and time.time() < rate_limit_until:
                logger.warning(f"API is rate-limited. Skipping call to {func.__name__}.")
                symbol = args[0] if args and isinstance(args[0], str) else 'N/A'
                if func.__name__ != 'check_api_status': log_rejection(symbol, "API Rate Limited", {"function": func.__name__})
                return None
        try:
            return func(*args, **kwargs)
        except BinanceAPIException as e:
            if e.code == -1003:
                with rate_limit_lock:
                    if not is_api_rate_limited:
                        ban_duration_minutes = 30
                        rate_limit_until = time.time() + (ban_duration_minutes * 60)
                        is_api_rate_limited = True
                        logger.critical(f"ğŸš¨ IP BANNED by Binance (Code -1003). Pausing all API requests for {ban_duration_minutes} minutes.")
                        log_and_notify("critical", f"IP BANNED by Binance. Pausing API requests for {ban_duration_minutes} minutes.", "API_BAN")
                        def unban_task():
                            global is_api_rate_limited
                            time.sleep(ban_duration_minutes * 60 + 5)
                            with rate_limit_lock: is_api_rate_limited = False; logger.info("âœ… API rate-limit ban has been lifted. Resuming API calls.")
                        Thread(target=unban_task, daemon=True).start()
            logger.error(f"âŒ Binance API Error in {func.__name__}: {e}", exc_info=False)
            return None
        except Exception as e:
            logger.error(f"âŒ Unexpected Error in {func.__name__}: {e}", exc_info=True)
            return None
    return wrapper

# ---------------------- Ø¯Ø§Ù„Ø© HTML Ù„Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ… ----------------------
def get_dashboard_html():
    return """
<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ù„ÙˆØ­Ø© ØªØ­ÙƒÙ… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ V27.5</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.2/dist/chart.umd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/luxon@3.4.4/build/global/luxon.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-adapter-luxon@1.3.1/dist/chartjs-adapter-luxon.umd.min.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Tajawal:wght@400;500;700;800&display=swap" rel="stylesheet">
    <style>
        :root { --bg-main: #0D1117; --bg-card: #161B22; --border-color: #30363D; --text-primary: #E6EDF3; --text-secondary: #848D97; --accent-blue: #58A6FF; --accent-green: #3FB950; --accent-red: #F85149; --accent-yellow: #D29922; }
        body { font-family: 'Tajawal', sans-serif; background-color: var(--bg-main); color: var(--text-primary); }
        .card { background-color: var(--bg-card); border: 1px solid var(--border-color); border-radius: 0.5rem; transition: all 0.3s ease; }
        .card:hover { border-color: var(--accent-blue); }
        .skeleton { animation: pulse 1.5s cubic-bezier(0.4, 0, 0.6, 1) infinite; background-color: #21262d; border-radius: 0.5rem; }
        @keyframes pulse { 50% { opacity: .6; } }
        .tab-btn { position: relative; transition: color 0.2s ease; }
        .tab-btn.active { color: var(--text-primary); }
        .tab-btn.active::after { content: ''; position: absolute; bottom: -1px; left: 0; right: 0; height: 2px; background-color: var(--accent-blue); border-radius: 2px; }
        .toggle-bg:after { content: ''; position: absolute; top: 2px; left: 2px; background: white; border-radius: 9999px; height: 1.25rem; width: 1.25rem; transition: transform 0.2s ease-in-out; }
        input:checked + .toggle-bg:after { transform: translateX(100%); }
        input:checked + .toggle-bg { background-color: var(--accent-green); }
        .trend-light { width: 1rem; height: 1rem; border-radius: 9999px; border: 2px solid rgba(255, 255, 255, 0.1); transition: background-color 0.5s ease, box-shadow 0.5s ease; box-shadow: inset 0 1px 2px rgba(0,0,0,0.3); }
        .light-on-green { background-color: var(--accent-green); box-shadow: inset 0 1px 2px rgba(0,0,0,0.3), 0 0 10px 2px rgba(63, 185, 80, 0.6); }
        .light-on-red { background-color: var(--accent-red); box-shadow: inset 0 1px 2px rgba(0,0,0,0.3), 0 0 10px 2px rgba(248, 81, 73, 0.6); }
        .light-on-yellow { background-color: var(--accent-yellow); box-shadow: inset 0 1px 2px rgba(0,0,0,0.3), 0 0 10px 2px rgba(210, 153, 34, 0.6); }
        .light-off { background-color: #30363D; }
    </style>
</head>
<body class="p-4 md:p-6">
    <div class="container mx-auto max-w-screen-2xl">
        <header class="mb-6 flex flex-wrap justify-between items-center gap-4">
            <h1 class="text-2xl md:text-3xl font-extrabold text-white">
                <span class="text-accent-blue">Ù„ÙˆØ­Ø© ØªØ­ÙƒÙ… Ø§Ù„ØªØ¯Ø§ÙˆÙ„</span>
                <span class="text-text-secondary font-medium">V27.5</span>
            </h1>
            <div id="trend-lights-container" class="flex items-center gap-x-6 bg-black/20 px-4 py-2 rounded-lg border border-border-color">
                <div class="flex items-center gap-2" title="Ø§ØªØ¬Ø§Ù‡ ÙØ±ÙŠÙ… 15 Ø¯Ù‚ÙŠÙ‚Ø©"><div id="trend-light-15m" class="trend-light skeleton"></div><span class="text-sm font-bold text-text-secondary">15Ø¯</span></div>
                <div class="flex items-center gap-2" title="Ø§ØªØ¬Ø§Ù‡ ÙØ±ÙŠÙ… Ø³Ø§Ø¹Ø©"><div id="trend-light-1h" class="trend-light skeleton"></div><span class="text-sm font-bold text-text-secondary">1Ø³</span></div>
                <div class="flex items-center gap-2" title="Ø§ØªØ¬Ø§Ù‡ ÙØ±ÙŠÙ… 4 Ø³Ø§Ø¹Ø§Øª"><div id="trend-light-4h" class="trend-light skeleton"></div><span class="text-sm font-bold text-text-secondary">4Ø³</span></div>
            </div>
            <div id="connection-status" class="flex items-center gap-3 text-sm">
                <div class="flex items-center gap-2"><div id="db-status-light" class="w-2.5 h-2.5 rounded-full bg-gray-600 animate-pulse"></div><span class="text-text-secondary">DB</span></div>
                <div class="flex items-center gap-2"><div id="api-status-light" class="w-2.5 h-2.5 rounded-full bg-gray-600 animate-pulse"></div><span class="text-text-secondary">API</span></div>
            </div>
        </header>
        <!-- ... (Ø¨Ù‚ÙŠØ© ÙƒÙˆØ¯ HTML Ù„Ù… ÙŠØªØºÙŠØ±) ... -->
        <main>
            <div id="signals-tab" class="tab-content">...</div>
            <div id="stats-tab" class="tab-content hidden">...</div>
            <div id="notifications-tab" class="tab-content hidden">...</div>
            <div id="rejections-tab" class="tab-content hidden">...</div>
            <div id="filters-tab" class="tab-content hidden">...</div>
        </main>
    </div>
<script>
// ... (ÙƒÙˆØ¯ JavaScript Ù„Ù… ÙŠØªØºÙŠØ± Ø¨Ø´ÙƒÙ„ ÙƒØ¨ÙŠØ±) ...
function manualCloseSignal(signalId) {
    if (confirm(`Ù‡Ù„ Ø£Ù†Øª Ù…ØªØ£ÙƒØ¯ Ù…Ù† Ø±ØºØ¨ØªÙƒ ÙÙŠ Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„ØµÙÙ‚Ø© #${signalId} ÙŠØ¯ÙˆÙŠØ§Ù‹ØŸ`)) {
        fetch(`/api/close/${signalId}`, { method: 'POST' }).then(res => res.json()).then(data => {
            alert(data.message || data.error);
            refreshData();
        });
    }
}
function refreshData() {
    // ...
    updateList('/api/rejection_logs', 'rejections-list', log => {
        const details = log.details ? Object.entries(log.details).map(([key, value]) => `${key}: ${value}`).join(', ') : 'Ù„Ø§ ØªÙˆØ¬Ø¯ ØªÙØ§ØµÙŠÙ„';
        return `<div class="p-3 rounded-md bg-gray-900/50 text-sm">[${new Date(log.timestamp).toLocaleString('fr-CA', { timeZone: 'UTC' })}] <strong>${log.symbol}</strong>: ${log.reason} - <span class="font-mono text-xs text-text-secondary">${details}</span></div>`;
    });
}
setInterval(refreshData, 5000);
window.onload = refreshData;
</script>
</body>
</html>
    """

# ---------------------- Ø¯ÙˆØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ----------------------
def init_db(retries: int = 5, delay: int = 5) -> None:
    global conn
    logger.info("[DB] Initializing database connection...")
    db_url_to_use = DB_URL
    if 'postgres' in db_url_to_use and 'sslmode' not in db_url_to_use: db_url_to_use += ('&' if '?' in db_url_to_use else '?') + "sslmode=require"
    for attempt in range(retries):
        try:
            conn = psycopg2.connect(db_url_to_use, connect_timeout=15, cursor_factory=RealDictCursor)
            conn.autocommit = False
            with conn.cursor() as cur:
                cur.execute("""
                    CREATE TABLE IF NOT EXISTS signals (
                        id SERIAL PRIMARY KEY, symbol TEXT NOT NULL, entry_price DOUBLE PRECISION NOT NULL,
                        target_price DOUBLE PRECISION NOT NULL, stop_loss DOUBLE PRECISION NOT NULL, status TEXT DEFAULT 'open',
                        closing_price DOUBLE PRECISION, closed_at TIMESTAMP, profit_percentage DOUBLE PRECISION,
                        strategy_name TEXT, signal_details JSONB, current_peak_price DOUBLE PRECISION,
                        is_real_trade BOOLEAN DEFAULT FALSE, quantity DOUBLE PRECISION, order_id TEXT
                    );
                    CREATE INDEX IF NOT EXISTS idx_signals_status ON signals (status);
                    CREATE TABLE IF NOT EXISTS notifications (id SERIAL PRIMARY KEY, timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW(), type TEXT NOT NULL, message TEXT NOT NULL, is_read BOOLEAN DEFAULT FALSE);
                """)
            conn.commit()
            logger.info("âœ… [DB] Database connection and schema are up-to-date.")
            return
        except Exception as e:
            logger.error(f"âŒ [DB] Error during initialization (Attempt {attempt + 1}/{retries}): {e}")
            if conn: conn.rollback()
            if attempt < retries - 1: time.sleep(delay)
            else: logger.critical("âŒ [DB] Failed to connect to the database.")

def check_db_connection() -> bool:
    global conn
    if conn is None or conn.closed != 0:
        logger.warning("[DB] Connection is closed, attempting to reconnect...")
        init_db()
    try:
        if conn and conn.closed == 0:
            with conn.cursor() as cur: cur.execute("SELECT 1;")
            return True
        return False
    except (OperationalError, InterfaceError):
        logger.error(f"âŒ [DB] Connection lost. Reconnecting...")
        try: init_db(); return conn is not None and conn.closed == 0
        except Exception as retry_e: logger.error(f"âŒ [DB] Reconnect failed: {retry_e}"); return False
    return False

def log_and_notify(level: str, message: str, notification_type: str):
    log_methods = {'info': logger.info, 'warning': logger.warning, 'error': logger.error, 'critical': logger.critical}
    log_methods.get(level.lower(), logger.info)(message)
    if not check_db_connection() or not conn: return
    try:
        new_notification = {"timestamp": datetime.now().isoformat(), "type": notification_type, "message": message}
        with notifications_lock: notifications_cache.appendleft(new_notification)
        with conn.cursor() as cur: cur.execute("INSERT INTO notifications (type, message) VALUES (%s, %s);", (notification_type, message))
        conn.commit()
    except Exception as e: logger.error(f"âŒ [Notify DB] Failed to save notification: {e}"); conn.rollback()

def log_rejection(symbol: str, reason_key: str, details: Optional[Dict] = None):
    reason_ar = REJECTION_REASONS_AR.get(reason_key, reason_key)
    details_str = " | ".join([f"{k}: {v}" for k, v in (details or {}).items()])
    logger.info(f"ğŸš« [REJECTED] {symbol} | {reason_ar} ({reason_key}) | {details_str}")
    with rejection_logs_lock:
        rejection_logs_cache.appendleft({"timestamp": datetime.now(timezone.utc).isoformat(), "symbol": symbol, "reason": reason_ar, "details": details or {}})

def init_redis() -> None:
    global redis_client
    logger.info("[Redis] Initializing Redis connection...")
    try:
        redis_client = redis.from_url(REDIS_URL, decode_responses=True)
        redis_client.ping()
        logger.info("âœ… [Redis] Successfully connected to Redis server.")
    except redis.exceptions.ConnectionError as e: logger.critical(f"âŒ [Redis] Failed to connect to Redis: {e}"); exit(1)

# ---------------------- Ø¯ÙˆØ§Ù„ Binance ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ----------------------
@handle_binance_api_errors
def get_exchange_info_map_call() -> Optional[Dict]: return client.get_exchange_info()

def get_exchange_info_map() -> None:
    global exchange_info_map
    logger.info("â„¹ï¸ [Exchange Info] Fetching exchange trading rules...")
    info = get_exchange_info_map_call()
    if info: exchange_info_map = {s['symbol']: s for s in info['symbols']}; logger.info(f"âœ… [Exchange Info] Loaded rules for {len(exchange_info_map)} symbols.")
    else: logger.error("âŒ [Exchange Info] Could not fetch exchange info due to API error.")

def get_validated_symbols(filename: str = 'crypto_list.txt') -> List[str]:
    if not client: return []
    try:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        file_path = os.path.join(script_dir, filename)
        with open(file_path, 'r', encoding='utf-8') as f: raw_symbols = {line.strip().upper() for line in f if line.strip() and not line.startswith('#')}
        formatted = {f"{s}USDT" if not s.endswith('USDT') else s for s in raw_symbols}
        if not exchange_info_map: get_exchange_info_map()
        active = {s for s, info in exchange_info_map.items() if info.get('quoteAsset') == 'USDT' and info.get('status') == 'TRADING'}
        validated = sorted(list(formatted.intersection(active)))
        logger.info(f"âœ… [Validation] Bot will monitor {len(validated)} symbols.")
        return validated
    except Exception as e: logger.error(f"âŒ [Validation] Error during symbol validation: {e}", exc_info=True); return []

@handle_binance_api_errors
def fetch_historical_data(symbol: str, interval: str, days: int) -> Optional[pd.DataFrame]:
    limit = int((days * 24 * 60) / int(re.sub('[a-zA-Z]', '', interval)))
    klines = client.get_historical_klines(symbol, interval, limit=min(limit, 1000))
    if not klines: return None
    df = pd.DataFrame(klines, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_volume', 'trades', 'taker_buy_base', 'taker_buy_quote', 'ignore'])
    df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']]
    for col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')
    df = df.astype({'open': np.float32, 'high': np.float32, 'low': np.float32, 'close': np.float32, 'volume': np.float32})
    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True)
    df.set_index('timestamp', inplace=True)
    return df.dropna()

# --- [Ø¬Ø¯ÙŠØ¯] Ø¯Ø§Ù„Ø© Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª ---
def get_cached_historical_data(symbol: str, interval: str, days: int) -> Optional[pd.DataFrame]:
    cache_key = f"{symbol}_{interval}"
    now = time.time()
    with data_cache_lock:
        if cache_key in historical_data_cache:
            cached_item = historical_data_cache[cache_key]
            if now - cached_item['timestamp'] < DATA_CACHE_TTL_SECONDS:
                logger.debug(f"âœ… [Cache HIT] Using cached data for {cache_key}.")
                return cached_item['data'].copy()
    
    logger.info(f"â³ [Cache MISS] Fetching new historical data for {cache_key}.")
    df = fetch_historical_data(symbol, interval, days)
    
    if df is not None and not df.empty:
        with data_cache_lock:
            historical_data_cache[cache_key] = {'timestamp': now, 'data': df}
            logger.info(f"ğŸ’¾ [Cache SET] Stored new data for {cache_key}.")
        return df.copy()
    return None

@handle_binance_api_errors
def analyze_order_book(symbol: str, entry_price: float) -> Optional[Dict[str, Any]]:
    # ... (Ù„Ù… ÙŠØªØºÙŠØ±)
    return None

# ---------------------- Ø¯ÙˆØ§Ù„ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙˆØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ ----------------------
def calculate_features(df: pd.DataFrame, btc_df: Optional[pd.DataFrame]) -> pd.DataFrame:
    # ... (Ù„Ù… ÙŠØªØºÙŠØ±)
    return df

def determine_market_trend_score():
    global current_market_state, last_market_state_check
    with market_state_lock:
        if time.time() - last_market_state_check < 300: return
    logger.info("ğŸ§  [Market Score] Updating multi-timeframe trend score...")
    try:
        total_score, details, tf_weights = 0, {}, {'15m': 0.2, '1h': 0.3, '4h': 0.5}
        for tf in TIMEFRAMES_FOR_TREND_ANALYSIS:
            days = 5 if tf == '15m' else (15 if tf == '1h' else 50)
            # --- [Ù…ÙØ¹Ø¯Ù‘ÙÙ„] Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø¹ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª ---
            df = get_cached_historical_data(BTC_SYMBOL, tf, days)
            if df is None or len(df) < EMA_PERIODS[-1]:
                details[tf] = {"score": 0, "label": "ØºÙŠØ± ÙˆØ§Ø¶Ø­", "reason": "Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ©"}; continue
            for p in EMA_PERIODS: df[f'ema_{p}'] = df['close'].ewm(span=p, adjust=False).mean()
            last = df.iloc[-1]
            close, ema21, ema50, ema200 = last['close'], last['ema_21'], last['ema_50'], last['ema_200']
            tf_score = (1 if close > ema21 else -1) + (1 if ema21 > ema50 else -1) + (1 if ema50 > ema200 else -1)
            label = "ØµØ§Ø¹Ø¯" if tf_score >= 2 else ("Ù‡Ø§Ø¨Ø·" if tf_score <= -2 else "Ù…Ø­Ø§ÙŠØ¯")
            details[tf] = {"score": tf_score, "label": label, "reason": f"E21:{ema21:.2f},E50:{ema50:.2f},E200:{ema200:.2f}"}
            total_score += tf_score * tf_weights[tf]
        final_score = round(total_score)
        trend_label = "ØµØ§Ø¹Ø¯ Ù‚ÙˆÙŠ" if final_score >= 4 else ("ØµØ§Ø¹Ø¯" if final_score >= 1 else ("Ù‡Ø§Ø¨Ø· Ù‚ÙˆÙŠ" if final_score <= -4 else ("Ù‡Ø§Ø¨Ø·" if final_score <= -1 else "Ù…Ø­Ø§ÙŠØ¯")))
        with market_state_lock:
            current_market_state = {"trend_score": final_score, "trend_label": trend_label, "details_by_tf": details, "last_updated": datetime.now(timezone.utc).isoformat()}
            last_market_state_check = time.time()
        logger.info(f"âœ… [Market Score] New State: Score={final_score}, Label='{trend_label}'")
    except Exception as e:
        logger.error(f"âŒ [Market Score] Failed to determine market state: {e}", exc_info=True)
        with market_state_lock: current_market_state.update({'trend_score': 0, 'trend_label': "ØºÙŠØ± ÙˆØ§Ø¶Ø­"})

def analyze_market_and_create_dynamic_profile():
    # ... (Ù„Ù… ÙŠØªØºÙŠØ±)
    pass

def get_current_filter_profile() -> Dict[str, Any]:
    with dynamic_filter_lock: return dict(dynamic_filter_profile_cache)

def load_ml_model_bundle_from_folder(symbol: str) -> Optional[Dict[str, Any]]:
    # ... (Ù„Ù… ÙŠØªØºÙŠØ±)
    return None

# ---------------------- Ø¯ÙˆØ§Ù„ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© ÙˆØ§Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ ----------------------
def adjust_quantity_to_lot_size(symbol: str, quantity: float) -> Optional[Decimal]:
    # ... (Ù„Ù… ÙŠØªØºÙŠØ±)
    return None

@handle_binance_api_errors
def get_asset_balance_call(asset: str) -> Optional[Dict]:
    return client.get_asset_balance(asset=asset)

def calculate_position_size(symbol: str, entry_price: float, stop_loss_price: float) -> Optional[Decimal]:
    # ... (Ù„Ù… ÙŠØªØºÙŠØ±)
    return None

@handle_binance_api_errors
def place_order(symbol: str, side: str, quantity: Decimal, order_type: str = Client.ORDER_TYPE_MARKET) -> Optional[Dict]:
    # ... (Ù„Ù… ÙŠØªØºÙŠØ±)
    return None

class TradingStrategy:
    # ... (Ù„Ù… ÙŠØªØºÙŠØ±)
    pass

def passes_filters(symbol: str, last_features: pd.Series, profile: Dict[str, Any], entry_price: float, tp_sl_data: Dict, df_15m: pd.DataFrame) -> bool:
    # ... (Ù„Ù… ÙŠØªØºÙŠØ±)
    return True

def passes_order_book_check(symbol: str, order_book_analysis: Dict, profile: Dict) -> bool:
    # ... (Ù„Ù… ÙŠØªØºÙŠØ±)
    return True

def calculate_tp_sl(symbol: str, entry_price: float, last_atr: float) -> Optional[Dict[str, Any]]:
    # ... (Ù„Ù… ÙŠØªØºÙŠØ±)
    return None

def handle_price_update_message(msg: List[Dict[str, Any]]) -> None:
    if not isinstance(msg, list) or not redis_client: return
    try:
        price_updates = {item.get('s'): float(item.get('c', 0)) for item in msg if item.get('s') and item.get('c')}
        if price_updates: redis_client.hset(REDIS_PRICES_HASH_NAME, mapping=price_updates)
    except Exception as e: logger.error(f"âŒ [WebSocket Price Updater] Error: {e}", exc_info=True)

def initiate_signal_closure(symbol: str, signal_to_close: Dict, status: str, closing_price: float):
    # ... (Ù„Ù… ÙŠØªØºÙŠØ±)
    pass

def trade_monitoring_loop():
    # ... (Ù„Ù… ÙŠØªØºÙŠØ±)
    pass

def send_telegram_message(target_chat_id: str, text: str):
    # ... (Ù„Ù… ÙŠØªØºÙŠØ±)
    pass

def send_new_signal_alert(signal_data: Dict[str, Any]):
    # ... (Ù„Ù… ÙŠØªØºÙŠØ±)
    pass

def insert_signal_into_db(signal: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    # ... (Ù„Ù… ÙŠØªØºÙŠØ±)
    return None

def close_signal(signal: Dict, status: str, closing_price: float):
    # ... (Ù„Ù… ÙŠØªØºÙŠØ±)
    pass

def load_open_signals_to_cache():
    # ... (Ù„Ù… ÙŠØªØºÙŠØ±)
    pass

def load_notifications_to_cache():
    # ... (Ù„Ù… ÙŠØªØºÙŠØ±)
    pass

def get_btc_data_for_bot() -> Optional[pd.DataFrame]:
    # --- [Ù…ÙØ¹Ø¯Ù‘ÙÙ„] Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø¹ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª ---
    btc_data = get_cached_historical_data(BTC_SYMBOL, SIGNAL_GENERATION_TIMEFRAME, SIGNAL_GENERATION_LOOKBACK_DAYS)
    if btc_data is not None: btc_data['btc_returns'] = btc_data['close'].pct_change()
    return btc_data

def perform_end_of_cycle_cleanup():
    logger.info("ğŸ§¹ [Cleanup] Starting end-of-cycle cleanup...")
    try:
        # Ù„Ø§ ØªÙ‚Ù… Ø¨Ù…Ø³Ø­ Ø°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù‡Ù†Ø§ØŒ Ø¯Ø¹Ù‡Ø§ ØªØ­ØªÙØ¸ Ø¨Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        ml_models_cache.clear()
        collected = gc.collect()
        logger.info(f"ğŸ§¹ [Cleanup] ML model cache cleared. Collected {collected} objects.")
    except Exception as e: logger.error(f"âŒ [Cleanup] An error occurred during cleanup: {e}", exc_info=True)

# ---------------------- Ø­Ù„Ù‚Ø© Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ----------------------
def main_loop():
    logger.info("[Main Loop] Waiting for initialization...")
    time.sleep(15)
    if not validated_symbols_to_scan:
        log_and_notify("critical", "No validated symbols to scan. Bot will not start.", "SYSTEM"); return
    
    log_and_notify("info", f"âœ… Starting main scan loop for {len(validated_symbols_to_scan)} symbols.", "SYSTEM")
    
    while True:
        try:
            logger.info("ğŸ”„ Starting new main cycle...")
            determine_market_trend_score()
            analyze_market_and_create_dynamic_profile()
            filter_profile = get_current_filter_profile()
            active_strategy_type = filter_profile.get("strategy")

            if not active_strategy_type or active_strategy_type == "DISABLED":
                logger.warning(f"ğŸ›‘ Trading disabled by profile: '{filter_profile.get('name')}'. Skipping cycle."); time.sleep(300); continue

            if redis_client:
                num_prices = redis_client.hlen(REDIS_PRICES_HASH_NAME)
                if num_prices < len(validated_symbols_to_scan) * 0.7:
                    logger.warning(f"âš ï¸ [Main Loop] Redis price cache is not fully populated ({num_prices}/{len(validated_symbols_to_scan)}). Waiting for WebSocket...")
                    time.sleep(30); continue
            
            btc_data = get_btc_data_for_bot()
            if btc_data is None: logger.warning("âš ï¸ Could not get BTC data, some features will be disabled."); time.sleep(60); continue
            
            script_dir = os.path.dirname(os.path.abspath(__file__))
            all_symbols_with_models = [s for s in validated_symbols_to_scan if os.path.exists(os.path.join(script_dir, MODEL_FOLDER, f"{BASE_ML_MODEL_NAME}_{s}.pkl"))]
            if not all_symbols_with_models: logger.warning("âš ï¸ No symbols with models found. Skipping scan cycle."); time.sleep(300); continue

            random.shuffle(all_symbols_with_models)
            total_batches = (len(all_symbols_with_models) + SYMBOL_PROCESSING_BATCH_SIZE - 1) // SYMBOL_PROCESSING_BATCH_SIZE

            for i in range(0, len(all_symbols_with_models), SYMBOL_PROCESSING_BATCH_SIZE):
                batch_symbols = all_symbols_with_models[i:i + SYMBOL_PROCESSING_BATCH_SIZE]
                batch_num = (i // SYMBOL_PROCESSING_BATCH_SIZE) + 1
                logger.info(f"ğŸ”„ Processing Batch {batch_num}/{total_batches} with {len(batch_symbols)} symbols.")

                for symbol in batch_symbols:
                    try:
                        with signal_cache_lock:
                            if symbol in open_signals_cache or len(open_signals_cache) >= MAX_OPEN_TRADES: continue
                        
                        model_bundle = load_ml_model_bundle_from_folder(symbol)
                        if not model_bundle: continue

                        # --- [Ù…ÙØ¹Ø¯Ù‘ÙÙ„] Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø¹ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª ---
                        df_15m = get_cached_historical_data(symbol, SIGNAL_GENERATION_TIMEFRAME, SIGNAL_GENERATION_LOOKBACK_DAYS)
                        if df_15m is None or df_15m.empty: continue
                        
                        if not redis_client: continue
                        entry_price_str = redis_client.hget(REDIS_PRICES_HASH_NAME, symbol)
                        if not entry_price_str: logger.debug(f"[{symbol}] Price not in Redis cache. Skipping."); continue
                        entry_price = float(entry_price_str)
                        
                        df_features = calculate_features(df_15m, btc_data)
                        if df_features is None or df_features.empty: continue
                        
                        strategy = TradingStrategy(symbol)
                        ml_signal = strategy.generate_buy_signal(df_features)
                        if not ml_signal or ml_signal['confidence'] < BUY_CONFIDENCE_THRESHOLD: continue
                        
                        last_features = df_features.iloc[-1]
                        tp_sl_data = calculate_tp_sl(symbol, entry_price, last_features.get('atr', 0))
                        if not tp_sl_data or not passes_filters(symbol, last_features, filter_profile, entry_price, tp_sl_data, df_15m): continue
                        
                        order_book_analysis = analyze_order_book(symbol, entry_price)
                        if not order_book_analysis or not passes_order_book_check(symbol, order_book_analysis, filter_profile): continue
                        
                        # ... (Ø¨Ù‚ÙŠØ© Ù…Ù†Ø·Ù‚ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØµÙÙ‚Ø© Ù„Ù… ÙŠØªØºÙŠØ±) ...

                    except Exception as e:
                        logger.error(f"âŒ [Processing Error] for symbol {symbol}: {e}", exc_info=True)
                    finally: time.sleep(0.5)
                
                logger.info(f"ğŸ§¹ [Batch Cleanup] Cleaning up memory after batch {batch_num}/{total_batches}...")
                ml_models_cache.clear(); gc.collect()

            logger.info("âœ… [End of Cycle] Full scan of all batches finished. Waiting for 60 seconds..."); time.sleep(60)

        except (KeyboardInterrupt, SystemExit):
            log_and_notify("info", "Bot is shutting down by user request.", "SYSTEM"); break
        except Exception as main_err:
            log_and_notify("error", f"Critical error in main loop: {main_err}", "SYSTEM"); time.sleep(120)

# ---------------------- ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª Flask ----------------------
app = Flask(__name__)
# ... (Ø¨Ù‚ÙŠØ© Ø¯ÙˆØ§Ù„ Flask Ù„Ù… ØªØªØºÙŠØ±)

def run_flask():
    port = int(os.environ.get('PORT', 10000))
    host = "0.0.0.0"
    logger.info(f"âœ… Preparing to start dashboard on {host}:{port}")
    try: from waitress import serve; serve(app, host=host, port=port, threads=8)
    except ImportError: logger.warning("âš ï¸ 'waitress' not found. Using Flask's development server."); app.run(host=host, port=port)

# ---------------------- Ù†Ù‚Ø·Ø© Ø§Ù†Ø·Ù„Ø§Ù‚ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ ----------------------
def run_websocket_manager():
    if not client or not validated_symbols_to_scan:
        logger.error("âŒ [WebSocket] Cannot start: Client or symbols not initialized."); return
    logger.info("ğŸ“¡ [WebSocket] Starting WebSocket Manager...")
    twm = ThreadedWebsocketManager(api_key=API_KEY, api_secret=API_SECRET)
    twm.start()
    streams = [f"{s.lower()}@miniTicker" for s in validated_symbols_to_scan]
    twm.start_multiplex_socket(callback=handle_price_update_message, streams=streams)
    logger.info(f"âœ… [WebSocket] Subscribed to {len(streams)} price streams.")
    twm.join()

def initialize_bot_services():
    global client, validated_symbols_to_scan
    logger.info("ğŸ¤– [Bot Services] Starting background initialization...")
    try:
        client = Client(API_KEY, API_SECRET)
        init_db(); init_redis()
        get_exchange_info_map()
        load_open_signals_to_cache(); load_notifications_to_cache()
        validated_symbols_to_scan = get_validated_symbols()
        if not validated_symbols_to_scan:
            logger.critical("âŒ No validated symbols to scan. Bot will not start."); return
        
        Thread(target=run_websocket_manager, daemon=True).start()
        # --- [Ù…ÙØ¹Ø¯Ù‘ÙÙ„] Ø²ÙŠØ§Ø¯Ø© ÙˆÙ‚Øª Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ù„Ù„Ø³Ù…Ø§Ø­ Ù„Ù€ WebSocket Ø¨Ø§Ù„Ø¹Ù…Ù„ ---
        logger.info("â³ Giving WebSocket Manager time to populate Redis (20 seconds)...")
        time.sleep(20)

        Thread(target=determine_market_trend_score, daemon=True).start()
        Thread(target=trade_monitoring_loop, daemon=True).start()
        Thread(target=main_loop, daemon=True).start()
        logger.info("âœ… [Bot Services] All background services started successfully.")
    except Exception as e:
        log_and_notify("critical", f"A critical error occurred during initialization: {e}", "SYSTEM")
        exit(1)

if __name__ == "__main__":
    logger.info("ğŸš€ LAUNCHING TRADING BOT & DASHBOARD (V27.5 - API Optimization) ğŸš€")
    initialization_thread = Thread(target=initialize_bot_services, daemon=True)
    initialization_thread.start()
    run_flask()
    logger.info("ğŸ‘‹ [Shutdown] Application has been shut down."); os._exit(0)
