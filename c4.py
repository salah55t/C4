import time
import os
import json
import logging
import requests
import numpy as np
import pandas as pd
import psycopg2
import pickle
import gc
from psycopg2 import sql, OperationalError, InterfaceError
from psycopg2.extras import RealDictCursor
from binance.client import Client
from binance import ThreadedWebsocketManager
from binance.exceptions import BinanceAPIException
from flask import Flask, request, Response, jsonify, render_template_string
from flask_cors import CORS
from threading import Thread, Lock
from datetime import datetime, timedelta, UTC
from decouple import config
from typing import List, Dict, Optional, Tuple, Any, Union
from sklearn.preprocessing import StandardScaler
from collections import deque

# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (Logging) ----------------------
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('crypto_bot_v5_advanced_sr.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('CryptoBotV5_AdvancedSR')

# ---------------------- ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© ----------------------
try:
    API_KEY: str = config('BINANCE_API_KEY')
    API_SECRET: str = config('BINANCE_API_SECRET')
    TELEGRAM_TOKEN: str = config('TELEGRAM_BOT_TOKEN')
    CHAT_ID: str = config('TELEGRAM_CHAT_ID')
    DB_URL: str = config('DATABASE_URL')
    WEBHOOK_URL: Optional[str] = config('WEBHOOK_URL', default=None)
except Exception as e:
     logger.critical(f"âŒ ÙØ´Ù„ Ø­Ø§Ø³Ù… ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©: {e}")
     exit(1)

# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø«ÙˆØ§Ø¨Øª ÙˆØ§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© ----------------------
BASE_ML_MODEL_NAME: str = 'LightGBM_Scalping_V5'
SIGNAL_GENERATION_TIMEFRAME: str = '15m'
HIGHER_TIMEFRAME: str = '4h'
DATA_FETCH_LOOKBACK_DAYS: int = 15

# --- Indicator & Feature Parameters ---
ADX_PERIOD: int = 14
BBANDS_PERIOD: int = 20
RSI_PERIOD: int = 14
MACD_FAST, MACD_SLOW, MACD_SIGNAL = 12, 26, 9
ATR_PERIOD: int = 14
EMA_SLOW_PERIOD: int = 200
EMA_FAST_PERIOD: int = 50
BTC_CORR_PERIOD: int = 30
STOCH_RSI_PERIOD: int = 14
STOCH_K: int = 3
STOCH_D: int = 3
REL_VOL_PERIOD: int = 30
RSI_OVERBOUGHT: int = 70
RSI_OVERSOLD: int = 30
STOCH_RSI_OVERBOUGHT: int = 80
STOCH_RSI_OVERSOLD: int = 20
BTC_SYMBOL = 'BTCUSDT'

# --- Trading Logic Constants ---
MODEL_CONFIDENCE_THRESHOLD = 0.80
MAX_OPEN_TRADES: int = 5
USE_SR_LEVELS = True
MINIMUM_SR_SCORE = 30
ATR_SL_MULTIPLIER = 2.0
ATR_TP_MULTIPLIER = 2.5
USE_BTC_TREND_FILTER = True
BTC_TREND_TIMEFRAME = '4h'
BTC_TREND_EMA_PERIOD = 10

# --- Ø«ÙˆØ§Ø¨Øª ÙÙ„ØªØ±Ø© Ø§Ù„ØµÙÙ‚Ø§Øª ---
MINIMUM_PROFIT_PERCENTAGE = 0.5
MINIMUM_RISK_REWARD_RATIO = 1.2
MINIMUM_15M_VOLUME_USDT = 10_000

# --- Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© ÙˆÙ‚ÙÙ„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª ---
conn: Optional[psycopg2.extensions.connection] = None
client: Optional[Client] = None
validated_symbols_to_scan: List[str] = []
open_signals_cache: Dict[str, Dict] = {}
signal_cache_lock = Lock()
current_prices: Dict[str, float] = {}
prices_lock = Lock()
notifications_cache = deque(maxlen=50)
notifications_lock = Lock()


# ---------------------- Ø¯ÙˆØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù…ÙØ¹Ø¯Ù‘ÙÙ„Ø©) ----------------------
def init_db(retries: int = 5, delay: int = 5) -> None:
    global conn
    logger.info("[Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª] Ø¨Ø¯Ø¡ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø§ØªØµØ§Ù„...")
    for attempt in range(retries):
        try:
            conn = psycopg2.connect(DB_URL, connect_timeout=10, cursor_factory=RealDictCursor)
            conn.autocommit = False
            with conn.cursor() as cur:
                cur.execute("""
                    CREATE TABLE IF NOT EXISTS signals ( id SERIAL PRIMARY KEY, symbol TEXT NOT NULL, entry_price DOUBLE PRECISION NOT NULL,
                        target_price DOUBLE PRECISION NOT NULL, stop_loss DOUBLE PRECISION NOT NULL, status TEXT DEFAULT 'open',
                        closing_price DOUBLE PRECISION, closed_at TIMESTAMP, profit_percentage DOUBLE PRECISION,
                        strategy_name TEXT, signal_details JSONB );
                """)
                cur.execute("""
                    CREATE TABLE IF NOT EXISTS notifications ( id SERIAL PRIMARY KEY, timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                        type TEXT NOT NULL, message TEXT NOT NULL, is_read BOOLEAN DEFAULT FALSE );
                """)
                cur.execute("""
                     CREATE TABLE IF NOT EXISTS ml_models ( id SERIAL PRIMARY KEY, model_name TEXT NOT NULL UNIQUE,
                        model_data BYTEA NOT NULL, trained_at TIMESTAMP DEFAULT NOW(), metrics JSONB );
                """)
                cur.execute("""
                    CREATE TABLE IF NOT EXISTS support_resistance_levels ( id SERIAL PRIMARY KEY, symbol TEXT NOT NULL,
                        level_price DOUBLE PRECISION NOT NULL, level_type TEXT NOT NULL, timeframe TEXT NOT NULL,
                        strength NUMERIC NOT NULL, score NUMERIC DEFAULT 0, last_tested_at TIMESTAMP WITH TIME ZONE,
                        details TEXT, created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                        CONSTRAINT unique_level UNIQUE (symbol, level_price, timeframe, level_type) );
                """)
                cur.execute("SELECT 1 FROM information_schema.columns WHERE table_name='support_resistance_levels' AND column_name='score'")
                if not cur.fetchone():
                    cur.execute("ALTER TABLE support_resistance_levels ADD COLUMN score NUMERIC DEFAULT 0;")

                cur.execute("""
                    CREATE TABLE IF NOT EXISTS pending_recommendations (
                        id SERIAL PRIMARY KEY,
                        symbol TEXT NOT NULL UNIQUE,
                        original_entry_price DOUBLE PRECISION NOT NULL,
                        original_target_price DOUBLE PRECISION NOT NULL,
                        trigger_price DOUBLE PRECISION NOT NULL,
                        atr_at_creation DOUBLE PRECISION,
                        created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                        signal_details JSONB
                    );
                """)

            conn.commit()
            logger.info("âœ… [Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª] ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø¬Ù…ÙŠØ¹ Ø¬Ø¯Ø§ÙˆÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­ (Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ pending_recommendations).")
            return
        except Exception as e:
            logger.error(f"âŒ [Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª] Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ (Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}): {e}")
            if conn: conn.rollback()
            if attempt < retries - 1: time.sleep(delay)
            else: logger.critical("âŒ [Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª] ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø¹Ø¯ Ø¹Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø§Øª."); exit(1)

def check_db_connection() -> bool:
    global conn
    if conn is None or conn.closed != 0:
        logger.warning("[Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª] Ø§Ù„Ø§ØªØµØ§Ù„ Ù…ØºÙ„Ù‚ØŒ Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„...")
        init_db()
    try:
        if conn:
            with conn.cursor() as cur:
                 cur.execute("SELECT 1;")
            return True
        return False
    except (OperationalError, InterfaceError) as e:
        logger.error(f"âŒ [Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª] ÙÙ‚Ø¯Ø§Ù† Ø§Ù„Ø§ØªØµØ§Ù„: {e}. Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„...")
        try:
            init_db()
            return conn is not None and conn.closed == 0
        except Exception as retry_e:
            logger.error(f"âŒ [Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª] ÙØ´Ù„ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„: {retry_e}")
            return False
    return False

def log_and_notify(level: str, message: str, notification_type: str):
    log_methods = {'info': logger.info, 'warning': logger.warning, 'error': logger.error, 'critical': logger.critical}
    log_methods.get(level.lower(), logger.info)(message)
    if not check_db_connection() or not conn: return
    try:
        new_notification = {"timestamp": datetime.now().isoformat(), "type": notification_type, "message": message}
        with notifications_lock: notifications_cache.appendleft(new_notification)
        with conn.cursor() as cur:
            cur.execute("INSERT INTO notifications (type, message) VALUES (%s, %s);", (notification_type, message))
        conn.commit()
    except Exception as e:
        logger.error(f"âŒ [Notify DB] ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}");
        if conn: conn.rollback()

def fetch_sr_levels(symbol: str) -> Optional[List[Dict]]:
    if not check_db_connection() or not conn:
        logger.warning(f"âš ï¸ [{symbol}] Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¬Ù„Ø¨ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©ØŒ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ØªØ§Ø­.")
        return None
    try:
        with conn.cursor() as cur:
            cur.execute( "SELECT level_price, level_type, score FROM support_resistance_levels WHERE symbol = %s ORDER BY level_price ASC", (symbol,))
            levels = cur.fetchall()
            if not levels: return None
            for level in levels: level['score'] = float(level.get('score', 0))
            return levels
    except Exception as e:
        logger.error(f"âŒ [{symbol}] Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©: {e}")
        if conn: conn.rollback()
        return None

# ---------------------- Ø¯ÙˆØ§Ù„ Binance ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±) ----------------------
def get_validated_symbols(filename: str = 'crypto_list.txt') -> List[str]:
    logger.info(f"â„¹ï¸ [Ø§Ù„ØªØ­Ù‚Ù‚] Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø±Ù…ÙˆØ² Ù…Ù† '{filename}' ÙˆØ§Ù„ØªØ­Ù‚Ù‚ Ù…Ù†Ù‡Ø§ Ù…Ø¹ Binance...")
    if not client: logger.error("âŒ [Ø§Ù„ØªØ­Ù‚Ù‚] ÙƒØ§Ø¦Ù† Binance client ØºÙŠØ± Ù…Ù‡ÙŠØ£."); return []
    try:
        script_dir = os.path.dirname(__file__)
        file_path = os.path.join(script_dir, filename)
        with open(file_path, 'r', encoding='utf-8') as f:
            raw_symbols = {line.strip().upper() for line in f if line.strip() and not line.startswith('#')}
        formatted = {f"{s}USDT" if not s.endswith('USDT') else s for s in raw_symbols}
        exchange_info = client.get_exchange_info()
        active = {s['symbol'] for s in exchange_info['symbols'] if s.get('quoteAsset') == 'USDT' and s.get('status') == 'TRADING'}
        validated = sorted(list(formatted.intersection(active)))
        logger.info(f"âœ… [Ø§Ù„ØªØ­Ù‚Ù‚] Ø³ÙŠÙ‚ÙˆÙ… Ø§Ù„Ø¨ÙˆØª Ø¨Ù…Ø±Ø§Ù‚Ø¨Ø© {len(validated)} Ø¹Ù…Ù„Ø© Ù…Ø¹ØªÙ…Ø¯Ø©.")
        return validated
    except Exception as e:
        logger.error(f"âŒ [Ø§Ù„ØªØ­Ù‚Ù‚] Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ²: {e}", exc_info=True); return []

def fetch_historical_data(symbol: str, interval: str, days: int) -> Optional[pd.DataFrame]:
    if not client: return None
    try:
        # *** FIX: Use datetime.now(UTC) instead of deprecated datetime.utcnow() ***
        start_str = (datetime.now(UTC) - timedelta(days=days + 1)).strftime("%Y-%m-%d %H:%M:%S")
        klines = client.get_historical_klines(symbol, interval, start_str)
        if not klines: return None
        df = pd.DataFrame(klines, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_volume', 'trades', 'taker_buy_base', 'taker_buy_quote', 'ignore'])
        numeric_cols = ['open', 'high', 'low', 'close', 'volume']
        for col in numeric_cols: df[col] = pd.to_numeric(df[col], errors='coerce')
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('timestamp', inplace=True)
        for col in numeric_cols:
            if df[col].dtype == 'float64': df[col] = df[col].astype('float32')
        return df[numeric_cols].dropna()
    except BinanceAPIException as e:
        logger.warning(f"âš ï¸ [API Binance] Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª {symbol}: {e}")
        return None
    except Exception as e:
        logger.error(f"âŒ [Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª] Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„Ù€ {symbol}: {e}")
        return None

def calculate_all_features(df_15m: pd.DataFrame, df_4h: pd.DataFrame, btc_df: pd.DataFrame) -> Optional[pd.DataFrame]:
    df_calc = df_15m.copy()
    high_low = df_calc['high'] - df_calc['low']; high_close = (df_calc['high'] - df_calc['close'].shift()).abs(); low_close = (df_calc['low'] - df_calc['close'].shift()).abs()
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    df_calc['atr'] = tr.ewm(span=ATR_PERIOD, adjust=False).mean()
    up_move = df_calc['high'].diff(); down_move = -df_calc['low'].diff()
    plus_dm = pd.Series(np.where((up_move > down_move) & (up_move > 0), up_move, 0.0), index=df_calc.index)
    minus_dm = pd.Series(np.where((down_move > up_move) & (down_move > 0), down_move, 0.0), index=df_calc.index)
    plus_di = 100 * plus_dm.ewm(span=ADX_PERIOD, adjust=False).mean() / df_calc['atr']
    minus_di = 100 * minus_dm.ewm(span=ADX_PERIOD, adjust=False).mean() / df_calc['atr']
    dx = 100 * (abs(plus_di - minus_di) / (plus_di + minus_di).replace(0, 1e-9))
    df_calc['adx'] = dx.ewm(span=ADX_PERIOD, adjust=False).mean()
    delta = df_calc['close'].diff()
    gain = delta.clip(lower=0).ewm(com=RSI_PERIOD - 1, adjust=False).mean(); loss = -delta.clip(upper=0).ewm(com=RSI_PERIOD - 1, adjust=False).mean()
    df_calc['rsi'] = 100 - (100 / (1 + (gain / loss.replace(0, 1e-9))))
    ema_fast_macd = df_calc['close'].ewm(span=MACD_FAST, adjust=False).mean(); ema_slow_macd = df_calc['close'].ewm(span=MACD_SLOW, adjust=False).mean()
    macd_line = ema_fast_macd - ema_slow_macd; signal_line = macd_line.ewm(span=MACD_SIGNAL, adjust=False).mean()
    df_calc['macd_hist'] = macd_line - signal_line
    df_calc['macd_cross'] = 0
    df_calc.loc[(df_calc['macd_hist'].shift(1) < 0) & (df_calc['macd_hist'] >= 0), 'macd_cross'] = 1
    df_calc.loc[(df_calc['macd_hist'].shift(1) > 0) & (df_calc['macd_hist'] <= 0), 'macd_cross'] = -1
    sma = df_calc['close'].rolling(window=BBANDS_PERIOD).mean(); std_dev = df_calc['close'].rolling(window=BBANDS_PERIOD).std()
    upper_band = sma + (std_dev * 2); lower_band = sma - (std_dev * 2)
    df_calc['bb_width'] = (upper_band - lower_band) / (sma + 1e-9)
    rsi_stoch = df_calc['rsi']; min_rsi = rsi_stoch.rolling(window=STOCH_RSI_PERIOD).min(); max_rsi = rsi_stoch.rolling(window=STOCH_RSI_PERIOD).max()
    stoch_rsi_val = (rsi_stoch - min_rsi) / (max_rsi - min_rsi).replace(0, 1e-9)
    df_calc['stoch_rsi_k'] = stoch_rsi_val.rolling(window=STOCH_K).mean() * 100
    df_calc['stoch_rsi_d'] = df_calc['stoch_rsi_k'].rolling(window=STOCH_D).mean()
    df_calc['relative_volume'] = df_calc['volume'] / (df_calc['volume'].rolling(window=REL_VOL_PERIOD, min_periods=1).mean() + 1e-9)
    df_calc['market_condition'] = 0
    df_calc.loc[(df_calc['rsi'] > 70) | (df_calc['stoch_rsi_k'] > 80), 'market_condition'] = 1
    df_calc.loc[(df_calc['rsi'] < 30) | (df_calc['stoch_rsi_k'] < 20), 'market_condition'] = -1
    ema_fast_trend = df_calc['close'].ewm(span=EMA_FAST_PERIOD, adjust=False).mean(); ema_slow_trend = df_calc['close'].ewm(span=EMA_SLOW_PERIOD, adjust=False).mean()
    df_calc['price_vs_ema50'] = (df_calc['close'] / ema_fast_trend) - 1
    df_calc['price_vs_ema200'] = (df_calc['close'] / ema_slow_trend) - 1
    df_calc['returns'] = df_calc['close'].pct_change()
    merged_df = pd.merge(df_calc, btc_df[['btc_returns']], left_index=True, right_index=True, how='left').fillna(0)
    df_calc['btc_correlation'] = merged_df['returns'].rolling(window=BTC_CORR_PERIOD).corr(merged_df['btc_returns'])
    df_calc['hour_of_day'] = df_calc.index.hour
    df_calc = calculate_candlestick_patterns(df_calc)
    delta_4h = df_4h['close'].diff()
    gain_4h = delta_4h.clip(lower=0).ewm(com=RSI_PERIOD - 1, adjust=False).mean(); loss_4h = -delta_4h.clip(upper=0).ewm(com=RSI_PERIOD - 1, adjust=False).mean()
    df_4h['rsi_4h'] = 100 - (100 / (1 + (gain_4h / loss_4h.replace(0, 1e-9))))
    ema_fast_4h = df_4h['close'].ewm(span=EMA_FAST_PERIOD, adjust=False).mean()
    df_4h['price_vs_ema50_4h'] = (df_4h['close'] / ema_fast_4h) - 1
    mtf_features = df_4h[['rsi_4h', 'price_vs_ema50_4h']]
    df_featured = df_calc.join(mtf_features)
    # *** FIX: Use .ffill() instead of deprecated .fillna(method='ffill') ***
    df_featured[['rsi_4h', 'price_vs_ema50_4h']] = df_featured[['rsi_4h', 'price_vs_ema50_4h']].ffill()
    return df_featured.dropna()

def calculate_candlestick_patterns(df: pd.DataFrame) -> pd.DataFrame:
    df_patterns = df.copy()
    op, hi, lo, cl = df_patterns['open'], df_patterns['high'], df_patterns['low'], df_patterns['close']
    body = abs(cl - op); candle_range = hi - lo; candle_range[candle_range == 0] = 1e-9
    upper_wick = hi - pd.concat([op, cl], axis=1).max(axis=1)
    lower_wick = pd.concat([op, cl], axis=1).min(axis=1) - lo
    df_patterns['candlestick_pattern'] = 0
    df_patterns.loc[(body / candle_range) < 0.05, 'candlestick_pattern'] = 3
    df_patterns.loc[(body > candle_range * 0.1) & (lower_wick >= body * 2) & (upper_wick < body), 'candlestick_pattern'] = 2
    df_patterns.loc[(body > candle_range * 0.1) & (upper_wick >= body * 2) & (lower_wick < body), 'candlestick_pattern'] = -2
    df_patterns.loc[(cl.shift(1) < op.shift(1)) & (cl > op) & (cl >= op.shift(1)) & (op <= cl.shift(1)) & (body > body.shift(1)), 'candlestick_pattern'] = 1
    df_patterns.loc[(cl.shift(1) > op.shift(1)) & (cl < op) & (op >= cl.shift(1)) & (cl <= op.shift(1)) & (body > body.shift(1)), 'candlestick_pattern'] = -1
    df_patterns.loc[(cl > op) & (body / candle_range > 0.95) & (upper_wick < body * 0.1) & (lower_wick < body * 0.1), 'candlestick_pattern'] = 4
    df_patterns.loc[(op > cl) & (body / candle_range > 0.95) & (upper_wick < body * 0.1) & (lower_wick < body * 0.1), 'candlestick_pattern'] = -4
    return df_patterns

def load_ml_model_bundle_from_folder(symbol: str) -> Optional[Dict[str, Any]]:
    model_name = f"{BASE_ML_MODEL_NAME}_{symbol}"
    model_dir = 'Mo'
    file_path = os.path.join(model_dir, f"{model_name}.pkl")
    if not os.path.isdir(model_dir):
        logger.warning(f"âš ï¸ [Ù†Ù…ÙˆØ°Ø¬ ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø©] Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ '{model_dir}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")
        return None
    if os.path.exists(file_path):
        try:
            with open(file_path, 'rb') as f:
                model_bundle = pickle.load(f)
            if 'model' in model_bundle and 'scaler' in model_bundle and 'feature_names' in model_bundle:
                return model_bundle
            else:
                logger.error(f"âŒ [Ù†Ù…ÙˆØ°Ø¬ ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø©] Ø­Ø²Ù…Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ø§Ù„Ù…Ù„Ù '{file_path}' ØºÙŠØ± Ù…ÙƒØªÙ…Ù„Ø©.")
                return None
        except Exception as e:
            logger.error(f"âŒ [Ù†Ù…ÙˆØ°Ø¬ ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø©] Ø®Ø·Ø£ Ø¹Ù†Ø¯ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ '{file_path}': {e}", exc_info=True)
            return None
    else:
        return None

# ---------------------- Ø¯ÙˆØ§Ù„ WebSocket ÙˆØ§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© (Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±) ----------------------
def handle_ticker_message(msg: Union[List[Dict[str, Any]], Dict[str, Any]]) -> None:
    global open_signals_cache, current_prices
    try:
        data = msg.get('data', msg) if isinstance(msg, dict) else msg
        if not isinstance(data, list): data = [data]
        for item in data:
            symbol = item.get('s')
            if not symbol: continue
            price = float(item.get('c', 0))
            if price == 0: continue
            with prices_lock: current_prices[symbol] = price
            signal_to_process, status, closing_price = None, None, None
            with signal_cache_lock:
                if symbol in open_signals_cache:
                    signal = open_signals_cache[symbol]
                    target_price = signal.get('target_price')
                    stop_loss_price = signal.get('stop_loss')
                    if not all(isinstance(p, (int, float)) for p in [price, target_price, stop_loss_price]): continue
                    if price >= target_price: status, closing_price, signal_to_process = 'target_hit', target_price, signal
                    elif price <= stop_loss_price: status, closing_price, signal_to_process = 'stop_loss_hit', stop_loss_price, signal
            if signal_to_process and status:
                logger.info(f"âš¡ [Ø§Ù„Ù…ØªØªØ¨Ø¹ Ø§Ù„ÙÙˆØ±ÙŠ] ØªÙ… ØªÙØ¹ÙŠÙ„ Ø­Ø¯Ø« '{status}' Ù„Ù„Ø¹Ù…Ù„Ø© {symbol} Ø¹Ù†Ø¯ Ø³Ø¹Ø± {price:.8f}")
                Thread(target=close_signal, args=(signal_to_process, status, closing_price, "auto")).start()
    except Exception as e:
        logger.error(f"âŒ [Ù…ØªØªØ¨Ø¹ WebSocket] Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø³Ø¹Ø± Ø§Ù„ÙÙˆØ±ÙŠØ©: {e}", exc_info=True)

def run_websocket_manager() -> None:
    logger.info("â„¹ï¸ [WebSocket] Ø¨Ø¯Ø¡ Ù…Ø¯ÙŠØ± WebSocket...")
    twm = ThreadedWebsocketManager(api_key=API_KEY, api_secret=API_SECRET)
    twm.start()
    twm.start_ticker_socket(callback=handle_ticker_message)
    logger.info("âœ… [WebSocket] ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ ÙˆØ§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ Ø¨Ù†Ø¬Ø§Ø­.")
    twm.join()

class TradingStrategy:
    def __init__(self, symbol: str):
        self.symbol = symbol
        model_bundle = load_ml_model_bundle_from_folder(symbol)
        self.ml_model, self.scaler, self.feature_names = (model_bundle.get('model'), model_bundle.get('scaler'), model_bundle.get('feature_names')) if model_bundle else (None, None, None)

    def get_features(self, df_15m: pd.DataFrame, df_4h: pd.DataFrame, btc_df: pd.DataFrame) -> Optional[pd.DataFrame]:
        return calculate_all_features(df_15m, df_4h, btc_df)

    def generate_signal(self, df_processed: pd.DataFrame) -> Optional[Dict[str, Any]]:
        if not all([self.ml_model, self.scaler, self.feature_names]):
            return None
        last_row = df_processed.iloc[-1]
        try:
            missing_features = [f for f in self.feature_names if f not in df_processed.columns]
            if missing_features: return None
            features_df = pd.DataFrame([last_row], columns=df_processed.columns)[self.feature_names]
            if features_df.isnull().values.any(): return None
            features_scaled = self.scaler.transform(features_df)
            features_scaled_df = pd.DataFrame(features_scaled, columns=self.feature_names)
            prediction = self.ml_model.predict(features_scaled_df)[0]
            prediction_proba = self.ml_model.predict_proba(features_scaled_df)[0]
            prob_for_class_1 = 0
            try:
                class_1_index = list(self.ml_model.classes_).index(1)
                prob_for_class_1 = prediction_proba[class_1_index]
            except ValueError:
                return None
            if prediction == 1 and prob_for_class_1 >= MODEL_CONFIDENCE_THRESHOLD:
                logger.info(f"âœ… [Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¥Ø´Ø§Ø±Ø© Ø£ÙˆÙ„ÙŠØ©] {self.symbol}: ØªÙ†Ø¨Ø£ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ 'Ø´Ø±Ø§Ø¡' Ø¨Ø«Ù‚Ø© {prob_for_class_1:.2%}.")
                return { 'symbol': self.symbol, 'strategy_name': BASE_ML_MODEL_NAME,
                    'signal_details': {'ML_Probability_Buy': f"{prob_for_class_1:.2%}"} }
            else:
                return None
        except Exception as e:
            logger.warning(f"âš ï¸ [ØªÙˆÙ„ÙŠØ¯ Ø¥Ø´Ø§Ø±Ø©] {self.symbol}: Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙˆÙ„ÙŠØ¯: {e}", exc_info=True)
            return None

# ---------------------- Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª ÙˆØ§Ù„Ø¥Ø¯Ø§Ø±Ø© (Ù…ÙØ¹Ø¯Ù‘ÙÙ„Ø©) ----------------------
def send_telegram_message(target_chat_id: str, text: str):
    if not TELEGRAM_TOKEN or not target_chat_id: return
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {'chat_id': str(target_chat_id), 'text': text, 'parse_mode': 'Markdown'}
    try: requests.post(url, json=payload, timeout=20).raise_for_status()
    except Exception as e: logger.error(f"âŒ [Telegram] ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø©: {e}")

def send_new_signal_alert(signal_data: Dict[str, Any]) -> None:
    safe_symbol = signal_data['symbol'].replace('_', '\\_')
    entry = signal_data['entry_price']
    sl = signal_data['stop_loss']
    signal_details = signal_data.get('signal_details', {})

    if 'TP1' in signal_details and 'TP2' in signal_details:
        target1 = signal_details['TP1']
        target2 = signal_details['TP2']
        profit_pct1 = ((target1 / entry) - 1) * 100 if entry > 0 else 0
        profit_pct2 = ((target2 / entry) - 1) * 100 if entry > 0 else 0
        target_text = (f"ğŸ¯ *Ø§Ù„Ù‡Ø¯Ù 1:* `${target1:,.8g}` (Ø±Ø¨Ø­ `{profit_pct1:+.2f}%`)\n"
                       f"ğŸ¯ *Ø§Ù„Ù‡Ø¯Ù 2:* `${target2:,.8g}` (Ø±Ø¨Ø­ `{profit_pct2:+.2f}%`)")
    else:
        target = signal_data['target_price']
        profit_pct = ((target / entry) - 1) * 100 if entry > 0 else 0
        target_text = f"ğŸ¯ *Ø§Ù„Ù‡Ø¯Ù:* `${target:,.8g}` (Ø±Ø¨Ø­ Ù…ØªÙˆÙ‚Ø¹ `{profit_pct:+.2f}%`)"

    rr_ratio_info = signal_details.get('risk_reward_ratio', 'N/A')
    volume_info = signal_details.get('last_15m_volume_usdt', 'N/A')
    strategy_name = signal_data.get('strategy_name', BASE_ML_MODEL_NAME)

    message = (f"ğŸ’¡ *Ø¥Ø´Ø§Ø±Ø© ØªØ¯Ø§ÙˆÙ„ Ø¬Ø¯ÙŠØ¯Ø© ({strategy_name})* ğŸ’¡\n\n"
               f"ğŸª™ *Ø§Ù„Ø¹Ù…Ù„Ø©:* `{safe_symbol}`\n"
               f"ğŸ“ˆ *Ø§Ù„Ù†ÙˆØ¹:* Ø´Ø±Ø§Ø¡ (LONG)\n\n"
               f"â¬…ï¸ *Ø³Ø¹Ø± Ø§Ù„Ø¯Ø®ÙˆÙ„:* `${entry:,.8g}`\n"
               f"{target_text}\n"
               f"ğŸ›‘ *ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©:* `${sl:,.8g}`\n\n"
               f"ğŸ’§ *Ø³ÙŠÙˆÙ„Ø© Ø¢Ø®Ø± 15Ø¯:* `{volume_info}`\n"
               f"ğŸ” *Ø«Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:* {signal_details.get('ML_Probability_Buy', 'N/A')}\n"
               f"âš–ï¸ *Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©/Ø§Ù„Ø¹Ø§Ø¦Ø¯:* `{rr_ratio_info}`\n"
               f"ğŸ› ï¸ *Ø£Ø³Ø§Ø³ Ø§Ù„Ù‡Ø¯Ù/Ø§Ù„ÙˆÙ‚Ù:* {signal_details.get('sr_info', 'ATR Default')}")

    reply_markup = {"inline_keyboard": [[{"text": "ğŸ“Š ÙØªØ­ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…", "url": WEBHOOK_URL or '#'}]]}
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {'chat_id': str(CHAT_ID), 'text': message, 'parse_mode': 'Markdown', 'reply_markup': json.dumps(reply_markup)}
    try: requests.post(url, json=payload, timeout=20).raise_for_status()
    except Exception as e: logger.error(f"âŒ [Telegram] ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ ØªÙ†Ø¨ÙŠÙ‡ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©: {e}")
    log_and_notify('info', f"Ø¥Ø´Ø§Ø±Ø© Ø¬Ø¯ÙŠØ¯Ø©: {signal_data['symbol']} Ø¨Ø³Ø¹Ø± Ø¯Ø®ÙˆÙ„ ${entry:,.8g}", "NEW_SIGNAL")

def insert_signal_into_db(signal: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    if not check_db_connection() or not conn: return None
    try:
        entry, target, sl = float(signal['entry_price']), float(signal['target_price']), float(signal['stop_loss'])
        with conn.cursor() as cur:
            cur.execute(
                """INSERT INTO signals (symbol, entry_price, target_price, stop_loss, strategy_name, signal_details)
                   VALUES (%s, %s, %s, %s, %s, %s) RETURNING id;""",
                (signal['symbol'], entry, target, sl, signal.get('strategy_name'), json.dumps(signal.get('signal_details', {})))
            )
            signal['id'] = cur.fetchone()['id']
        conn.commit()
        logger.info(f"âœ… [Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª] ØªÙ… Ø¥Ø¯Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù„Ù€ {signal['symbol']} (ID: {signal['id']}).")
        return signal
    except Exception as e:
        logger.error(f"âŒ [Ø¥Ø¯Ø±Ø§Ø¬ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª] Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¯Ø±Ø§Ø¬ Ø¥Ø´Ø§Ø±Ø© {signal['symbol']}: {e}", exc_info=True)
        if conn: conn.rollback()
        return None

def close_signal(signal: Dict, status: str, closing_price: float, closed_by: str):
    symbol = signal['symbol']
    with signal_cache_lock:
        if symbol not in open_signals_cache or open_signals_cache[symbol]['id'] != signal['id']: return
    if not check_db_connection() or not conn: return
    try:
        db_closing_price = float(closing_price)
        db_profit_pct = float(((db_closing_price / signal['entry_price']) - 1) * 100)
        with conn.cursor() as update_cur:
            update_cur.execute(
                "UPDATE signals SET status = %s, closing_price = %s, closed_at = NOW(), profit_percentage = %s WHERE id = %s;",
                (status, db_closing_price, db_profit_pct, signal['id'])
            )
        conn.commit()
        with signal_cache_lock: del open_signals_cache[symbol]
        status_map = {'target_hit': 'âœ… ØªØ­Ù‚Ù‚ Ø§Ù„Ù‡Ø¯Ù', 'stop_loss_hit': 'ğŸ›‘ Ø¶Ø±Ø¨ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©', 'manual_close': 'ğŸ–ï¸ Ø£ÙØºÙ„Ù‚Øª ÙŠØ¯ÙˆÙŠØ§Ù‹'}
        status_message = status_map.get(status, status.replace('_', ' ').title())
        safe_symbol = signal['symbol'].replace('_', '\\_')
        alert_msg_tg = f"*{status_message}*\n`{safe_symbol}` | *Ø§Ù„Ø±Ø¨Ø­:* `{db_profit_pct:+.2f}%`"
        send_telegram_message(CHAT_ID, alert_msg_tg)
        alert_msg_db = f"{status_message}: {signal['symbol']} | Ø§Ù„Ø±Ø¨Ø­: {db_profit_pct:+.2f}%"
        log_and_notify('info', alert_msg_db, 'CLOSE_SIGNAL')
    except Exception as e:
        logger.error(f"âŒ [Ø¥ØºÙ„Ø§Ù‚ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª] Ø®Ø·Ø£ ÙØ§Ø¯Ø­ Ø£Ø«Ù†Ø§Ø¡ Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© {signal['id']} Ù„Ù€ {signal['symbol']}: {e}", exc_info=True)
        if conn: conn.rollback()

def load_open_signals_to_cache():
    if not check_db_connection() or not conn: return
    logger.info("â„¹ï¸ [ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©] Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø© Ø³Ø§Ø¨Ù‚Ø§Ù‹...")
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT * FROM signals WHERE status = 'open';")
            open_signals = cur.fetchall()
            with signal_cache_lock:
                open_signals_cache.clear()
                for signal in open_signals: open_signals_cache[signal['symbol']] = dict(signal)
            logger.info(f"âœ… [ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©] ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(open_signals)} Ø¥Ø´Ø§Ø±Ø© Ù…ÙØªÙˆØ­Ø©.")
    except Exception as e: logger.error(f"âŒ [ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©] ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø©: {e}")

def load_notifications_to_cache():
    if not check_db_connection() or not conn: return
    logger.info("â„¹ï¸ [ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©] Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø¢Ø®Ø± Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª...")
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT * FROM notifications ORDER BY timestamp DESC LIMIT 50;")
            recent = cur.fetchall()
            with notifications_lock:
                notifications_cache.clear()
                for n in reversed(recent):
                    if 'timestamp' in n and isinstance(n['timestamp'], datetime):
                        n['timestamp'] = n['timestamp'].isoformat()
                    notifications_cache.appendleft(dict(n))
            logger.info(f"âœ… [ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©] ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(notifications_cache)} ØªÙ†Ø¨ÙŠÙ‡.")
    except Exception as e: logger.error(f"âŒ [ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©] ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª: {e}")

def save_pending_recommendation(signal: Dict[str, Any]) -> None:
    if not check_db_connection() or not conn:
        logger.warning(f"âš ï¸ [{signal['symbol']}] Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø­ÙØ¸ ØªÙˆØµÙŠØ© Ù‚ÙŠØ¯ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±ØŒ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ØªØ§Ø­.")
        return

    try:
        # *** FIX: Convert all potential numpy types to standard Python floats ***
        original_entry = float(signal['entry_price'])
        original_target = float(signal['target_price'])
        trigger_price_val = float(signal['stop_loss'])
        atr_value = signal['signal_details'].get('atr_value')
        atr_value_float = float(atr_value) if atr_value is not None else None

        with conn.cursor() as cur:
            cur.execute(
                """
                INSERT INTO pending_recommendations (
                    symbol, original_entry_price, original_target_price, trigger_price,
                    atr_at_creation, signal_details
                ) VALUES (%s, %s, %s, %s, %s, %s)
                ON CONFLICT (symbol) DO UPDATE SET
                    original_entry_price = EXCLUDED.original_entry_price,
                    original_target_price = EXCLUDED.original_target_price,
                    trigger_price = EXCLUDED.trigger_price,
                    atr_at_creation = EXCLUDED.atr_at_creation,
                    signal_details = EXCLUDED.signal_details,
                    created_at = NOW();
                """,
                (
                    signal['symbol'],
                    original_entry,
                    original_target,
                    trigger_price_val,
                    atr_value_float,
                    json.dumps(signal.get('signal_details', {}))
                )
            )
        conn.commit()
        logger.info(f"ğŸ’¾ [{signal['symbol']}] ØªÙ… Ø­ÙØ¸/ØªØ­Ø¯ÙŠØ« ØªÙˆØµÙŠØ© Ù‚ÙŠØ¯ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ù†Ø¬Ø§Ø­.")
        log_and_notify('info', f"ØªÙˆØµÙŠØ© Ù‚ÙŠØ¯ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù€ {signal['symbol']}", "PENDING_SIGNAL")
    except Exception as e:
        logger.error(f"âŒ [Ø­ÙØ¸ ØªÙˆØµÙŠØ© Ù…Ø¹Ù„Ù‚Ø©] Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ ØªÙˆØµÙŠØ© {signal['symbol']}: {e}", exc_info=True)
        if conn: conn.rollback()

# ---------------------- Ø­Ù„Ù‚Ø© Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙˆØ§Ù„Ø¬Ø¯ÙŠØ¯Ø© ----------------------
def get_btc_trend() -> Dict[str, Any]:
    if not client: return {"status": "error", "message": "Binance client not initialized", "is_uptrend": False}
    try:
        klines = client.get_klines(symbol=BTC_SYMBOL, interval=BTC_TREND_TIMEFRAME, limit=BTC_TREND_EMA_PERIOD * 2)
        df = pd.DataFrame(klines, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_volume', 'trades', 'taker_buy_base', 'taker_buy_quote', 'ignore'])
        df['close'] = pd.to_numeric(df['close'])
        ema = df['close'].ewm(span=BTC_TREND_EMA_PERIOD, adjust=False).mean().iloc[-1]
        current_price = df['close'].iloc[-1]
        status, message = ("Uptrend", f"ØµØ§Ø¹Ø¯ (Ø§Ù„Ø³Ø¹Ø± ÙÙˆÙ‚ EMA {BTC_TREND_EMA_PERIOD})") if current_price > ema else ("Downtrend", f"Ù‡Ø§Ø¨Ø· (Ø§Ù„Ø³Ø¹Ø± ØªØ­Øª EMA {BTC_TREND_EMA_PERIOD})")
        return {"status": status, "message": message, "is_uptrend": (status == "Uptrend")}
    except Exception as e:
        logger.error(f"âŒ [ÙÙ„ØªØ± BTC] ÙØ´Ù„ ØªØ­Ø¯ÙŠØ¯ Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ†: {e}")
        return {"status": "Error", "message": str(e), "is_uptrend": False}

def main_loop():
    logger.info("[Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©] Ø§Ù†ØªØ¸Ø§Ø± Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©...")
    time.sleep(15)
    if not validated_symbols_to_scan:
        log_and_notify("critical", "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø±Ù…ÙˆØ² Ù…Ø¹ØªÙ…Ø¯Ø© Ù„Ù„Ù…Ø³Ø­. Ù„Ù† ÙŠØ³ØªÙ…Ø± Ø§Ù„Ø¨ÙˆØª ÙÙŠ Ø§Ù„Ø¹Ù…Ù„.", "SYSTEM")
        return
    log_and_notify("info", f"Ø¨Ø¯Ø¡ Ø­Ù„Ù‚Ø© Ø§Ù„Ù…Ø³Ø­ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (Ù„ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ù…Ø¹Ù„Ù‚Ø©) Ù„Ù€ {len(validated_symbols_to_scan)} Ø¹Ù…Ù„Ø©.", "SYSTEM")

    while True:
        try:
            if USE_BTC_TREND_FILTER:
                trend_data = get_btc_trend()
                if not trend_data.get("is_uptrend"):
                    logger.warning(f"âš ï¸ [Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø³Ø­] ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¥Ø´Ø§Ø±Ø§Øª Ø´Ø±Ø§Ø¡ Ø¨Ø³Ø¨Ø¨ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ù‡Ø§Ø¨Ø· Ù„Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ†. {trend_data.get('message')}")
                    time.sleep(300); continue

            btc_data_cycle = fetch_historical_data(BTC_SYMBOL, SIGNAL_GENERATION_TIMEFRAME, DATA_FETCH_LOOKBACK_DAYS)
            if btc_data_cycle is None:
                logger.error("âŒ ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª BTC. Ø³ÙŠØªÙ… ØªØ®Ø·ÙŠ Ø¯ÙˆØ±Ø© Ø§Ù„Ù…Ø³Ø­ Ù‡Ø°Ù‡.")
                time.sleep(120); continue
            btc_data_cycle['btc_returns'] = btc_data_cycle['close'].pct_change()

            for symbol in validated_symbols_to_scan:
                with signal_cache_lock:
                    if symbol in open_signals_cache: continue

                try:
                    df_15m = fetch_historical_data(symbol, SIGNAL_GENERATION_TIMEFRAME, DATA_FETCH_LOOKBACK_DAYS)
                    df_4h = fetch_historical_data(symbol, HIGHER_TIMEFRAME, DATA_FETCH_LOOKBACK_DAYS)
                    if df_15m is None or df_15m.empty or df_4h is None or df_4h.empty: continue

                    strategy = TradingStrategy(symbol)
                    df_features = strategy.get_features(df_15m, df_4h, btc_data_cycle)
                    if df_features is None or df_features.empty:
                        del df_15m, df_4h, strategy; gc.collect(); continue

                    potential_signal = strategy.generate_signal(df_features)
                    if potential_signal:
                        last_candle = df_features.iloc[-1]
                        last_15m_volume_usdt = last_candle['volume'] * last_candle['close']
                        if last_15m_volume_usdt < MINIMUM_15M_VOLUME_USDT:
                            continue

                        potential_signal['signal_details']['last_15m_volume_usdt'] = f"${last_15m_volume_usdt:,.0f}"
                        with prices_lock: current_price = current_prices.get(symbol)
                        if not current_price: continue

                        potential_signal['entry_price'] = current_price
                        atr_value = df_features['atr'].iloc[-1]
                        potential_signal['signal_details']['atr_value'] = atr_value

                        stop_loss = current_price - (atr_value * ATR_SL_MULTIPLIER)
                        target_price = current_price + (atr_value * ATR_TP_MULTIPLIER)
                        sr_info = "ATR Default"

                        if USE_SR_LEVELS:
                            all_levels = fetch_sr_levels(symbol)
                            if all_levels:
                                strong_levels = [lvl for lvl in all_levels if lvl.get('score', 0) >= MINIMUM_SR_SCORE]
                                strong_supports = [lvl for lvl in strong_levels if 'support' in lvl.get('level_type', '') and lvl['level_price'] < current_price]
                                strong_resistances = [lvl for lvl in strong_levels if 'resistance' in lvl.get('level_type', '') and lvl['level_price'] > current_price]
                                if strong_supports:
                                    closest_strong_support = max(strong_supports, key=lambda x: x['level_price'])
                                    stop_loss = closest_strong_support['level_price'] * 0.998
                                    sr_info = f"Strong S/R (Score > {MINIMUM_SR_SCORE})"
                                if strong_resistances:
                                    closest_strong_resistance = min(strong_resistances, key=lambda x: x['level_price'])
                                    target_price = closest_strong_resistance['level_price'] * 0.998
                                    sr_info = f"Strong S/R (Score > {MINIMUM_SR_SCORE})"

                        if target_price <= current_price or stop_loss >= current_price: continue
                        potential_profit_pct = ((target_price / current_price) - 1) * 100
                        if potential_profit_pct < MINIMUM_PROFIT_PERCENTAGE: continue
                        potential_risk = current_price - stop_loss
                        if potential_risk <= 0: continue
                        risk_reward_ratio = (target_price - current_price) / potential_risk
                        if risk_reward_ratio < MINIMUM_RISK_REWARD_RATIO: continue

                        potential_signal['stop_loss'] = stop_loss
                        potential_signal['target_price'] = target_price
                        potential_signal['signal_details']['sr_info'] = sr_info
                        potential_signal['signal_details']['risk_reward_ratio'] = f"{risk_reward_ratio:.2f} : 1"

                        save_pending_recommendation(potential_signal)

                    del df_15m, df_4h, df_features, strategy
                except Exception as e:
                    logger.error(f"âŒ [Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©] Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¹Ù…Ù„Ø© {symbol}: {e}", exc_info=True)

            del btc_data_cycle
            gc.collect()
            time.sleep(120)

        except (KeyboardInterrupt, SystemExit): break
        except Exception as main_err:
            log_and_notify("error", f"Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: {main_err}", "SYSTEM")
            time.sleep(120)

def monitor_pending_loop():
    logger.info("â³ [Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„ØªÙˆØµÙŠØ§Øª] Ø¨Ø¯Ø¡ Ø­Ù„Ù‚Ø© Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©...")
    time.sleep(25)

    while True:
        try:
            if not check_db_connection() or not conn:
                logger.warning("âš ï¸ [Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„ØªÙˆØµÙŠØ§Øª] Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ Ø³ÙŠØªÙ… ØªØ®Ø·ÙŠ Ø§Ù„Ø¯ÙˆØ±Ø©.")
                time.sleep(30); continue

            with signal_cache_lock:
                if len(open_signals_cache) >= MAX_OPEN_TRADES:
                    time.sleep(10); continue

            pending_recs = []
            with conn.cursor() as cur:
                cur.execute("SELECT * FROM pending_recommendations;")
                pending_recs = cur.fetchall()

            if not pending_recs:
                time.sleep(10); continue

            for rec in pending_recs:
                symbol = rec['symbol']
                trigger_price = rec['trigger_price']
                with prices_lock: current_price = current_prices.get(symbol)
                if not current_price: continue

                if current_price <= trigger_price:
                    logger.info(f"ğŸ’¥ [{symbol}] ØªÙ… ØªÙØ¹ÙŠÙ„ ØªÙˆØµÙŠØ© Ù…Ø¹Ù„Ù‚Ø©! Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ ({current_price}) ÙˆØµÙ„ Ù„Ø³Ø¹Ø± Ø§Ù„ØªÙØ¹ÙŠÙ„ ({trigger_price}).")

                    with signal_cache_lock:
                        if len(open_signals_cache) >= MAX_OPEN_TRADES:
                            logger.warning(f"âš ï¸ [{symbol}] ØªÙ… ØªÙØ¹ÙŠÙ„ Ø§Ù„ØªÙˆØµÙŠØ© ÙˆÙ„ÙƒÙ† Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ù…Ø§ÙƒÙ† Ù…ØªØ§Ø­Ø© Ù„Ù„ØµÙÙ‚Ø§Øª. Ø³ÙŠØªÙ… Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹.")
                            continue

                    new_entry_price = trigger_price
                    tp1 = rec['original_entry_price']
                    tp2 = rec['original_target_price']
                    atr_at_creation = rec.get('atr_at_creation')

                    new_stop_loss, sl_info = 0, "ATR Fallback"
                    strong_supports = []
                    if USE_SR_LEVELS:
                        all_levels = fetch_sr_levels(symbol)
                        if all_levels:
                            strong_lvls = [lvl for lvl in all_levels if lvl.get('score', 0) >= MINIMUM_SR_SCORE]
                            strong_supports = [lvl for lvl in strong_lvls if 'support' in lvl.get('level_type','') and lvl['level_price'] < new_entry_price]
                    if strong_supports:
                        closest_support = max(strong_supports, key=lambda x: x['level_price'])
                        new_stop_loss = closest_support['level_price'] * 0.998
                        sl_info = f"Strong Support (Score > {MINIMUM_SR_SCORE})"
                    elif atr_at_creation:
                        new_stop_loss = new_entry_price - (atr_at_creation * ATR_SL_MULTIPLIER)
                    else:
                        new_stop_loss = new_entry_price * 0.98
                        sl_info = "Failsafe 2%"

                    if tp2 <= new_entry_price or new_stop_loss >= new_entry_price:
                        logger.error(f"âŒ [{symbol}] ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ØªÙˆØµÙŠØ© Ø§Ù„Ù…ÙØ¹Ù„Ø©. Ø§Ù„Ø£Ù‡Ø¯Ø§Ù Ø£Ùˆ Ø§Ù„ÙˆÙ‚Ù ØºÙŠØ± Ù…Ù†Ø·Ù‚ÙŠØ©. Ø³ÙŠØªÙ… Ø­Ø°ÙÙ‡Ø§.")
                        with conn.cursor() as del_cur:
                            del_cur.execute("DELETE FROM pending_recommendations WHERE id = %s;", (rec['id'],))
                        conn.commit(); continue

                    new_signal = { 'symbol': symbol, 'entry_price': new_entry_price, 'target_price': tp2,
                        'stop_loss': new_stop_loss, 'strategy_name': "Pending-Triggered",
                        'signal_details': { **json.loads(rec.get('signal_details', '{}')),
                            'TP1': tp1, 'TP2': tp2,
                            'trigger_event': 'SL of pending recommendation hit', 'sr_info': sl_info } }

                    saved_signal = insert_signal_into_db(new_signal)
                    if saved_signal:
                        with signal_cache_lock: open_signals_cache[saved_signal['symbol']] = saved_signal
                        send_new_signal_alert(saved_signal)
                        with conn.cursor() as del_cur:
                            del_cur.execute("DELETE FROM pending_recommendations WHERE id = %s;", (rec['id'],))
                        conn.commit()
                        logger.info(f"âœ… [{symbol}] ØªÙ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØµÙŠØ© Ø§Ù„Ù…Ø¹Ù„Ù‚Ø© Ø¥Ù„Ù‰ ØµÙÙ‚Ø© Ù†Ø´Ø·Ø© ÙˆØ­Ø°ÙÙ‡Ø§ Ù…Ù† Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±.")

        except (OperationalError, InterfaceError) as db_err:
            logger.error(f"âŒ [Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„ØªÙˆØµÙŠØ§Øª] Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {db_err}. Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§ØªØµØ§Ù„...")
            check_db_connection(); time.sleep(30)
        except Exception as e:
            logger.error(f"âŒ [Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„ØªÙˆØµÙŠØ§Øª] Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø­Ù„Ù‚Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©: {e}", exc_info=True)
            time.sleep(60)

        time.sleep(5)

# ---------------------- ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª Flask (Ù…ÙØ¹Ø¯Ù‘ÙÙ„Ø©) ----------------------
app = Flask(__name__)
CORS(app)

def get_fear_and_greed_index() -> Dict[str, Any]:
    classification_translation = {"Extreme Fear": "Ø®ÙˆÙ Ø´Ø¯ÙŠØ¯", "Fear": "Ø®ÙˆÙ", "Neutral": "Ù…Ø­Ø§ÙŠØ¯", "Greed": "Ø·Ù…Ø¹", "Extreme Greed": "Ø·Ù…Ø¹ Ø´Ø¯ÙŠØ¯", "Error": "Ø®Ø·Ø£"}
    try:
        response = requests.get("https://api.alternative.me/fng/?limit=1", timeout=10)
        response.raise_for_status()
        data = response.json()['data'][0]
        original = data['value_classification']
        return {"value": int(data['value']), "classification": classification_translation.get(original, original)}
    except Exception as e:
        logger.error(f"âŒ [Ù…Ø¤Ø´Ø± Ø§Ù„Ø®ÙˆÙ ÙˆØ§Ù„Ø·Ù…Ø¹] ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ù€ API: {e}")
        return {"value": -1, "classification": classification_translation["Error"]}

@app.route('/')
def home():
    try:
        script_dir = os.path.dirname(__file__)
        file_path = os.path.join(script_dir, 'index.html')
        if not os.path.exists(file_path):
             return "<h1>Ù…Ù„Ù Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ… (index.html) ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.</h1><p>ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù ÙÙŠ Ù†ÙØ³ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª.</p>", 404
        with open(file_path, 'r', encoding='utf-8') as f: return render_template_string(f.read())
    except FileNotFoundError: return "<h1>Ù…Ù„Ù Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ… (index.html) ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.</h1>", 404
    except Exception as e: return f"<h1>Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…:</h1><p>{e}</p>", 500

@app.route('/api/market_status')
def get_market_status(): return jsonify({"btc_trend": get_btc_trend(), "fear_and_greed": get_fear_and_greed_index()})

@app.route('/api/stats')
def get_stats():
    if not check_db_connection() or not conn: return jsonify({"error": "ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"}), 500
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT status, profit_percentage FROM signals WHERE status != 'open';")
            closed = cur.fetchall()
        wins = sum(1 for s in closed if s.get('profit_percentage', 0) > 0)
        losses = len(closed) - wins
        total_closed = len(closed)
        win_rate = (wins / total_closed * 100) if total_closed > 0 else 0
        total_profit_percent = sum(s['profit_percentage'] for s in closed if s.get('profit_percentage') is not None)
        return jsonify({"win_rate": win_rate, "wins": wins, "losses": losses, "total_profit_percent": total_profit_percent, "total_closed_trades": total_closed})
    except Exception as e:
        logger.error(f"âŒ [API Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª] Ø®Ø·Ø£: {e}"); return jsonify({"error": "ØªØ¹Ø°Ø± Ø¬Ù„Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª"}), 500

@app.route('/api/signals')
def get_signals():
    if not check_db_connection() or not conn: return jsonify({"error": "ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"}), 500
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT * FROM signals ORDER BY CASE WHEN status = 'open' THEN 0 ELSE 1 END, id DESC;")
            all_signals = cur.fetchall()
        for s in all_signals:
            if s.get('closed_at') and isinstance(s['closed_at'], datetime):
                s['closed_at'] = s['closed_at'].isoformat()
            if s['status'] == 'open':
                with prices_lock: s['current_price'] = current_prices.get(s['symbol'])
        return jsonify(all_signals)
    except Exception as e:
        logger.error(f"âŒ [API Ø¥Ø´Ø§Ø±Ø§Øª] Ø®Ø·Ø£: {e}"); return jsonify({"error": "ØªØ¹Ø°Ø± Ø¬Ù„Ø¨ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª"}), 500

@app.route('/api/close/<int:signal_id>', methods=['POST'])
def manual_close_signal(signal_id):
    logger.info(f"â„¹ï¸ [API Ø¥ØºÙ„Ø§Ù‚] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø·Ù„Ø¨ Ø¥ØºÙ„Ø§Ù‚ ÙŠØ¯ÙˆÙŠ Ù„Ù„Ø¥Ø´Ø§Ø±Ø© ID: {signal_id}")
    signal_to_close = None
    with signal_cache_lock:
        for s in open_signals_cache.values():
            if s['id'] == signal_id: signal_to_close = s.copy(); break
    if not signal_to_close: return jsonify({"error": "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©."}), 404
    symbol_to_close = signal_to_close['symbol']
    with prices_lock: closing_price = current_prices.get(symbol_to_close)
    if not closing_price: return jsonify({"error": f"ØªØ¹Ø°Ø± Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ Ù„Ù€ {symbol_to_close}."}), 500
    Thread(target=close_signal, args=(signal_to_close, 'manual_close', closing_price, "manual")).start()
    return jsonify({"message": f"Ø¬Ø§Ø±ÙŠ Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© {signal_id} Ù„Ù€ {symbol_to_close}."})

@app.route('/api/notifications')
def get_notifications():
    with notifications_lock:
        notifications_list = []
        for n in list(notifications_cache):
            notif_copy = n.copy()
            if 'timestamp' in notif_copy and isinstance(notif_copy['timestamp'], (datetime, str)):
                 notif_copy['timestamp'] = pd.to_datetime(notif_copy['timestamp']).isoformat()
            notifications_list.append(notif_copy)
        return jsonify(notifications_list)

@app.route('/api/pending_recommendations')
def get_pending_recommendations():
    if not check_db_connection() or not conn:
        return jsonify({"error": "ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"}), 500
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT * FROM pending_recommendations ORDER BY created_at DESC;")
            pending_recs = cur.fetchall()
        for rec in pending_recs:
            with prices_lock:
                rec['current_price'] = current_prices.get(rec['symbol'])
            if 'created_at' in rec and isinstance(rec['created_at'], datetime):
                 rec['created_at'] = rec['created_at'].isoformat()
        return jsonify(pending_recs)
    except Exception as e:
        logger.error(f"âŒ [API ØªÙˆØµÙŠØ§Øª Ù…Ø¹Ù„Ù‚Ø©] Ø®Ø·Ø£: {e}")
        return jsonify({"error": "ØªØ¹Ø°Ø± Ø¬Ù„Ø¨ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©"}), 500

@app.route('/api/trigger_pending/<int:rec_id>', methods=['POST'])
def trigger_pending_recommendation(rec_id):
    logger.info(f"â„¹ï¸ [API ØªÙØ¹ÙŠÙ„ ÙÙˆØ±ÙŠ] ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø·Ù„Ø¨ ØªÙØ¹ÙŠÙ„ ÙÙˆØ±ÙŠ Ù„Ù„ØªÙˆØµÙŠØ© Ø§Ù„Ù…Ø¹Ù„Ù‚Ø© ID: {rec_id}")
    if not check_db_connection() or not conn:
        return jsonify({"error": "ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"}), 500
    with signal_cache_lock:
        if len(open_signals_cache) >= MAX_OPEN_TRADES:
            return jsonify({"error": f"Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ØªÙØ¹ÙŠÙ„ØŒ ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„ØµÙÙ‚Ø§Øª ({MAX_OPEN_TRADES})."}), 400
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT * FROM pending_recommendations WHERE id = %s;", (rec_id,))
            rec = cur.fetchone()
        if not rec: return jsonify({"error": "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ØªÙˆØµÙŠØ© Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©."}), 404
        symbol = rec['symbol']
        with prices_lock:
            current_price = current_prices.get(symbol)
        if not current_price:
            return jsonify({"error": f"ØªØ¹Ø°Ø± Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ Ù„Ù€ {symbol}."}), 500

        new_entry_price = current_price
        tp1 = rec['original_entry_price']
        tp2 = rec['original_target_price']
        atr_at_creation = rec.get('atr_at_creation')

        new_stop_loss, sl_info = 0, "ATR Fallback"
        strong_supports = []
        if USE_SR_LEVELS:
            all_levels = fetch_sr_levels(symbol)
            if all_levels:
                strong_lvls = [lvl for lvl in all_levels if lvl.get('score', 0) >= MINIMUM_SR_SCORE]
                strong_supports = [lvl for lvl in strong_lvls if 'support' in lvl.get('level_type','') and lvl['level_price'] < new_entry_price]
        if strong_supports:
            closest_support = max(strong_supports, key=lambda x: x['level_price'])
            new_stop_loss = closest_support['level_price'] * 0.998
            sl_info = f"Strong Support (Score > {MINIMUM_SR_SCORE})"
        elif atr_at_creation:
            new_stop_loss = new_entry_price - (atr_at_creation * ATR_SL_MULTIPLIER)
        else:
            new_stop_loss = new_entry_price * 0.98

        if tp2 <= new_entry_price or new_stop_loss >= new_entry_price:
            return jsonify({"error": "ÙØ´Ù„ Ø§Ù„ØªÙØ¹ÙŠÙ„. Ø§Ù„Ù‡Ø¯Ù Ø£Ùˆ Ø§Ù„ÙˆÙ‚Ù ØºÙŠØ± Ù…Ù†Ø·Ù‚ÙŠ Ø¨Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ."}), 400

        original_details = json.loads(rec.get('signal_details', '{}'))
        new_signal = {
            'symbol': symbol, 'entry_price': new_entry_price, 'target_price': tp2,
            'stop_loss': new_stop_loss, 'strategy_name': "Manual-Triggered",
            'signal_details': { **original_details, 'TP1': tp1, 'TP2': tp2,
                'trigger_event': 'Manual trigger from dashboard', 'sr_info': sl_info }
        }
        saved_signal = insert_signal_into_db(new_signal)
        if saved_signal:
            with signal_cache_lock:
                open_signals_cache[saved_signal['symbol']] = saved_signal
            send_new_signal_alert(saved_signal)
            with conn.cursor() as del_cur:
                del_cur.execute("DELETE FROM pending_recommendations WHERE id = %s;", (rec_id,))
            conn.commit()
            logger.info(f"âœ… [{symbol}] ØªÙ… ØªÙØ¹ÙŠÙ„ Ø§Ù„ØªÙˆØµÙŠØ© Ø§Ù„Ù…Ø¹Ù„Ù‚Ø© ÙŠØ¯ÙˆÙŠØ§Ù‹ Ø¨Ù†Ø¬Ø§Ø­.")
            return jsonify({"message": f"ØªÙ… ØªÙØ¹ÙŠÙ„ Ø§Ù„ØµÙÙ‚Ø© Ù„Ù€ {symbol} Ø¨Ù†Ø¬Ø§Ø­."})
        else:
            return jsonify({"error": "ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„ØµÙÙ‚Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."}), 500
    except Exception as e:
        logger.error(f"âŒ [API ØªÙØ¹ÙŠÙ„ ÙÙˆØ±ÙŠ] Ø®Ø·Ø£ ÙØ§Ø¯Ø­: {e}", exc_info=True)
        if conn: conn.rollback()
        return jsonify({"error": "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…."}), 500

def run_flask():
    host, port = "0.0.0.0", int(os.environ.get('PORT', 10000))
    log_and_notify("info", f"Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ… Ø¹Ù„Ù‰ {host}:{port}", "SYSTEM")
    try:
        from waitress import serve
        serve(app, host=host, port=port, threads=8)
    except ImportError:
        logger.warning("âš ï¸ [Flask] Ù…ÙƒØªØ¨Ø© 'waitress' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©, Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø§Ø¯Ù… Ø§Ù„ØªØ·ÙˆÙŠØ±.")
        app.run(host=host, port=port)

# ---------------------- Ù†Ù‚Ø·Ø© Ø§Ù†Ø·Ù„Ø§Ù‚ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ (Ù…ÙØ¹Ø¯Ù‘ÙÙ„Ø©) ----------------------
def initialize_bot_services():
    global client, validated_symbols_to_scan
    logger.info("ğŸ¤– [Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¨ÙˆØª] Ø¨Ø¯Ø¡ Ø§Ù„ØªÙ‡ÙŠØ¦Ø© ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©...")
    try:
        client = Client(API_KEY, API_SECRET)
        logger.info("âœ… [Binance] ØªÙ… Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª Binance Ø¨Ù†Ø¬Ø§Ø­.")
        init_db()
        load_open_signals_to_cache()
        load_notifications_to_cache()
        validated_symbols_to_scan = get_validated_symbols()
        if not validated_symbols_to_scan:
            logger.critical("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø±Ù…ÙˆØ² Ù…Ø¹ØªÙ…Ø¯Ø© Ù„Ù„Ù…Ø³Ø­. Ø§Ù„Ø­Ù„Ù‚Ø§Øª Ù„Ù† ØªØ¨Ø¯Ø£.")
            return
        Thread(target=run_websocket_manager, daemon=True).start()
        Thread(target=main_loop, daemon=True).start()
        Thread(target=monitor_pending_loop, daemon=True).start()
        logger.info("âœ… [Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¨ÙˆØª] ØªÙ… Ø¨Ø¯Ø¡ Ø¬Ù…ÙŠØ¹ Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø®Ù„ÙÙŠØ© Ø¨Ù†Ø¬Ø§Ø­.")
    except Exception as e:
        log_and_notify("critical", f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø­Ø§Ø³Ù… Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙ‡ÙŠØ¦Ø©: {e}", "SYSTEM")
        pass

if __name__ == "__main__":
    logger.info(f"ğŸš€ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø¨ÙˆØª Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… - Ø¥ØµØ¯Ø§Ø± {BASE_ML_MODEL_NAME}...")
    initialization_thread = Thread(target=initialize_bot_services, daemon=True)
    initialization_thread.start()
    run_flask()
    logger.info("ğŸ‘‹ [Ø¥ÙŠÙ‚Ø§Ù] ØªÙ… Ø¥ÙŠÙ‚Ø§Ù ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª.")
    os._exit(0)
