import time
import os
import json
import logging
import requests
import numpy as np
import pandas as pd
import psycopg2
import pickle
import redis
import re
from urllib.parse import urlparse
from psycopg2 import sql, OperationalError, InterfaceError
from psycopg2.extras import RealDictCursor
from binance.client import Client
from binance import ThreadedWebsocketManager
from binance.exceptions import BinanceAPIException
from flask import Flask, request, Response, jsonify, render_template_string
from flask_cors import CORS
from threading import Thread, Lock
from datetime import datetime, timedelta, timezone
from decouple import config
from typing import List, Dict, Optional, Any, Set
from sklearn.preprocessing import StandardScaler
from collections import deque
import warnings
import gc

# --- ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª ØºÙŠØ± Ø§Ù„Ù‡Ø§Ù…Ø© ---
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.simplefilter(action='ignore', category=UserWarning)


# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (Logging) ----------------------
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('crypto_bot_v16.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('CryptoBotV16_Reinforcement')

# ---------------------- ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© ----------------------
try:
    API_KEY: str = config('BINANCE_API_KEY')
    API_SECRET: str = config('BINANCE_API_SECRET')
    TELEGRAM_TOKEN: str = config('TELEGRAM_BOT_TOKEN')
    CHAT_ID: str = config('TELEGRAM_CHAT_ID')
    DB_URL: str = config('DATABASE_URL')
    WEBHOOK_URL: Optional[str] = config('WEBHOOK_URL', default=None)
    REDIS_URL: str = config('REDIS_URL', default='redis://localhost:6379/0')
except Exception as e:
    logger.critical(f"âŒ ÙØ´Ù„ Ø­Ø§Ø³Ù… ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©: {e}")
    exit(1)

# ---------------------- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø«ÙˆØ§Ø¨Øª ÙˆØ§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© ----------------------
BASE_ML_MODEL_NAME: str = 'LightGBM_Scalping_V8_With_Momentum'
MODEL_FOLDER: str = 'V8'
SIGNAL_GENERATION_TIMEFRAME: str = '15m'
HIGHER_TIMEFRAME: str = '4h'
SIGNAL_GENERATION_LOOKBACK_DAYS: int = 30
REDIS_PRICES_HASH_NAME: str = "crypto_bot_current_prices_v8"
MODEL_BATCH_SIZE: int = 5
DIRECT_API_CHECK_INTERVAL: int = 10
TRADING_FEE_PERCENT: float = 0.1 # Ø±Ø³ÙˆÙ… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ 0.1%
HYPOTHETICAL_TRADE_SIZE_USDT: float = 10.0 # Ø­Ø¬Ù… Ø§Ù„ØµÙÙ‚Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø±Ø¨Ø­ Ø¨Ø§Ù„Ø¯ÙˆÙ„Ø§Ø±

# --- Ù…Ø¤Ø´Ø±Ø§Øª ÙÙ†ÙŠØ© ---
ADX_PERIOD: int = 14
RSI_PERIOD: int = 14
ATR_PERIOD: int = 14
EMA_FAST_PERIOD: int = 50
EMA_SLOW_PERIOD: int = 200
REL_VOL_PERIOD: int = 30
MOMENTUM_PERIOD: int = 12
EMA_SLOPE_PERIOD: int = 5


# --- Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØµÙÙ‚Ø§Øª ---
MAX_OPEN_TRADES: int = 10
BUY_CONFIDENCE_THRESHOLD = 0.65
SELL_CONFIDENCE_THRESHOLD = 0.70
MIN_PROFIT_FOR_SELL_CLOSE_PERCENT = 0.2
# âœ¨ New: Minimum confidence increase to justify a trade update
MIN_CONFIDENCE_INCREASE_FOR_UPDATE = 0.05 

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù‡Ø¯Ù ÙˆÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© ---
ATR_FALLBACK_SL_MULTIPLIER: float = 1.5
ATR_FALLBACK_TP_MULTIPLIER: float = 2.0
SL_BUFFER_ATR_PERCENT: float = 0.25

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ù…ØªØ­Ø±Ùƒ (Trailing Stop-Loss) ---
USE_TRAILING_STOP_LOSS: bool = True
TRAILING_ACTIVATION_PROFIT_PERCENT: float = 1.0
TRAILING_DISTANCE_PERCENT: float = 0.8
LAST_PEAK_UPDATE_TIME: Dict[int, float] = {}
PEAK_UPDATE_COOLDOWN: int = 60

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙÙ„Ø§ØªØ± Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø© ---
USE_BTC_TREND_FILTER: bool = True
BTC_SYMBOL: str = 'BTCUSDT'
BTC_TREND_TIMEFRAME: str = '4h'
BTC_TREND_EMA_PERIOD: int = 50
USE_SPEED_FILTER: bool = True
USE_RRR_FILTER: bool = True
MIN_RISK_REWARD_RATIO: float = 1.1
USE_BTC_CORRELATION_FILTER: bool = True
MIN_BTC_CORRELATION: float = 0.1
USE_MIN_VOLATILITY_FILTER: bool = True
MIN_VOLATILITY_PERCENT: float = 0.3
USE_MOMENTUM_FILTER: bool = True


# --- Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© ÙˆÙ‚ÙÙ„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª ---
conn: Optional[psycopg2.extensions.connection] = None
client: Optional[Client] = None
redis_client: Optional[redis.Redis] = None
ml_models_cache: Dict[str, Any] = {}
validated_symbols_to_scan: List[str] = []
open_signals_cache: Dict[str, Dict] = {}
signal_cache_lock = Lock()
notifications_cache = deque(maxlen=50)
notifications_lock = Lock()
signals_pending_closure: Set[int] = set()
closure_lock = Lock()
last_api_check_time = time.time()
rejection_logs_cache = deque(maxlen=100)
rejection_logs_lock = Lock()
last_market_state_check = 0
current_market_state: Dict[str, Any] = {
    "overall_regime": "INITIALIZING",
    "details": {},
    "last_updated": None
}
market_state_lock = Lock()


# ---------------------- Ø¯Ø§Ù„Ø© HTML Ù„Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ… (ØªÙ… Ø§Ù„Ø¥ØµÙ„Ø§Ø­) ----------------------
def get_dashboard_html():
    """
    Ù„ÙˆØ­Ø© ØªØ­ÙƒÙ… Ù…Ø­Ø³Ù†Ø© Ù…Ø¹ Ø´Ø§Ø±Øª Ø£Ø±Ø¨Ø§Ø­ Ø¨ØªØµÙ…ÙŠÙ… Ø§Ù„Ø´Ù…ÙˆØ¹ Ø§Ù„ÙŠØ§Ø¨Ø§Ù†ÙŠØ© (Ø´Ù„Ø§Ù„) ÙˆØªØµÙ…ÙŠÙ… Ù…ØªØ¬Ø§ÙˆØ¨.
    """
    return """
<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ù„ÙˆØ­Ø© ØªØ­ÙƒÙ… Ø¨ÙˆØª Ø§Ù„ØªØ¯Ø§ÙˆÙ„ V8</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.2/dist/chart.umd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/luxon@3.4.4/build/global/luxon.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-adapter-luxon@1.3.1/dist/chartjs-adapter-luxon.umd.min.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=Cairo:wght@400;700;900&display=swap" rel="stylesheet">
    <style>
        :root {
            --bg-dark: #111827; --bg-card: #1F2937; --border-color: #374151;
            --text-primary: #F9FAFB; --text-secondary: #9CA3AF;
            --accent-blue: #3B82F6; --accent-green: #22C55E; --accent-red: #EF4444; --accent-yellow: #EAB308;
        }
        body { font-family: 'Cairo', sans-serif; background-color: var(--bg-dark); color: var(--text-primary); }
        .card { background-color: var(--bg-card); border: 1px solid var(--border-color); border-radius: 0.75rem; transition: all 0.3s ease-in-out; padding: 1rem; }
        .card:hover { transform: translateY(-4px); box-shadow: 0 8px 25px rgba(0,0,0,0.2); border-color: var(--accent-blue); }
        .skeleton { animation: pulse 1.5s cubic-bezier(0.4, 0, 0.6, 1) infinite; background-color: #374151; border-radius: 0.5rem; }
        @keyframes pulse { 50% { opacity: .5; } }
        .progress-bar-container { position: relative; width: 100%; height: 1.25rem; background-color: #374151; border-radius: 0.5rem; overflow: hidden; display: flex; align-items: center; }
        .progress-bar { height: 100%; transition: width 0.5s ease-in-out; }
        .progress-point { position: absolute; top: 50%; transform: translateY(-50%); width: 8px; height: 8px; border-radius: 50%; border: 2px solid white; }
        .entry-point { background-color: var(--accent-blue); }
        .current-point { background-color: var(--accent-yellow); }
        .progress-labels { display: flex; justify-content: space-between; font-size: 0.7rem; color: var(--text-secondary); padding: 0 2px; margin-top: 2px; }
        #needle { transition: transform 1s cubic-bezier(0.68, -0.55, 0.27, 1.55); }
        .tab-btn.active { border-bottom-color: var(--accent-blue); color: var(--text-primary); }
    </style>
</head>
<body class="p-4 md:p-6">
    <div class="container mx-auto max-w-7xl">
        <header class="mb-6 flex flex-wrap justify-between items-center gap-4">
            <h1 class="text-3xl md:text-4xl font-black text-white">Ù„ÙˆØ­Ø© ØªØ­ÙƒÙ… Ø§Ù„ØªØ¯Ø§ÙˆÙ„</h1>
            <div id="connection-status" class="flex items-center gap-2 text-sm">
                <div id="db-status-light" class="w-3 h-3 rounded-full bg-gray-500 animate-pulse"></div><span class="text-text-secondary">DB</span>
                <div id="api-status-light" class="w-3 h-3 rounded-full bg-gray-500 animate-pulse"></div><span class="text-text-secondary">API</span>
            </div>
        </header>

        <section class="mb-6 grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-5">
            <div class="card lg:col-span-2">
                <h3 class="font-bold mb-3 text-lg">Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø³ÙˆÙ‚ (BTC)</h3>
                <div class="grid grid-cols-2 sm:grid-cols-4 gap-4 text-center">
                    <div>
                        <h4 class="text-sm font-semibold text-text-secondary">Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù…</h4>
                        <div id="overall-regime" class="text-2xl font-bold skeleton h-8 w-3/4 mx-auto mt-1"></div>
                    </div>
                    <div>
                        <h4 class="text-sm font-semibold text-text-secondary">Ø¥Ø·Ø§Ø± 15 Ø¯Ù‚ÙŠÙ‚Ø©</h4>
                        <div id="tf-15m-status" class="text-xl font-bold skeleton h-7 w-2/3 mx-auto mt-1"></div>
                        <div id="tf-15m-details" class="text-xs text-text-secondary skeleton h-4 w-1/2 mx-auto mt-1"></div>
                    </div>
                    <div>
                        <h4 class="text-sm font-semibold text-text-secondary">Ø¥Ø·Ø§Ø± Ø³Ø§Ø¹Ø©</h4>
                        <div id="tf-1h-status" class="text-xl font-bold skeleton h-7 w-2/3 mx-auto mt-1"></div>
                        <div id="tf-1h-details" class="text-xs text-text-secondary skeleton h-4 w-1/2 mx-auto mt-1"></div>
                    </div>
                    <div>
                        <h4 class="text-sm font-semibold text-text-secondary">Ø¥Ø·Ø§Ø± 4 Ø³Ø§Ø¹Ø§Øª</h4>
                        <div id="tf-4h-status" class="text-xl font-bold skeleton h-7 w-2/3 mx-auto mt-1"></div>
                        <div id="tf-4h-details" class="text-xs text-text-secondary skeleton h-4 w-1/2 mx-auto mt-1"></div>
                    </div>
                </div>
            </div>
            <div class="card flex flex-col justify-center items-center">
                 <h3 class="font-bold mb-2 text-lg">Ù…Ø¤Ø´Ø± Ø§Ù„Ø®ÙˆÙ ÙˆØ§Ù„Ø·Ù…Ø¹</h3>
                 <div id="fear-greed-gauge" class="relative w-full max-w-[180px] aspect-square"></div>
                 <div id="fear-greed-value" class="text-3xl font-bold mt-[-25px] skeleton h-10 w-1/2"></div>
                 <div id="fear-greed-text" class="text-md text-text-secondary skeleton h-6 w-3/4 mt-1"></div>
            </div>
            <div class="card flex flex-col justify-center items-center text-center">
                <h3 class="font-bold text-text-secondary text-lg">ØµÙÙ‚Ø§Øª Ù…ÙØªÙˆØ­Ø©</h3>
                <div id="open-trades-value" class="text-5xl font-black text-accent-blue mt-2 skeleton h-12 w-1/2"></div>
            </div>
        </section>

        <section class="mb-6 grid grid-cols-1 lg:grid-cols-3 gap-5">
            <div id="profit-chart-card" class="card lg:col-span-2">
                <h3 class="font-bold mb-3">Ø£Ø¯Ø§Ø¡ Ø§Ù„ØµÙÙ‚Ø§Øª (Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠ %)</h3>
                <div class="relative h-80 md:h-96">
                    <canvas id="profitChart"></canvas>
                </div>
            </div>
            <div id="other-stats-container" class="grid grid-cols-1 sm:grid-cols-3 lg:grid-cols-1 gap-4">
                <div class="card text-center flex flex-col justify-center">
                    <div class="text-sm text-text-secondary mb-1">ØµØ§ÙÙŠ Ø§Ù„Ø±Ø¨Ø­ (USDT)</div>
                    <div id="net-profit-usdt" class="text-2xl font-bold skeleton h-8 w-3/4 mx-auto"></div>
                </div>
                <div class="card text-center flex flex-col justify-center">
                    <div class="text-sm text-text-secondary mb-1">Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­</div>
                    <div id="win-rate" class="text-2xl font-bold skeleton h-8 w-1/2 mx-auto"></div>
                </div>
                <div class="card text-center flex flex-col justify-center">
                    <div class="text-sm text-text-secondary mb-1">Ø¹Ø§Ù…Ù„ Ø§Ù„Ø±Ø¨Ø­</div>
                    <div id="profit-factor" class="text-2xl font-bold skeleton h-8 w-1/2 mx-auto"></div>
                </div>
            </div>
        </section>

        <div class="mb-4 border-b border-border-color">
            <nav class="flex space-x-4 -mb-px" aria-label="Tabs">
                <button onclick="showTab('signals', this)" class="tab-btn active text-white border-b-2 py-3 px-4 font-semibold">Ø§Ù„ØµÙÙ‚Ø§Øª</button>
                <button onclick="showTab('notifications', this)" class="tab-btn text-text-secondary hover:text-white py-3 px-4">Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª</button>
                <button onclick="showTab('rejections', this)" class="tab-btn text-text-secondary hover:text-white py-3 px-4">Ø§Ù„ØµÙÙ‚Ø§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¶Ø©</button>
            </nav>
        </div>

        <main>
            <div id="signals-tab" class="tab-content"><div class="overflow-x-auto card p-0"><table class="min-w-full text-sm text-right"><thead class="border-b border-border-color"><tr><th class="p-4 font-semibold">Ø§Ù„Ø¹Ù…Ù„Ø©</th><th class="p-4 font-semibold">Ø§Ù„Ø­Ø§Ù„Ø©</th><th class="p-4 font-semibold">Ø§Ù„Ø±Ø¨Ø­/Ø§Ù„Ø®Ø³Ø§Ø±Ø©</th><th class="p-4 font-semibold w-[35%]">Ø§Ù„ØªÙ‚Ø¯Ù… Ù†Ø­Ùˆ Ø§Ù„Ù‡Ø¯Ù</th><th class="p-4 font-semibold">Ø§Ù„Ø¯Ø®ÙˆÙ„ / Ø§Ù„Ø­Ø§Ù„ÙŠ</th><th class="p-4 font-semibold">Ø¥Ø¬Ø±Ø§Ø¡</th></tr></thead><tbody id="signals-table"></tbody></table></div></div>
            <div id="notifications-tab" class="tab-content hidden"><div id="notifications-list" class="card p-4 max-h-[60vh] overflow-y-auto space-y-2"></div></div>
            <div id="rejections-tab" class="tab-content hidden"><div id="rejections-list" class="card p-4 max-h-[60vh] overflow-y-auto space-y-2"></div></div>
        </main>
    </div>

<script>
let profitChartInstance;
const REGIME_STYLES = {
    "STRONG UPTREND": { text: "ØµØ§Ø¹Ø¯ Ù‚ÙˆÙŠ", color: "text-accent-green" }, "UPTREND": { text: "ØµØ§Ø¹Ø¯", color: "text-green-400" },
    "RANGING": { text: "Ø¹Ø±Ø¶ÙŠ", color: "text-accent-yellow" }, "DOWNTREND": { text: "Ù‡Ø§Ø¨Ø·", color: "text-red-400" },
    "STRONG DOWNTREND": { text: "Ù‡Ø§Ø¨Ø· Ù‚ÙˆÙŠ", color: "text-accent-red" }, "UNCERTAIN": { text: "ØºÙŠØ± ÙˆØ§Ø¶Ø­", color: "text-text-secondary" },
    "INITIALIZING": { text: "ØªÙ‡ÙŠØ¦Ø©...", color: "text-accent-blue" }
};
const TF_STATUS_STYLES = {
    "Uptrend": { text: "ØµØ§Ø¹Ø¯", icon: "â–²", color: "text-accent-green" }, "Downtrend": { text: "Ù‡Ø§Ø¨Ø·", icon: "â–¼", color: "text-accent-red" },
    "Ranging": { text: "Ø¹Ø±Ø¶ÙŠ", icon: "â†”", color: "text-accent-yellow" }, "Uncertain": { text: "ØºÙŠØ± ÙˆØ§Ø¶Ø­", icon: "?", color: "text-text-secondary" }
};

function formatNumber(num, digits = 2) {
    if (num === null || num === undefined || isNaN(num)) return 'N/A';
    return num.toLocaleString('en-US', { minimumFractionDigits: digits, maximumFractionDigits: digits });
}

function showTab(tabName, element) {
    document.querySelectorAll('.tab-content').forEach(tab => tab.classList.add('hidden'));
    document.getElementById(`${tabName}-tab`).classList.remove('hidden');
    document.querySelectorAll('.tab-btn').forEach(btn => {
        btn.classList.remove('active', 'text-white', 'border-accent-blue', 'font-semibold');
        btn.classList.add('text-text-secondary', 'border-transparent');
    });
    element.classList.add('active', 'text-white', 'border-accent-blue', 'font-semibold');
    element.classList.remove('text-text-secondary', 'border-transparent');
}

async function apiFetch(url) {
    try {
        const response = await fetch(url);
        if (!response.ok) { 
            console.error(`API Error ${response.status}`); 
            try {
                return await response.json(); // Try to get error message from body
            } catch (e) {
                return { error: `HTTP Error ${response.status}` };
            }
        }
        return await response.json();
    } catch (error) { 
        console.error(`Fetch error for ${url}:`, error); 
        return { error: "Network or fetch error" };
    }
}

function getFngColor(value) {
    if (value < 25) return '#EF4444'; if (value < 45) return '#F97316';
    if (value < 55) return '#EAB308'; if (value < 75) return '#84CC16';
    return '#22C55E';
}

function renderFearGreedGauge(value, classification) {
    const container = document.getElementById('fear-greed-gauge');
    const valueEl = document.getElementById('fear-greed-value');
    const textEl = document.getElementById('fear-greed-text');
    [valueEl, textEl].forEach(el => el.classList.remove('skeleton', 'h-10', 'w-1/2', 'h-6', 'w-3/4'));

    if (value === -1) {
        container.innerHTML = `<div class="text-center text-text-secondary">Ø®Ø·Ø£</div>`;
        valueEl.textContent = 'N/A'; textEl.textContent = 'ÙØ´Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„';
        return;
    }
    valueEl.textContent = value; textEl.textContent = classification;
    const angle = -90 + (value / 100) * 180;
    const color = getFngColor(value);
    valueEl.style.color = color;
    container.innerHTML = `<svg viewBox="0 0 100 57" class="w-full h-full"><defs><linearGradient id="g"><stop offset="0%" stop-color="#EF4444"/><stop offset="50%" stop-color="#EAB308"/><stop offset="100%" stop-color="#22C55E"/></linearGradient></defs><path d="M10 50 A 40 40 0 0 1 90 50" stroke="url(#g)" stroke-width="10" fill="none" stroke-linecap="round"/><g transform="rotate(${angle} 50 50)"><path d="M50 45 L 47 15 Q 50 10 53 15 L 50 45" fill="${color}" id="needle"/></g><circle cx="50" cy="50" r="4" fill="${color}"/></svg>`;
}

function updateMarketStatus() {
    apiFetch('/api/market_status').then(data => {
        if (!data || data.error) return;
        document.getElementById('db-status-light').className = `w-3 h-3 rounded-full ${data.db_ok ? 'bg-green-500' : 'bg-red-500'}`;
        document.getElementById('api-status-light').className = `w-3 h-3 rounded-full ${data.api_ok ? 'bg-green-500' : 'bg-red-500'}`;
        
        const state = data.market_state;
        const overallRegime = state.overall_regime || "UNCERTAIN";
        const regimeStyle = REGIME_STYLES[overallRegime.toUpperCase()] || REGIME_STYLES["UNCERTAIN"];
        const overallDiv = document.getElementById('overall-regime');
        overallDiv.textContent = regimeStyle.text;
        overallDiv.className = `text-2xl font-bold ${regimeStyle.color}`;
        overallDiv.classList.remove('skeleton', 'h-8', 'w-3/4', 'mx-auto', 'mt-1');

        ['15m', '1h', '4h'].forEach(tf => {
            const tfData = state.details[tf];
            const statusDiv = document.getElementById(`tf-${tf}-status`);
            const detailsDiv = document.getElementById(`tf-${tf}-details`);
            [statusDiv, detailsDiv].forEach(el => el.classList.remove('skeleton', 'h-7', 'w-2/3', 'h-4', 'w-1/2', 'mx-auto', 'mt-1'));
            if (tfData) {
                const style = TF_STATUS_STYLES[tfData.trend] || TF_STATUS_STYLES["Uncertain"];
                statusDiv.innerHTML = `<span class="${style.color}">${style.icon} ${style.text}</span>`;
                detailsDiv.textContent = `RSI: ${formatNumber(tfData.rsi, 1)} | ADX: ${formatNumber(tfData.adx, 1)}`;
            } else {
                statusDiv.textContent = 'N/A'; detailsDiv.textContent = '';
            }
        });
        renderFearGreedGauge(data.fear_and_greed.value, data.fear_and_greed.classification);
    });
}

function updateStats() {
    apiFetch('/api/stats').then(data => {
        const stat_ids = ['open-trades-value', 'net-profit-usdt', 'win-rate', 'profit-factor'];
        if (!data || data.error) {
            console.error("Failed to fetch stats:", data ? data.error : "No data");
            stat_ids.forEach(id => {
                const el = document.getElementById(id);
                if (el) {
                    el.textContent = 'Ø®Ø·Ø£';
                    el.classList.remove('skeleton');
                }
            });
            return;
        }

        const profitFactorDisplay = data.profit_factor === 'Infinity' ? 'âˆ' : formatNumber(data.profit_factor);

        const fields = {
            'open-trades-value': formatNumber(data.open_trades_count, 0),
            'net-profit-usdt': `$${formatNumber(data.net_profit_usdt)}`,
            'win-rate': `${formatNumber(data.win_rate)}%`,
            'profit-factor': profitFactorDisplay
        };

        for (const [id, value] of Object.entries(fields)) {
            const el = document.getElementById(id);
            if (el) {
                el.textContent = value;
                el.classList.remove('skeleton', 'h-12', 'h-8', 'w-1/2', 'w-3/4', 'mx-auto');
                if (id === 'net-profit-usdt') {
                    el.className = `text-2xl font-bold ${data.net_profit_usdt >= 0 ? 'text-accent-green' : 'text-accent-red'}`;
                }
            }
        }
    });
}

// âœ¨ UPDATED: Profit chart function for waterfall/candlestick style
function updateProfitChart() {
    const chartCard = document.getElementById('profit-chart-card');
    const canvas = document.getElementById('profitChart');

    apiFetch('/api/profit_curve').then(data => {
        const existingMsg = chartCard.querySelector('.no-data-msg, .error-msg');
        if(existingMsg) existingMsg.remove();

        if (!data || data.error) { 
            canvas.style.display = 'none'; 
            chartCard.insertAdjacentHTML('beforeend', '<p class="error-msg text-center text-text-secondary mt-8">Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ.</p>');
            return; 
        }
        if (data.length <= 1) { 
            canvas.style.display = 'none'; 
            chartCard.insertAdjacentHTML('beforeend', '<p class="no-data-msg text-center text-text-secondary mt-8">Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙÙ‚Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ.</p>');
            return;
        }
        
        canvas.style.display = 'block';
        const ctx = canvas.getContext('2d');
        const labels = data.map((d, i) => i > 0 ? `ØµÙÙ‚Ø© ${i}` : 'Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©');
        const chartData = data.map(d => d.profit_range);
        
        const config = {
            type: 'bar',
            data: {
                labels: labels,
                datasets: [{
                    label: 'Ø§Ù„Ø±Ø¨Ø­/Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ù„Ù„ØµÙÙ‚Ø©',
                    data: chartData,
                    backgroundColor: (ctx) => {
                        if (ctx.raw === null || ctx.raw === undefined) return 'var(--border-color)';
                        const [start, end] = ctx.raw;
                        return end >= start ? 'rgba(34, 197, 94, 0.7)' : 'rgba(239, 68, 68, 0.7)';
                    },
                    borderColor: (ctx) => {
                        if (ctx.raw === null || ctx.raw === undefined) return 'var(--border-color)';
                        const [start, end] = ctx.raw;
                        return end >= start ? 'var(--accent-green)' : 'var(--accent-red)';
                    },
                    borderWidth: 1,
                    barPercentage: 0.8,
                    categoryPercentage: 0.9,
                    borderSkipped: false
                }]
            },
            options: {
                responsive: true, maintainAspectRatio: false,
                scales: {
                    x: { ticks: { display: false }, grid: { display: false } },
                    y: { beginAtZero: false, ticks: { color: 'var(--text-secondary)', callback: v => formatNumber(v) + '%' }, grid: { color: '#37415180' } }
                },
                plugins: {
                    legend: { display: false },
                    tooltip: {
                        mode: 'index', intersect: false, backgroundColor: 'var(--bg-card)',
                        titleFont: { weight: 'bold' }, bodyFont: { family: 'Cairo' },
                        callbacks: {
                            title: (ctx) => ctx[0] ? ctx[0].label : '',
                            label: (ctx) => {
                                if (ctx.dataIndex === 0) return `Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©: ${formatNumber(ctx.raw[1])}%`;
                                const tradeData = data[ctx.dataIndex];
                                const profit = tradeData.profit_change;
                                const cumulative = tradeData.profit_range[1];
                                return [`Ø±Ø¨Ø­ Ø§Ù„ØµÙÙ‚Ø©: ${formatNumber(profit)}%`, `Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„ØªØ±Ø§ÙƒÙ…ÙŠ: ${formatNumber(cumulative)}%`];
                            }
                        }
                    }
                }
            }
        };

        if (profitChartInstance) {
            profitChartInstance.data.labels = labels;
            profitChartInstance.data.datasets[0].data = chartData;
            profitChartInstance.update('none');
        } else {
            profitChartInstance = new Chart(ctx, config);
        }
    });
}

function renderProgressBar(signal) {
    const { entry_price, stop_loss, target_price, current_price } = signal;
    if ([entry_price, stop_loss, target_price, current_price].some(v => v === null)) return '<span>Ù„Ø§ ØªØªÙˆÙØ± Ø¨ÙŠØ§Ù†Ø§Øª</span>';
    const [entry, sl, tp, current] = [entry_price, stop_loss, target_price, current_price].map(parseFloat);
    const totalDist = tp - sl;
    if (totalDist <= 0) return '<span>Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ØµØ§Ù„Ø­Ø©</span>';
    const progressPct = Math.max(0, Math.min(100, ((current - sl) / totalDist) * 100));
    const entryPointPct = Math.max(0, Math.min(100, ((entry - sl) / totalDist) * 100));
    return `<div class="flex flex-col w-full"><div class="progress-bar-container"><div class="progress-bar ${current >= entry ? 'bg-accent-green' : 'bg-accent-red'}" style="width: ${progressPct}%"></div><div class="progress-point entry-point" style="left: ${entryPointPct}%" title="Ø§Ù„Ø¯Ø®ÙˆÙ„: ${entry.toFixed(4)}"></div></div><div class="progress-labels"><span title="ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©">${sl.toFixed(4)}</span><span title="Ø§Ù„Ù‡Ø¯Ù">${tp.toFixed(4)}</span></div></div>`;
}

function updateSignals() {
    apiFetch('/api/signals').then(data => {
        const tableBody = document.getElementById('signals-table');
        if (!data || data.error) { tableBody.innerHTML = '<tr><td colspan="6" class="p-8 text-center">ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙÙ‚Ø§Øª.</td></tr>'; return; }
        if (data.length === 0) { tableBody.innerHTML = '<tr><td colspan="6" class="p-8 text-center">Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙÙ‚Ø§Øª Ù„Ø¹Ø±Ø¶Ù‡Ø§.</td></tr>'; return; }
        tableBody.innerHTML = data.map(signal => {
            const pnlPct = signal.status === 'open' || signal.status === 'updated' ? (signal.pnl_pct || 0) : (signal.profit_percentage || 0);
            const statusClass = signal.status === 'open' ? 'text-yellow-400' : (signal.status === 'updated' ? 'text-blue-400' : 'text-gray-400');
            const statusText = signal.status === 'updated' ? 'ØªÙ… ØªØ­Ø¯ÙŠØ«Ù‡Ø§' : signal.status;
            return `<tr class="border-b border-border-color hover:bg-gray-800/50 transition-colors">
                    <td class="p-4 font-mono font-semibold">${signal.symbol}</td>
                    <td class="p-4 font-bold ${statusClass}">${statusText}</td>
                    <td class="p-4 font-mono font-bold ${pnlPct >= 0 ? 'text-accent-green' : 'text-accent-red'}">${formatNumber(pnlPct)}%</td>
                    <td class="p-4">${signal.status === 'open' || signal.status === 'updated' ? renderProgressBar(signal) : '-'}</td>
                    <td class="p-4 font-mono text-xs"><div>${formatNumber(signal.entry_price, 5)}</div><div class="text-text-secondary">${signal.current_price ? formatNumber(signal.current_price, 5) : 'N/A'}</div></td>
                    <td class="p-4">${signal.status === 'open' || signal.status === 'updated' ? `<button onclick="manualCloseSignal(${signal.id})" class="bg-red-600 hover:bg-red-700 text-white text-xs py-1 px-3 rounded-md">Ø¥ØºÙ„Ø§Ù‚</button>` : ''}</td>
                </tr>`;
        }).join('');
    });
}

function updateList(endpoint, listId, formatter) {
    apiFetch(endpoint).then(data => {
        if (!data || data.error) return;
        document.getElementById(listId).innerHTML = data.map(formatter).join('') || `<div class="p-4 text-center text-text-secondary">Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª.</div>`;
    });
}

function manualCloseSignal(signalId) {
    if (confirm(`Ù‡Ù„ Ø£Ù†Øª Ù…ØªØ£ÙƒØ¯ Ù…Ù† Ø±ØºØ¨ØªÙƒ ÙÙŠ Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„ØµÙÙ‚Ø© #${signalId} ÙŠØ¯ÙˆÙŠØ§Ù‹ØŸ`)) {
        fetch(`/api/close/${signalId}`, { method: 'POST' }).then(res => res.json()).then(data => {
            alert(data.message || data.error);
            refreshData();
        });
    }
}

function refreshData() {
    updateMarketStatus();
    updateStats();
    updateProfitChart();
    updateSignals();
    const dateLocaleOptions = { timeZone: 'UTC', year: 'numeric', month: '2-digit', day: '2-digit', hour: '2-digit', minute: '2-digit', second: '2-digit', hour12: false };
    const locale = 'fr-CA';
    updateList('/api/notifications', 'notifications-list', n => `<div class="p-3 rounded-md bg-gray-900/50 text-sm">[${new Date(n.timestamp).toLocaleString(locale, dateLocaleOptions)}] ${n.message}</div>`);
    updateList('/api/rejection_logs', 'rejections-list', log => `<div class="p-3 rounded-md bg-gray-900/50 text-sm">[${new Date(log.timestamp).toLocaleString(locale, dateLocaleOptions)}] <strong>${log.symbol}</strong>: ${log.reason} - <span class="font-mono text-xs text-text-secondary">${JSON.stringify(log.details)}</span></div>`);
}

setInterval(refreshData, 2000);
window.onload = refreshData;
</script>
</body>
</html>
    """

# ---------------------- Ø¯ÙˆØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ----------------------
def init_db(retries: int = 5, delay: int = 5) -> None:
    global conn
    logger.info("[DB] Initializing database connection...")
    db_url_to_use = DB_URL
    if 'postgres' in db_url_to_use and 'sslmode' not in db_url_to_use:
        separator = '&' if '?' in db_url_to_use else '?'
        db_url_to_use += f"{separator}sslmode=require"
    for attempt in range(retries):
        try:
            conn = psycopg2.connect(db_url_to_use, connect_timeout=15, cursor_factory=RealDictCursor)
            conn.autocommit = False
            with conn.cursor() as cur:
                cur.execute("""
                    CREATE TABLE IF NOT EXISTS signals (
                        id SERIAL PRIMARY KEY, symbol TEXT NOT NULL, entry_price DOUBLE PRECISION NOT NULL,
                        target_price DOUBLE PRECISION NOT NULL, stop_loss DOUBLE PRECISION NOT NULL,
                        status TEXT DEFAULT 'open', closing_price DOUBLE PRECISION, closed_at TIMESTAMP,
                        profit_percentage DOUBLE PRECISION, strategy_name TEXT, signal_details JSONB,
                        current_peak_price DOUBLE PRECISION
                    );
                """)
                # Add status index for faster queries
                cur.execute("CREATE INDEX IF NOT EXISTS idx_signals_status ON signals (status);")
                cur.execute("""
                    CREATE TABLE IF NOT EXISTS notifications (
                        id SERIAL PRIMARY KEY, timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                        type TEXT NOT NULL, message TEXT NOT NULL, is_read BOOLEAN DEFAULT FALSE
                    );
                """)
            conn.commit()
            logger.info("âœ… [DB] Database connection successful and tables initialized.")
            return
        except Exception as e:
            logger.error(f"âŒ [DB] Connection error (Attempt {attempt + 1}/{retries}): {e}")
            if conn: conn.rollback()
            if attempt < retries - 1: time.sleep(delay)
            else: logger.critical("âŒ [DB] Failed to connect to the database after multiple retries.")


def check_db_connection() -> bool:
    global conn
    if conn is None or conn.closed != 0:
        logger.warning("[DB] Connection is closed, attempting to reconnect...")
        init_db()
    try:
        if conn and conn.closed == 0:
            with conn.cursor() as cur: cur.execute("SELECT 1;")
            return True
        return False
    except (OperationalError, InterfaceError) as e:
        logger.error(f"âŒ [DB] Connection lost: {e}. Attempting to reconnect...")
        try:
            init_db()
            return conn is not None and conn.closed == 0
        except Exception as retry_e:
            logger.error(f"âŒ [DB] Reconnect failed: {retry_e}")
            return False
    return False

def log_and_notify(level: str, message: str, notification_type: str):
    log_methods = {'info': logger.info, 'warning': logger.warning, 'error': logger.error, 'critical': logger.critical}
    log_methods.get(level.lower(), logger.info)(message)
    if not check_db_connection() or not conn: return
    try:
        new_notification = {"timestamp": datetime.now().isoformat(), "type": notification_type, "message": message}
        with notifications_lock: notifications_cache.appendleft(new_notification)
        with conn.cursor() as cur: cur.execute("INSERT INTO notifications (type, message) VALUES (%s, %s);", (notification_type, message))
        conn.commit()
    except Exception as e:
        logger.error(f"âŒ [Notify DB] Failed to save notification to DB: {e}")
        if conn: conn.rollback()

def log_rejection(symbol: str, reason: str, details: Optional[Dict] = None):
    log_message = f"ğŸš« [REJECTED] {symbol} | Reason: {reason} | Details: {details or {}}"
    logger.info(log_message)
    with rejection_logs_lock:
        rejection_logs_cache.appendleft({
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "symbol": symbol,
            "reason": reason,
            "details": details or {}
        })

def init_redis() -> None:
    global redis_client
    logger.info("[Redis] Initializing Redis connection...")
    try:
        redis_client = redis.from_url(REDIS_URL, decode_responses=True)
        redis_client.ping()
        logger.info("âœ… [Redis] Successfully connected to Redis server.")
    except redis.exceptions.ConnectionError as e:
        logger.critical(f"âŒ [Redis] Failed to connect to Redis. Error: {e}")
        exit(1)

# ---------------------- Ø¯ÙˆØ§Ù„ Binance ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ----------------------
def get_validated_symbols(filename: str = 'crypto_list.txt') -> List[str]:
    if not client: return []
    try:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        file_path = os.path.join(script_dir, filename)
        with open(file_path, 'r', encoding='utf-8') as f:
            raw_symbols = {line.strip().upper() for line in f if line.strip() and not line.startswith('#')}
        formatted = {f"{s}USDT" if not s.endswith('USDT') else s for s in raw_symbols}
        exchange_info = client.get_exchange_info()
        active = {s['symbol'] for s in exchange_info['symbols'] if s.get('quoteAsset') == 'USDT' and s.get('status') == 'TRADING'}
        validated = sorted(list(formatted.intersection(active)))
        logger.info(f"âœ… [Validation] Bot will monitor {len(validated)} validated symbols.")
        return validated
    except Exception as e:
        logger.error(f"âŒ [Validation] An error occurred during symbol validation: {e}", exc_info=True)
        return []

def fetch_historical_data(symbol: str, interval: str, days: int) -> Optional[pd.DataFrame]:
    if not client: return None
    try:
        limit = int((days * 24 * 60) / int(re.sub('[a-zA-Z]', '', interval)))
        klines = client.get_historical_klines(symbol, interval, limit=min(limit, 1000))
        if not klines: return None
        df = pd.DataFrame(klines, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_volume', 'trades', 'taker_buy_base', 'taker_buy_quote', 'ignore'])
        df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']].astype(float)
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True)
        df.set_index('timestamp', inplace=True)
        return df.dropna()
    except Exception as e:
        logger.error(f"âŒ [Data] Error fetching historical data for {symbol}: {e}")
        return None

# ---------------------- Ø¯ÙˆØ§Ù„ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙˆØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ ----------------------
def calculate_features(df: pd.DataFrame, btc_df: Optional[pd.DataFrame]) -> pd.DataFrame:
    df_calc = df.copy()
    high_low = df_calc['high'] - df_calc['low']
    high_close = (df_calc['high'] - df_calc['close'].shift()).abs()
    low_close = (df_calc['low'] - df_calc['close'].shift()).abs()
    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
    df_calc['atr'] = tr.ewm(span=ATR_PERIOD, adjust=False).mean()
    up_move = df_calc['high'].diff()
    down_move = -df_calc['low'].diff()
    plus_dm = pd.Series(np.where((up_move > down_move) & (up_move > 0), up_move, 0.0), index=df_calc.index)
    minus_dm = pd.Series(np.where((down_move > up_move) & (down_move > 0), down_move, 0.0), index=df_calc.index)
    plus_di = 100 * plus_dm.ewm(span=ADX_PERIOD, adjust=False).mean() / df_calc['atr'].replace(0, 1e-9)
    minus_di = 100 * minus_dm.ewm(span=ADX_PERIOD, adjust=False).mean() / df_calc['atr'].replace(0, 1e-9)
    dx = 100 * (abs(plus_di - minus_di) / (plus_di + minus_di).replace(0, 1e-9))
    df_calc['adx'] = dx.ewm(span=ADX_PERIOD, adjust=False).mean()
    delta = df_calc['close'].diff()
    gain = delta.clip(lower=0).ewm(com=RSI_PERIOD - 1, adjust=False).mean()
    loss = -delta.clip(upper=0).ewm(com=RSI_PERIOD - 1, adjust=False).mean()
    df_calc['rsi'] = 100 - (100 / (1 + (gain / loss.replace(0, 1e-9))))
    df_calc['relative_volume'] = df_calc['volume'] / (df_calc['volume'].rolling(window=REL_VOL_PERIOD, min_periods=1).mean() + 1e-9)
    df_calc['price_vs_ema50'] = (df_calc['close'] / df_calc['close'].ewm(span=EMA_FAST_PERIOD, adjust=False).mean()) - 1
    df_calc['price_vs_ema200'] = (df_calc['close'] / df_calc['close'].ewm(span=EMA_SLOW_PERIOD, adjust=False).mean()) - 1
    if btc_df is not None and not btc_df.empty:
        merged_df = pd.merge(df_calc, btc_df[['btc_returns']], left_index=True, right_index=True, how='left').fillna(0)
        df_calc['btc_correlation'] = df_calc['close'].pct_change().rolling(window=30).corr(merged_df['btc_returns'])
    else:
        df_calc['btc_correlation'] = 0.0
    df_calc[f'roc_{MOMENTUM_PERIOD}'] = (df_calc['close'] / df_calc['close'].shift(MOMENTUM_PERIOD) - 1) * 100
    df_calc['roc_acceleration'] = df_calc[f'roc_{MOMENTUM_PERIOD}'].diff()
    ema_slope = df_calc['close'].ewm(span=EMA_SLOPE_PERIOD, adjust=False).mean()
    df_calc[f'ema_slope_{EMA_SLOPE_PERIOD}'] = (ema_slope - ema_slope.shift(1)) / ema_slope.shift(1).replace(0, 1e-9) * 100
    df_calc['hour_of_day'] = df_calc.index.hour
    return df_calc.astype('float32', errors='ignore')

def get_trend_for_timeframe(df: Optional[pd.DataFrame]) -> Dict[str, Any]:
    if df is None or len(df) < 26: return {"trend": "Uncertain", "rsi": -1, "adx": -1}
    try:
        close_series = df['close']
        delta = close_series.diff()
        gain = delta.clip(lower=0).ewm(com=RSI_PERIOD - 1, adjust=False).mean()
        loss = -delta.clip(upper=0).ewm(com=RSI_PERIOD - 1, adjust=False).mean()
        rsi = (100 - (100 / (1 + (gain / loss.replace(0, 1e-9))))).iloc[-1]
        high_low = df['high'] - df['low']
        high_close = (df['high'] - close_series.shift()).abs()
        low_close = (df['low'] - close_series.shift()).abs()
        tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
        atr = tr.ewm(span=ADX_PERIOD, adjust=False).mean()
        up_move = df['high'].diff(); down_move = -df['low'].diff()
        plus_dm = pd.Series(np.where((up_move > down_move) & (up_move > 0), up_move, 0.0), index=df.index)
        minus_dm = pd.Series(np.where((down_move > up_move) & (down_move > 0), down_move, 0.0), index=df.index)
        plus_di = 100 * plus_dm.ewm(span=ADX_PERIOD, adjust=False).mean() / atr.replace(0, 1e-9)
        minus_di = 100 * minus_dm.ewm(span=ADX_PERIOD, adjust=False).mean() / atr.replace(0, 1e-9)
        dx = 100 * (abs(plus_di - minus_di) / (plus_di + minus_di).replace(0, 1e-9))
        adx = dx.ewm(span=ADX_PERIOD, adjust=False).mean().iloc[-1]
        ema_fast = close_series.ewm(span=12, adjust=False).mean().iloc[-1]
        ema_slow = close_series.ewm(span=26, adjust=False).mean().iloc[-1]
        trend = "Ranging"
        if adx > 20:
            if ema_fast > ema_slow and rsi > 50: trend = "Uptrend"
            elif ema_fast < ema_slow and rsi < 50: trend = "Downtrend"
        return {"trend": trend, "rsi": float(rsi), "adx": float(adx)}
    except Exception as e:
        logger.error(f"Error in get_trend_for_timeframe: {e}")
        return {"trend": "Uncertain", "rsi": -1, "adx": -1}

def determine_market_state():
    global current_market_state, last_market_state_check
    with market_state_lock:
        if time.time() - last_market_state_check < 300: return
    logger.info("ğŸ§  [Market State] Updating market state...")
    try:
        df_15m = fetch_historical_data(BTC_SYMBOL, '15m', 2)
        df_1h = fetch_historical_data(BTC_SYMBOL, '1h', 5)
        df_4h = fetch_historical_data(BTC_SYMBOL, '4h', 15)
        state_15m = get_trend_for_timeframe(df_15m)
        state_1h = get_trend_for_timeframe(df_1h)
        state_4h = get_trend_for_timeframe(df_4h)
        trends = [state_15m['trend'], state_1h['trend'], state_4h['trend']]
        uptrends = trends.count("Uptrend")
        downtrends = trends.count("Downtrend")
        overall_regime = "RANGING"
        if uptrends == 3: overall_regime = "STRONG UPTREND"
        elif uptrends >= 2 and downtrends == 0: overall_regime = "UPTREND"
        elif downtrends == 3: overall_regime = "STRONG DOWNTREND"
        elif downtrends >= 2 and uptrends == 0: overall_regime = "DOWNTREND"
        elif "Uncertain" in trends: overall_regime = "UNCERTAIN"
        with market_state_lock:
            current_market_state = {
                "overall_regime": overall_regime,
                "details": {"15m": state_15m, "1h": state_1h, "4h": state_4h},
                "last_updated": datetime.now(timezone.utc).isoformat()
            }
            last_market_state_check = time.time()
        logger.info(f"âœ… [Market State] New state: {overall_regime} (15m: {state_15m['trend']}, 1h: {state_1h['trend']}, 4h: {state_4h['trend']})")
    except Exception as e:
        logger.error(f"âŒ [Market State] Failed to determine market state: {e}", exc_info=True)
        with market_state_lock: current_market_state['overall_regime'] = "UNCERTAIN"

def load_ml_model_bundle_from_folder(symbol: str) -> Optional[Dict[str, Any]]:
    global ml_models_cache
    model_name = f"{BASE_ML_MODEL_NAME}_{symbol}"
    if model_name in ml_models_cache:
        return ml_models_cache[model_name]
    script_dir = os.path.dirname(os.path.abspath(__file__))
    model_dir_path = os.path.join(script_dir, MODEL_FOLDER)
    if not os.path.exists(model_dir_path):
        os.makedirs(model_dir_path)
        logger.info(f"ğŸ“ Created model directory: {model_dir_path}")
    model_path = os.path.join(model_dir_path, f"{model_name}.pkl")
    if not os.path.exists(model_path):
        logger.warning(f"âš ï¸ [ML Model] Model file not found at '{model_path}'.")
        return None
    try:
        with open(model_path, 'rb') as f:
            model_bundle = pickle.load(f)
        if 'model' in model_bundle and 'scaler' in model_bundle and 'feature_names' in model_bundle:
            ml_models_cache[model_name] = model_bundle
            logger.info(f"âœ… [ML Model] Loaded model '{model_name}' successfully.")
            return model_bundle
        else:
            logger.error(f"âŒ [ML Model] Model bundle at '{model_path}' is incomplete.")
            return None
    except Exception as e:
        logger.error(f"âŒ [ML Model] Error loading model for symbol {symbol}: {e}", exc_info=True)
        return None
class TradingStrategy:
    def __init__(self, symbol: str):
        self.symbol = symbol
        model_bundle = load_ml_model_bundle_from_folder(symbol)
        self.ml_model, self.scaler, self.feature_names = (model_bundle.get('model'), model_bundle.get('scaler'), model_bundle.get('feature_names')) if model_bundle else (None, None, None)

    def get_features(self, df_15m: pd.DataFrame, df_4h: pd.DataFrame, btc_df: pd.DataFrame) -> Optional[pd.DataFrame]:
        if self.feature_names is None: return None
        try:
            df_featured = calculate_features(df_15m, btc_df)
            df_4h_features = calculate_features(df_4h, None)
            df_4h_features = df_4h_features.rename(columns=lambda c: f"{c}_4h" if c not in ['atr', 'volume'] else c, inplace=False)
            required_4h_cols = ['rsi_4h', 'price_vs_ema50_4h']
            df_featured = df_featured.join(df_4h_features[required_4h_cols], how='outer')
            df_featured.fillna(method='ffill', inplace=True)
            for col in self.feature_names:
                if col not in df_featured.columns: df_featured[col] = 0.0
            df_featured.replace([np.inf, -np.inf], np.nan, inplace=True)
            return df_featured.dropna(subset=self.feature_names)
        except Exception as e:
            logger.error(f"âŒ [{self.symbol}] Feature engineering failed: {e}", exc_info=True)
            return None

    def generate_signal(self, df_features: pd.DataFrame) -> Optional[Dict[str, Any]]:
        if not all([self.ml_model, self.scaler, self.feature_names]) or df_features.empty: return None
        try:
            last_row_ordered_df = df_features.iloc[[-1]][self.feature_names]
            features_scaled_np = self.scaler.transform(last_row_ordered_df)
            features_scaled_df = pd.DataFrame(features_scaled_np, columns=self.feature_names)
            prediction = self.ml_model.predict(features_scaled_df)[0]
            prediction_proba = self.ml_model.predict_proba(features_scaled_df)
            confidence = float(np.max(prediction_proba[0]))
            logger.info(f"â„¹ï¸ [{self.symbol}] Model predicted '{'BUY' if prediction == 1 else 'SELL/HOLD'}' with {confidence:.2%} confidence.")
            return {'prediction': int(prediction), 'confidence': confidence}
        except Exception as e:
            logger.warning(f"âš ï¸ [{self.symbol}] Signal Generation Error: {e}")
            return None

def passes_momentum_filter(last_features: pd.Series) -> bool:
    symbol = last_features.name
    roc = last_features.get(f'roc_{MOMENTUM_PERIOD}', 0)
    accel = last_features.get('roc_acceleration', 0)
    slope = last_features.get(f'ema_slope_{EMA_SLOPE_PERIOD}', 0)
    if roc > 0 and accel >= 0 and slope > 0:
        return True
    log_rejection(symbol, "Momentum Filter", {
        "ROC": f"{roc:.2f} (Req: > 0)",
        "Acceleration": f"{accel:.4f} (Req: >= 0)",
        "Slope": f"{slope:.6f} (Req: > 0)"
    })
    return False

def passes_speed_filter(last_features: pd.Series) -> bool:
    symbol = last_features.name
    with market_state_lock: regime = current_market_state.get("overall_regime", "RANGING")
    if regime in ["DOWNTREND", "STRONG DOWNTREND"]:
        log_rejection(symbol, "Speed Filter", {"detail": f"Disabled due to market regime: {regime}"})
        return True
    if regime == "STRONG UPTREND": adx_threshold, rel_vol_threshold, rsi_min, rsi_max = (25.0, 0.6, 45.0, 85.0)
    elif regime == "UPTREND": adx_threshold, rel_vol_threshold, rsi_min, rsi_max = (22.0, 0.5, 40.0, 80.0)
    else: adx_threshold, rel_vol_threshold, rsi_min, rsi_max = (18.0, 0.2, 30.0, 80.0)
    adx, rel_vol, rsi = last_features.get('adx', 0), last_features.get('relative_volume', 0), last_features.get('rsi', 0)
    if (adx >= adx_threshold and rel_vol >= rel_vol_threshold and rsi_min <= rsi < rsi_max): return True
    log_rejection(symbol, "Speed Filter", {"Regime": regime, "ADX": f"{adx:.2f} (Req: >{adx_threshold})", "Volume": f"{rel_vol:.2f} (Req: >{rel_vol_threshold})", "RSI": f"{rsi:.2f} (Req: {rsi_min}-{rsi_max})"})
    return False

def calculate_tp_sl(symbol: str, entry_price: float, last_atr: float) -> Optional[Dict[str, Any]]:
    if last_atr <= 0:
        log_rejection(symbol, "Invalid ATR for Fallback", {"detail": "ATR is zero or negative"})
        return None
    fallback_tp = entry_price + (last_atr * ATR_FALLBACK_TP_MULTIPLIER)
    fallback_sl = entry_price - (last_atr * ATR_FALLBACK_SL_MULTIPLIER)
    return {'target_price': fallback_tp, 'stop_loss': fallback_sl, 'source': 'ATR_Fallback'}

def handle_price_update_message(msg: List[Dict[str, Any]]) -> None:
    if not isinstance(msg, list) or not redis_client: return
    try:
        price_updates = {item.get('s'): float(item.get('c', 0)) for item in msg if item.get('s') and item.get('c')}
        if price_updates: redis_client.hset(REDIS_PRICES_HASH_NAME, mapping=price_updates)
    except Exception as e: logger.error(f"âŒ [WebSocket Price Updater] Error: {e}", exc_info=True)

def initiate_signal_closure(symbol: str, signal_to_close: Dict, status: str, closing_price: float):
    signal_id = signal_to_close.get('id')
    if not signal_id:
        logger.error(f"âŒ [Closure] Attempted to close a signal without an ID for symbol {symbol}")
        return
    with closure_lock:
        if signal_id in signals_pending_closure:
            logger.warning(f"âš ï¸ [Closure] Closure for signal {signal_id} ({symbol}) already in progress.")
            return
        signals_pending_closure.add(signal_id)
    with signal_cache_lock: open_signals_cache.pop(symbol, None)
    logger.info(f"â„¹ï¸ [Closure] Starting closure thread for signal {signal_id} ({symbol}) with status '{status}'.")
    Thread(target=close_signal, args=(signal_to_close, status, closing_price, "initiator")).start()

def update_signal_peak_price_in_db(signal_id: int, new_peak_price: float):
    if not check_db_connection() or not conn:
        logger.error(f"âŒ [DB Peak Update] Cannot update peak for signal {signal_id}, DB connection is down.")
        return
    try:
        with conn.cursor() as cur:
            cur.execute("UPDATE signals SET current_peak_price = %s WHERE id = %s;", (new_peak_price, signal_id))
        conn.commit()
        logger.debug(f"ğŸ’¾ [DB Peak Update] Saved new peak price {new_peak_price} for signal {signal_id}.")
    except Exception as e:
        logger.error(f"âŒ [DB Peak Update] Failed to update peak price for signal {signal_id}: {e}")
        if conn: conn.rollback()

def trade_monitoring_loop():
    global last_api_check_time
    logger.info("âœ… [Trade Monitor] Starting trade monitoring loop.")
    while True:
        try:
            with signal_cache_lock:
                signals_to_check = dict(open_signals_cache)
            if not signals_to_check or not redis_client or not client:
                time.sleep(1)
                continue
            perform_direct_api_check = (time.time() - last_api_check_time) > DIRECT_API_CHECK_INTERVAL
            if perform_direct_api_check:
                last_api_check_time = time.time()
            symbols_to_fetch = list(signals_to_check.keys())
            redis_prices_list = redis_client.hmget(REDIS_PRICES_HASH_NAME, symbols_to_fetch)
            redis_prices = {symbol: price for symbol, price in zip(symbols_to_fetch, redis_prices_list)}
            for symbol, signal in signals_to_check.items():
                signal_id = signal.get('id')
                if not signal_id: continue
                with closure_lock:
                    if signal_id in signals_pending_closure:
                        continue
                price = None
                if perform_direct_api_check:
                    try:
                        price = float(client.get_symbol_ticker(symbol=symbol)['price'])
                    except Exception: pass
                if not price and redis_prices.get(symbol):
                    price = float(redis_prices[symbol])
                if not price: continue
                with signal_cache_lock:
                    if symbol in open_signals_cache:
                        open_signals_cache[symbol]['current_price'] = price
                        open_signals_cache[symbol]['pnl_pct'] = ((price / float(signal['entry_price'])) - 1) * 100
                target_price = float(signal.get('target_price', 0))
                original_stop_loss = float(signal.get('stop_loss', 0))
                effective_stop_loss = original_stop_loss
                if USE_TRAILING_STOP_LOSS:
                    entry_price = float(signal.get('entry_price', 0))
                    activation_price = entry_price * (1 + TRAILING_ACTIVATION_PROFIT_PERCENT / 100)
                    if price > activation_price:
                        current_peak = float(signal.get('current_peak_price', entry_price))
                        if price > current_peak:
                            with signal_cache_lock:
                                if symbol in open_signals_cache:
                                    open_signals_cache[symbol]['current_peak_price'] = price
                            now = time.time()
                            last_update = LAST_PEAK_UPDATE_TIME.get(signal_id, 0)
                            if now - last_update > PEAK_UPDATE_COOLDOWN:
                                update_signal_peak_price_in_db(signal_id, price)
                                LAST_PEAK_UPDATE_TIME[signal_id] = now
                            current_peak = price
                        trailing_stop_price = current_peak * (1 - TRAILING_DISTANCE_PERCENT / 100)
                        if trailing_stop_price > effective_stop_loss:
                            logger.info(f"ğŸ“ˆ [Trailing SL] {symbol} new peak: {current_peak:.4f}. Adjusted SL to: {trailing_stop_price:.4f}")
                            effective_stop_loss = trailing_stop_price
                status_to_set = None
                if price >= target_price:
                    status_to_set = 'target_hit'
                elif price <= effective_stop_loss:
                    status_to_set = 'stop_loss_hit'
                if status_to_set:
                    logger.info(f"âœ… [TRIGGER] ID:{signal_id} | {symbol} | Condition '{status_to_set}' met at price {price}.")
                    initiate_signal_closure(symbol, signal, status_to_set, price)
            time.sleep(0.2)
        except Exception as e:
            logger.error(f"âŒ [Trade Monitor] Critical error: {e}", exc_info=True)
            time.sleep(5)

def send_telegram_message(target_chat_id: str, text: str, reply_markup: Optional[Dict] = None) -> bool:
    if not TELEGRAM_TOKEN or not target_chat_id: return False
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {'chat_id': str(target_chat_id), 'text': text, 'parse_mode': 'Markdown'}
    if reply_markup: payload['reply_markup'] = json.dumps(reply_markup)
    try:
        response = requests.post(url, json=payload, timeout=10)
        if response.status_code == 200: return True
        else: logger.error(f"âŒ [Telegram] Failed to send message. Status: {response.status_code}, Response: {response.text}"); return False
    except requests.exceptions.RequestException as e: logger.error(f"âŒ [Telegram] Request failed: {e}"); return False

def send_new_signal_alert(signal_data: Dict[str, Any]):
    symbol = signal_data['symbol']; entry = float(signal_data['entry_price']); target = float(signal_data['target_price']); sl = float(signal_data['stop_loss'])
    profit_pct = ((target / entry) - 1) * 100
    risk_pct = abs(((entry / sl) - 1) * 100) if sl > 0 else 0
    rrr = profit_pct / risk_pct if risk_pct > 0 else 0
    with market_state_lock: market_regime = current_market_state.get('overall_regime', 'N/A')
    confidence_display = signal_data['signal_details'].get('ML_Confidence_Display', 'N/A')
    message = (f"ğŸ’¡ *ØªÙˆØµÙŠØ© ØªØ¯Ø§ÙˆÙ„ Ø¬Ø¯ÙŠØ¯Ø©* ğŸ’¡\n\n*Ø§Ù„Ø¹Ù…Ù„Ø©:* `{symbol}`\n*Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚:* `{market_regime}`\n\n"
               f"*Ø§Ù„Ø¯Ø®ÙˆÙ„:* `{entry:,.8g}`\n*Ø§Ù„Ù‡Ø¯Ù:* `{target:,.8g}`\n*ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©:* `{sl:,.8g}`\n\n"
               f"*Ø§Ù„Ø±Ø¨Ø­ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:* `{profit_pct:.2f}%`\n*Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©/Ø§Ù„Ø¹Ø§Ø¦Ø¯:* `1:{rrr:.2f}`\n\n"
               f"*Ø«Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:* `{confidence_display}`")
    reply_markup = {"inline_keyboard": [[{"text": "ğŸ“Š ÙØªØ­ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…", "url": WEBHOOK_URL or '#'}]]}
    if send_telegram_message(CHAT_ID, message, reply_markup):
        log_and_notify('info', f"New Signal Alert Sent: {symbol} in {market_regime} market", "NEW_SIGNAL")

def send_trade_update_alert(signal_data: Dict[str, Any], old_signal_data: Dict[str, Any]):
    symbol = signal_data['symbol']
    old_target = float(old_signal_data['target_price'])
    new_target = float(signal_data['target_price'])
    old_sl = float(old_signal_data['stop_loss'])
    new_sl = float(signal_data['stop_loss'])
    old_conf = old_signal_data['signal_details'].get('ML_Confidence_Display', 'N/A')
    new_conf = signal_data['signal_details'].get('ML_Confidence_Display', 'N/A')
    
    message = (f"ğŸ”„ *ØªØ­Ø¯ÙŠØ« ØµÙÙ‚Ø© (ØªØ¹Ø²ÙŠØ²)* ğŸ”„\n\n"
               f"*Ø§Ù„Ø¹Ù…Ù„Ø©:* `{symbol}`\n\n"
               f"*Ø§Ù„Ø«Ù‚Ø©:* `{old_conf}` â¬…ï¸ `{new_conf}`\n"
               f"*Ø§Ù„Ù‡Ø¯Ù:* `{old_target:,.8g}` â¬…ï¸ `{new_target:,.8g}`\n"
               f"*Ø§Ù„ÙˆÙ‚Ù:* `{old_sl:,.8g}` â¬…ï¸ `{new_sl:,.8g}`\n\n"
               f"ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„ØµÙÙ‚Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¥Ø´Ø§Ø±Ø© Ø´Ø±Ø§Ø¡ Ø£Ù‚ÙˆÙ‰.")
    reply_markup = {"inline_keyboard": [[{"text": "ğŸ“Š ÙØªØ­ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…", "url": WEBHOOK_URL or '#'}]]}
    if send_telegram_message(CHAT_ID, message, reply_markup):
        log_and_notify('info', f"Updated Signal: {symbol} due to stronger signal.", "UPDATE_SIGNAL")

# --- MODIFICATION START: New function to save signal in the background ---
# --- ØªØ¹Ø¯ÙŠÙ„: Ø¯Ø§Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù„Ø­ÙØ¸ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ© ---
def save_and_cache_signal(signal_to_save: Dict[str, Any]):
    """
    Saves the signal to the database and caches it.
    If it fails, sends a cancellation alert.
    This is designed to be run in a background thread.
    
    ØªÙ‚ÙˆÙ… Ø¨Ø­ÙØ¸ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ°Ø§ÙƒØ±Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª.
    Ø¥Ø°Ø§ ÙØ´Ù„Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©ØŒ ØªØ±Ø³Ù„ Ø¥Ø´Ø¹Ø§Ø± Ø¥Ù„ØºØ§Ø¡.
    Ù…ØµÙ…Ù…Ø© Ù„Ù„Ø¹Ù…Ù„ ÙÙŠ thread Ù…Ù†ÙØµÙ„ ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©.
    """
    saved_signal = insert_signal_into_db(signal_to_save)
    if saved_signal:
        with signal_cache_lock:
            open_signals_cache[saved_signal['symbol']] = saved_signal
        logger.info(f"âœ… [DB Save] Successfully saved and cached signal ID {saved_signal.get('id')} for {saved_signal['symbol']}")
    else:
        logger.critical(f"âŒ [DB Save] FAILED to save signal for {signal_to_save['symbol']} after alert was sent. Sending cancellation.")
        cancellation_message = (
            f"âš ï¸ *Ø¥Ù„ØºØ§Ø¡ ØªÙˆØµÙŠØ© - Ø®Ø·Ø£ ÙÙ†ÙŠ* âš ï¸\n\n"
            f"*Ø§Ù„Ø¹Ù…Ù„Ø©:* `{signal_to_save['symbol']}`\n\n"
            f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙ†ÙŠ Ø£Ø«Ù†Ø§Ø¡ Ø­ÙØ¸ Ø§Ù„ØªÙˆØµÙŠØ© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. "
            f"ÙŠØ±Ø¬Ù‰ ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø¥Ø´Ø¹Ø§Ø± Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„Ø©."
        )
        send_telegram_message(CHAT_ID, cancellation_message)
        log_and_notify('critical', f"Sent cancellation for {signal_to_save['symbol']} due to DB save failure.", "SIGNAL_CANCELLED")
# --- MODIFICATION END ---

def insert_signal_into_db(signal: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    if not check_db_connection() or not conn: return None
    try:
        entry = float(signal['entry_price']); target = float(signal['target_price']); sl = float(signal['stop_loss'])
        with conn.cursor() as cur:
            cur.execute("INSERT INTO signals (symbol, entry_price, target_price, stop_loss, strategy_name, signal_details, current_peak_price) VALUES (%s, %s, %s, %s, %s, %s, %s) RETURNING id;",
                        (signal['symbol'], entry, target, sl, signal.get('strategy_name'), json.dumps(signal.get('signal_details', {})), entry))
            signal['id'] = cur.fetchone()['id']
        conn.commit()
        logger.info(f"âœ… [DB] Inserted signal {signal['id']} for {signal['symbol']}.")
        return signal
    except Exception as e:
        logger.error(f"âŒ [Insert] Error inserting signal for {signal['symbol']}: {e}", exc_info=True)
        if conn: conn.rollback()
        return None

def update_signal_in_db(signal_id: int, new_data: Dict[str, Any]) -> bool:
    if not check_db_connection() or not conn: return False
    try:
        target = float(new_data['target_price'])
        sl = float(new_data['stop_loss'])
        details = json.dumps(new_data.get('signal_details', {}))
        
        with conn.cursor() as cur:
            cur.execute("""
                UPDATE signals 
                SET target_price = %s, stop_loss = %s, signal_details = %s, status = 'updated'
                WHERE id = %s AND status IN ('open', 'updated');
            """, (target, sl, details, signal_id))
            if cur.rowcount == 0:
                logger.warning(f"âš ï¸ [DB Update] Signal {signal_id} not found or already closed. No update performed.")
                return False
        conn.commit()
        logger.info(f"âœ… [DB] Updated signal {signal_id} for {new_data['symbol']}.")
        return True
    except Exception as e:
        logger.error(f"âŒ [Update] Error updating signal {signal_id}: {e}", exc_info=True)
        if conn: conn.rollback()
        return False

def close_signal(signal: Dict, status: str, closing_price: float, closed_by: str):
    signal_id = signal.get('id'); symbol = signal.get('symbol')
    logger.info(f"Initiating closure for signal {signal_id} ({symbol}) with status '{status}'")
    try:
        if not check_db_connection() or not conn: raise OperationalError("DB connection failed.")
        db_closing_price = float(closing_price); entry_price = float(signal['entry_price'])
        profit_pct = ((db_closing_price / entry_price) - 1) * 100
        with conn.cursor() as cur:
            cur.execute("UPDATE signals SET status = %s, closing_price = %s, closed_at = NOW(), profit_percentage = %s WHERE id = %s AND status IN ('open', 'updated');",
                        (status, db_closing_price, profit_pct, signal_id))
            if cur.rowcount == 0: logger.warning(f"âš ï¸ [DB Close] Signal {signal_id} was already closed or not found."); return
        conn.commit()
        status_map = {'target_hit': 'âœ… ØªØ­Ù‚Ù‚ Ø§Ù„Ù‡Ø¯Ù', 'stop_loss_hit': 'ğŸ›‘ Ø¶Ø±Ø¨ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø©', 'manual_close': 'ğŸ–ï¸ Ø¥ØºÙ„Ø§Ù‚ ÙŠØ¯ÙˆÙŠ', 'closed_by_sell_signal': 'ğŸ”´ Ø¥ØºÙ„Ø§Ù‚ Ø¨Ø¥Ø´Ø§Ø±Ø© Ø¨ÙŠØ¹'}
        status_message = status_map.get(status, status)
        alert_msg = (f"*{status_message}*\n*Ø§Ù„Ø¹Ù…Ù„Ø©:* `{symbol}`\n*Ø§Ù„Ø±Ø¨Ø­:* `{profit_pct:+.2f}%`")
        send_telegram_message(CHAT_ID, alert_msg)
        log_and_notify('info', f"{status_message}: {symbol} | Profit: {profit_pct:+.2f}%", 'CLOSE_SIGNAL')
        logger.info(f"âœ… [DB Close] Signal {signal_id} closed successfully.")
    except Exception as e:
        logger.error(f"âŒ [DB Close] Critical error closing signal {signal_id}: {e}", exc_info=True)
        if conn: conn.rollback()
        if symbol:
            with signal_cache_lock:
                if symbol not in open_signals_cache: open_signals_cache[symbol] = signal
    finally:
        with closure_lock: signals_pending_closure.discard(signal_id)

def load_open_signals_to_cache():
    if not check_db_connection() or not conn: return
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT * FROM signals WHERE status IN ('open', 'updated');")
            open_signals = cur.fetchall()
            with signal_cache_lock:
                open_signals_cache.clear()
                for signal in open_signals: open_signals_cache[signal['symbol']] = dict(signal)
            logger.info(f"âœ… [Loading] Loaded {len(open_signals)} open signals.")
    except Exception as e: logger.error(f"âŒ [Loading] Failed to load open signals: {e}")

def load_notifications_to_cache():
    if not check_db_connection() or not conn: return
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT * FROM notifications ORDER BY timestamp DESC LIMIT 50;")
            recent = cur.fetchall()
            with notifications_lock:
                notifications_cache.clear()
                for n in reversed(recent): n['timestamp'] = n['timestamp'].isoformat(); notifications_cache.appendleft(dict(n))
            logger.info(f"âœ… [Loading] Loaded {len(notifications_cache)} notifications.")
    except Exception as e: logger.error(f"âŒ [Loading] Failed to load notifications: {e}")

def get_btc_data_for_bot() -> Optional[pd.DataFrame]:
    btc_data = fetch_historical_data(BTC_SYMBOL, SIGNAL_GENERATION_TIMEFRAME, SIGNAL_GENERATION_LOOKBACK_DAYS)
    if btc_data is not None: btc_data['btc_returns'] = btc_data['close'].pct_change()
    return btc_data

def main_loop():
    logger.info("[Main Loop] Waiting for initialization...")
    time.sleep(15)
    if not validated_symbols_to_scan: log_and_notify("critical", "No validated symbols to scan.", "SYSTEM"); return
    log_and_notify("info", f"Starting scan loop for {len(validated_symbols_to_scan)} symbols.", "SYSTEM")
    while True:
        try:
            determine_market_state()
            with market_state_lock: market_regime = current_market_state.get("overall_regime", "UNCERTAIN")
            if USE_BTC_TREND_FILTER and market_regime in ["DOWNTREND", "STRONG DOWNTREND"]:
                log_rejection("ALL", "BTC Trend Filter", {"detail": f"Scan paused due to market regime: {market_regime}"})
                time.sleep(300); continue
            
            btc_data = get_btc_data_for_bot()
            for symbol in validated_symbols_to_scan:
                try:
                    with signal_cache_lock:
                        open_trade = open_signals_cache.get(symbol)
                        open_trade_count = len(open_signals_cache)

                    df_15m = fetch_historical_data(symbol, SIGNAL_GENERATION_TIMEFRAME, SIGNAL_GENERATION_LOOKBACK_DAYS)
                    if df_15m is None: continue
                    strategy = TradingStrategy(symbol)
                    if not all([strategy.ml_model, strategy.scaler, strategy.feature_names]): continue
                    df_4h = fetch_historical_data(symbol, HIGHER_TIMEFRAME, SIGNAL_GENERATION_LOOKBACK_DAYS * 4)
                    if df_4h is None: continue
                    df_features = strategy.get_features(df_15m, df_4h, btc_data)
                    if df_features is None or df_features.empty: continue
                    signal_info = strategy.generate_signal(df_features)
                    
                    if not signal_info or not client: continue

                    # =================================================================================
                    # === CRITICAL FIX: Always fetch the latest price directly from the API         ===
                    # === before generating a signal to ensure the entry price is 100% accurate.    ===
                    # === Ø¥ØµÙ„Ø§Ø­ Ø­Ø§Ø³Ù…: Ø§Ø­ØµÙ„ Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø£Ø­Ø¯Ø« Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© (API)  ===
                    # === Ù‚Ø¨Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø£ÙŠ Ø¥Ø´Ø§Ø±Ø© Ù„Ø¶Ù…Ø§Ù† Ø¯Ù‚Ø© Ø³Ø¹Ø± Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø¨Ù†Ø³Ø¨Ø© 100%.                       ===
                    # =================================================================================
                    try:
                        current_price = float(client.get_symbol_ticker(symbol=symbol)['price'])
                    except Exception as api_price_err:
                        logger.warning(f"âš ï¸ [{symbol}] Could not fetch live price from API for signal generation. Skipping. Error: {api_price_err}")
                        continue
                    
                    prediction, confidence = signal_info['prediction'], signal_info['confidence']
                    
                    if prediction == 1 and confidence >= BUY_CONFIDENCE_THRESHOLD:
                        last_features = df_features.iloc[-1]; last_features.name = symbol
                        
                        if open_trade:
                            old_confidence_raw = open_trade.get('signal_details', {}).get('ML_Confidence', 0.0)
                            
                            old_confidence = 0.0
                            try:
                                if isinstance(old_confidence_raw, str):
                                    cleaned_str = old_confidence_raw.strip().replace('%', '')
                                    numeric_val = float(cleaned_str)
                                    old_confidence = numeric_val / 100.0 if numeric_val > 1 else numeric_val
                                elif old_confidence_raw is not None:
                                    old_confidence = float(old_confidence_raw)
                            except (ValueError, TypeError) as e:
                                logger.warning(f"[{symbol}] Could not parse old confidence value '{old_confidence_raw}'. Defaulting to 0.0. Error: {e}")
                                old_confidence = 0.0

                            if confidence > old_confidence + MIN_CONFIDENCE_INCREASE_FOR_UPDATE:
                                logger.info(f"ğŸ”„ [{symbol}] Stronger BUY signal. Old confidence: {old_confidence:.2%}, New: {confidence:.2%}. Evaluating update...")
                                
                                if USE_SPEED_FILTER and not passes_speed_filter(last_features): continue
                                if USE_MOMENTUM_FILTER and not passes_momentum_filter(last_features): continue
                                
                                last_atr = last_features.get('atr', 0)
                                tp_sl_data = calculate_tp_sl(symbol, current_price, last_atr)
                                if not tp_sl_data: continue
                                
                                updated_signal_data = {
                                    'symbol': symbol, 'target_price': tp_sl_data['target_price'], 'stop_loss': tp_sl_data['stop_loss'],
                                    'signal_details': {
                                        'ML_Confidence': confidence, 'ML_Confidence_Display': f"{confidence:.2%}",
                                        'Original_Confidence': old_confidence, 'Update_Reason': 'Reinforcement Signal'
                                    }
                                }
                                
                                if update_signal_in_db(open_trade['id'], updated_signal_data):
                                    with signal_cache_lock:
                                        open_signals_cache[symbol].update(updated_signal_data)
                                        open_signals_cache[symbol]['status'] = 'updated'
                                    send_trade_update_alert(updated_signal_data, open_trade)
                                else:
                                    logger.error(f"âŒ [{symbol}] Failed to update signal in DB, aborting.")
                            else:
                                logger.debug(f"[{symbol}] New BUY signal not strong enough to update existing trade.")
                            continue

                        if open_trade_count < MAX_OPEN_TRADES:
                            if USE_SPEED_FILTER and not passes_speed_filter(last_features): continue
                            if USE_MOMENTUM_FILTER and not passes_momentum_filter(last_features): continue
                            
                            last_atr = last_features.get('atr', 0)
                            volatility = (last_atr / current_price * 100)
                            if USE_MIN_VOLATILITY_FILTER and volatility < MIN_VOLATILITY_PERCENT:
                                log_rejection(symbol, "Low Volatility", {"volatility": f"{volatility:.2f}%", "min": f"{MIN_VOLATILITY_PERCENT}%"}); continue
                            if USE_BTC_CORRELATION_FILTER and market_regime in ["UPTREND", "STRONG UPTREND"]:
                                correlation = last_features.get('btc_correlation', 0)
                                if correlation < MIN_BTC_CORRELATION:
                                    log_rejection(symbol, "BTC Correlation", {"corr": f"{correlation:.2f}", "min": f"{MIN_BTC_CORRELATION}"}); continue
                            
                            tp_sl_data = calculate_tp_sl(symbol, current_price, last_atr)
                            if not tp_sl_data: continue
                            
                            new_signal = {
                                'symbol': symbol, 'strategy_name': BASE_ML_MODEL_NAME, 
                                'signal_details': {'ML_Confidence': confidence, 'ML_Confidence_Display': f"{confidence:.2%}"}, 
                                'entry_price': current_price, **tp_sl_data
                            }

                            if USE_RRR_FILTER:
                                risk = current_price - float(new_signal['stop_loss']); reward = float(new_signal['target_price']) - current_price
                                if risk <= 0 or reward <= 0 or (reward / risk) < MIN_RISK_REWARD_RATIO:
                                    log_rejection(symbol, "RRR Filter", {"rrr": f"{(reward/risk):.2f}" if risk > 0 else "N/A"}); continue
                            
                            logger.info(f"ğŸš€ [{symbol}] Signal passed all filters. Sending alert immediately.")
                            send_new_signal_alert(new_signal)
                            Thread(target=save_and_cache_signal, args=(new_signal,)).start()

                    time.sleep(2)
                except Exception as e: logger.error(f"âŒ [Processing Error] {symbol}: {e}", exc_info=True)
            logger.info("â„¹ï¸ [End of Cycle] Scan cycle finished. Waiting..."); time.sleep(300)
        except (KeyboardInterrupt, SystemExit): break
        except Exception as main_err: log_and_notify("error", f"Error in main loop: {main_err}", "SYSTEM"); time.sleep(120)

# ---------------------- ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª Flask (ØªÙ… Ø§Ù„Ø¥ØµÙ„Ø§Ø­) ----------------------
app = Flask(__name__)
CORS(app)

def get_fear_and_greed_index() -> Dict[str, Any]:
    try:
        response = requests.get("https://api.alternative.me/fng/?limit=1", timeout=10).json()
        return {"value": int(response['data'][0]['value']), "classification": response['data'][0]['value_classification']}
    except Exception as e:
        logger.warning(f"âš ï¸ [F&G Index] Could not fetch Fear & Greed index: {e}")
        return {"value": -1, "classification": "Error"}

def check_api_status() -> bool:
    if not client: return False
    try: client.ping(); return True
    except Exception: return False

@app.route('/')
def home():
    return render_template_string(get_dashboard_html())

@app.route('/api/market_status')
def get_market_status():
    with market_state_lock: state_copy = dict(current_market_state)
    return jsonify({
        "fear_and_greed": get_fear_and_greed_index(), "market_state": state_copy,
        "db_ok": check_db_connection(), "api_ok": check_api_status()
    })

@app.route('/api/stats')
def get_stats():
    if not check_db_connection() or not conn:
        logger.error("âŒ [API Stats] DB connection check failed.")
        return jsonify({"error": "DB connection failed"}), 500
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT status, profit_percentage FROM signals;")
            all_signals = cur.fetchall()
        open_trades_count = sum(1 for s in all_signals if s.get('status') in ['open', 'updated'])
        closed_trades = [s for s in all_signals if s.get('status') not in ['open', 'updated'] and s.get('profit_percentage') is not None]
        total_net_profit_usdt = 0.0
        win_rate = 0.0
        profit_factor_val = 0.0
        if closed_trades:
            total_net_profit_usdt = sum(
                ((float(t['profit_percentage']) - (2 * TRADING_FEE_PERCENT)) / 100) * HYPOTHETICAL_TRADE_SIZE_USDT
                for t in closed_trades
            )
            wins = sum(1 for s in closed_trades if float(s['profit_percentage']) > 0)
            win_rate = (wins / len(closed_trades) * 100) if closed_trades else 0.0
            total_profit_from_wins = sum(float(s['profit_percentage']) for s in closed_trades if float(s['profit_percentage']) > 0)
            total_loss_from_losses = abs(sum(float(s['profit_percentage']) for s in closed_trades if float(s['profit_percentage']) < 0))
            if total_loss_from_losses > 0:
                profit_factor_val = total_profit_from_wins / total_loss_from_losses
            elif total_profit_from_wins > 0:
                profit_factor_val = "Infinity"
        return jsonify({
            "open_trades_count": open_trades_count,
            "net_profit_usdt": total_net_profit_usdt,
            "win_rate": win_rate,
            "profit_factor": profit_factor_val
        })
    except Exception as e:
        logger.error(f"âŒ [API Stats] Critical error: {e}", exc_info=True)
        return jsonify({"error": "An internal error occurred while calculating stats."}), 500

@app.route('/api/profit_curve')
def get_profit_curve():
    if not check_db_connection(): return jsonify({"error": "DB connection failed"}), 500
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT closed_at, profit_percentage FROM signals WHERE status NOT IN ('open', 'updated') AND profit_percentage IS NOT NULL AND closed_at IS NOT NULL ORDER BY closed_at ASC;")
            trades = cur.fetchall()
        
        curve_data = []
        cumulative_profit = 0.0
        
        start_time = (trades[0]['closed_at'] - timedelta(minutes=1)).isoformat() if trades else datetime.now(timezone.utc).isoformat()
        curve_data.append({"timestamp": start_time, "profit_range": [0.0, 0.0], "profit_change": 0.0})

        for trade in trades:
            profit_change = float(trade['profit_percentage'])
            start_profit = cumulative_profit
            end_profit = cumulative_profit + profit_change
            curve_data.append({
                "timestamp": trade['closed_at'].isoformat(),
                "profit_range": [start_profit, end_profit],
                "profit_change": profit_change
            })
            cumulative_profit = end_profit
            
        return jsonify(curve_data)
    except Exception as e:
        logger.error(f"âŒ [API Profit Curve] Error: {e}", exc_info=True)
        return jsonify({"error": "Error fetching profit curve data"}), 500

@app.route('/api/signals')
def get_signals():
    if not check_db_connection() or not redis_client: return jsonify({"error": "Service connection failed"}), 500
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT * FROM signals ORDER BY CASE WHEN status IN ('open', 'updated') THEN 0 ELSE 1 END, id DESC;")
            all_signals = [dict(s) for s in cur.fetchall()]
        open_symbols = [s['symbol'] for s in all_signals if s['status'] in ('open', 'updated')]
        if open_symbols:
            prices_list = redis_client.hmget(REDIS_PRICES_HASH_NAME, open_symbols)
            current_prices = {symbol: float(p) if p else None for symbol, p in zip(open_symbols, prices_list)}
            for s in all_signals:
                if s['status'] in ('open', 'updated'):
                    price = current_prices.get(s['symbol'])
                    s['current_price'] = price
                    if price and s.get('entry_price'): s['pnl_pct'] = ((price / float(s['entry_price'])) - 1) * 100
        return jsonify(all_signals)
    except Exception as e: return jsonify({"error": str(e)}), 500

@app.route('/api/close/<int:signal_id>', methods=['POST'])
def manual_close_signal_api(signal_id):
    if not client: return jsonify({"error": "Binance Client not available"}), 500
    with closure_lock:
        if signal_id in signals_pending_closure: return jsonify({"error": "Signal is already being closed"}), 409
    if not check_db_connection(): return jsonify({"error": "DB connection failed"}), 500
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT * FROM signals WHERE id = %s AND status IN ('open', 'updated');", (signal_id,))
            signal_to_close = cur.fetchone()
        if not signal_to_close: return jsonify({"error": "Signal not found or already closed"}), 404
        symbol = dict(signal_to_close)['symbol']
        try:
            price = float(client.get_symbol_ticker(symbol=symbol)['price'])
        except Exception as e:
            logger.error(f"âŒ [API Close] Could not fetch price for {symbol}: {e}")
            return jsonify({"error": f"Could not fetch price for {symbol}"}), 500
        initiate_signal_closure(symbol, dict(signal_to_close), 'manual_close', price)
        return jsonify({"message": f"ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø·Ù„Ø¨ Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„ØµÙÙ‚Ø© {signal_id}..."})
    except Exception as e:
        logger.error(f"âŒ [API Close] Error: {e}", exc_info=True)
        return jsonify({"error": str(e)}), 500

@app.route('/api/notifications')
def get_notifications():
    with notifications_lock: return jsonify(list(notifications_cache))

@app.route('/api/rejection_logs')
def get_rejection_logs():
    with rejection_logs_lock: return jsonify(list(rejection_logs_cache))

def run_flask():
    port_str = os.environ.get('PORT', '10000')
    try:
        port = int(port_str)
    except (ValueError, TypeError):
        logger.error(f"âŒ Invalid PORT environment variable: '{port_str}'. Defaulting to 10000.")
        port = 10000
    host = "0.0.0.0"
    logger.info(f"âœ… Preparing to start dashboard on {host}:{port}")
    logger.info("ğŸ¤– Starting background bot services in a separate thread...")
    initialization_thread = Thread(target=initialize_bot_services, daemon=True)
    initialization_thread.start()
    logger.info("ğŸŒ Starting web server...")
    try:
        from waitress import serve
        logger.info("âœ… Found 'waitress', starting production server...")
        serve(app, host=host, port=port, threads=8)
    except ImportError:
        logger.warning("âš ï¸ 'waitress' not found. Using Flask's development server (NOT recommended for production).")
        app.run(host=host, port=port)

# ---------------------- Ù†Ù‚Ø·Ø© Ø§Ù†Ø·Ù„Ø§Ù‚ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ ----------------------
def run_websocket_manager():
    """Manages the WebSocket connection for real-time price updates."""
    if not client or not validated_symbols_to_scan:
        logger.error("âŒ [WebSocket] Cannot start WebSocket manager: Client or symbols not initialized.")
        return
    logger.info("ğŸ“ˆ [WebSocket] Starting WebSocket Manager for price streams...")
    twm = ThreadedWebsocketManager(api_key=API_KEY, api_secret=API_SECRET)
    twm.start()
    
    chunk_size = 50 
    symbol_chunks = [validated_symbols_to_scan[i:i + chunk_size] for i in range(0, len(validated_symbols_to_scan), chunk_size)]
    
    for i, chunk in enumerate(symbol_chunks):
        streams = [f"{s.lower()}@miniTicker" for s in chunk]
        twm.start_multiplex_socket(callback=handle_price_update_message, streams=streams)
        logger.info(f"âœ… [WebSocket] Subscribed to price stream chunk {i+1}/{len(symbol_chunks)}.")

    twm.join()

def initialize_bot_services():
    global client, validated_symbols_to_scan
    logger.info("ğŸ¤– [Bot Services] Starting background initialization...")
    try:
        client = Client(API_KEY, API_SECRET)
        init_db()
        init_redis()
        load_open_signals_to_cache()
        load_notifications_to_cache()
        Thread(target=determine_market_state, daemon=True).start()
        validated_symbols_to_scan = get_validated_symbols()
        if not validated_symbols_to_scan:
            logger.critical("âŒ No validated symbols to scan. Loops will not start."); return
        Thread(target=run_websocket_manager, daemon=True).start()
        Thread(target=trade_monitoring_loop, daemon=True).start()
        Thread(target=main_loop, daemon=True).start()
        logger.info("âœ… [Bot Services] All background services started successfully.")
    except Exception as e:
        log_and_notify("critical", f"A critical error occurred during initialization: {e}", "SYSTEM")
        exit(1)

if __name__ == "__main__":
    logger.info("======================================================")
    logger.info("ğŸš€ LAUNCHING TRADING BOT & DASHBOARD APPLICATION ğŸš€")
    logger.info("======================================================")
    run_flask()
    logger.info("ğŸ‘‹ [Shutdown] Application has been shut down."); os._exit(0)
