import os # Ù‡Ø°Ø§ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§ ÙÙŠ Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ù…Ù„Ù
import time
import json
import logging
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, Tuple

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø´ØªØ±ÙƒØ© Ù…Ù† Ù…Ù„Ù Ø§Ù„Ù…Ø±Ø§ÙÙ‚
from utils import (
    init_db, check_db_connection, initialize_binance_client,
    fetch_historical_data, calculate_rsi_indicator,
    get_btc_trend_4h,
    save_ml_model_to_db, convert_np_values, logger,
    RSI_PERIOD, VOLUME_LOOKBACK_CANDLES, RSI_MOMENTUM_LOOKBACK_CANDLES,
    BASE_ML_MODEL_NAME, ML_TARGET_LOOKAHEAD_CANDLES, CHAT_ID, TELEGRAM_TOKEN
)

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…ÙƒØªØ¨Ø§Øª ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø©
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler
import requests # Ù„Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ø¦Ù„ ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…

# ---------------------- Ø«ÙˆØ§Ø¨Øª Ø®Ø§ØµØ© Ø¨Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ----------------------
TRAINING_LOOKBACK_DAYS: int = 60 # Ø²ÙŠØ§Ø¯Ø© Ø£ÙŠØ§Ù… Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨


# ---------------------- ML Model Training Functions ----------------------

def prepare_data_for_ml(symbol: str, interval: str, lookback_days: int) -> Optional[pd.DataFrame]:
    """
    Fetches historical data, calculates features (volume, RSI momentum),
    and defines the target variable for ML training.
    """
    logger.info(f"â„¹ï¸ [ML Data Prep] ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ ML Ù„Ù€ {symbol}...")
    df = fetch_historical_data(symbol, interval, lookback_days)

    if df is None or df.empty:
        logger.warning(f"âš ï¸ [ML Data Prep] Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù€ {symbol} Ù„ØªØ¬Ù‡ÙŠØ²Ù‡Ø§ Ù„Ù„ØªØ¯Ø±ÙŠØ¨.")
        return None

    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
    df = calculate_rsi_indicator(df, RSI_PERIOD)
    df['volume_15m_avg'] = df['volume'].rolling(window=VOLUME_LOOKBACK_CANDLES, min_periods=1).mean()

    df['rsi_momentum_bullish'] = 0
    if len(df) >= RSI_MOMENTUM_LOOKBACK_CANDLES + 1:
        for i in range(RSI_MOMENTUM_LOOKBACK_CANDLES, len(df)):
            rsi_slice = df['rsi'].iloc[i - RSI_MOMENTUM_LOOKBACK_CANDLES : i + 1]
            if not rsi_slice.isnull().any() and np.all(np.diff(rsi_slice) > 0) and rsi_slice.iloc[-1] > 50:
                df.loc[df.index[i], 'rsi_momentum_bullish'] = 1

    # Ø¥Ø¶Ø§ÙØ© Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¨ÙŠØªÙƒÙˆÙŠÙ† ÙƒÙ…ÙŠØ²Ø© (ØªØ±Ù…ÙŠØ² ÙŠØ¯ÙˆÙŠ)
    btc_trend = get_btc_trend_4h()
    df['btc_trend_encoded'] = 0 # Ù…Ø­Ø§ÙŠØ¯ Ø£Ùˆ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ
    if "ØµØ¹ÙˆØ¯" in btc_trend:
        df['btc_trend_encoded'] = 1
    elif "Ù‡Ø¨ÙˆØ·" in btc_trend:
        df['btc_trend_encoded'] = -1

    # ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù‡Ø¯Ù (target_movement): Ù‡Ù„ Ø³ÙŠØ±ØªÙØ¹ Ø§Ù„Ø³Ø¹Ø± Ø¨Ø¹Ø¯ N Ø´Ù…Ø¹Ø©ØŸ
    # Ø¥Ø°Ø§ Ø§Ø±ØªÙØ¹ Ø³Ø¹Ø± Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ Ø¨Ø¹Ø¯ ML_TARGET_LOOKAHEAD_CANDLES Ø´Ù…Ø¹Ø©ØŒ Ø§Ù„Ù‡Ø¯Ù Ù‡Ùˆ 1ØŒ ÙˆØ¥Ù„Ø§ ÙÙ‡Ùˆ 0.
    df['future_close'] = df['close'].shift(-ML_TARGET_LOOKAHEAD_CANDLES)
    df['target_movement'] = (df['future_close'] > df['close']).astype(int)

    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚ÙŠÙ… NaN Ø¨Ø¹Ø¯ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª ÙˆØ§Ù„Ù‡Ø¯Ù
    feature_cols = [
        'volume_15m_avg',
        'rsi_momentum_bullish',
        'btc_trend_encoded'
    ]
    df.dropna(subset=feature_cols + ['target_movement'], inplace=True)

    if df.empty:
        logger.warning(f"âš ï¸ [ML Data Prep] DataFrame ÙØ§Ø±Øº Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ù‚ÙŠÙ… NaN Ù„Ù€ {symbol}.")
        return None

    logger.info(f"âœ… [ML Data Prep] ØªÙ… ØªØ¬Ù‡ÙŠØ² {len(df)} ØµÙÙ‹Ø§ Ù„ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ ML Ù„Ù€ {symbol}.")
    return df

def train_ml_model(symbol: str, df: pd.DataFrame) -> Optional[Tuple[Any, Dict[str, Any]]]:
    """
    Trains an ML model (DecisionTreeClassifier) for a given symbol.
    Returns the trained model and its metrics.
    """
    logger.info(f"â„¹ï¸ [ML Training] Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ ML Ù„Ù€ {symbol}...")

    feature_cols = [
        'volume_15m_avg',
        'rsi_momentum_bullish',
        'btc_trend_encoded'
    ]
    target_col = 'target_movement'

    X = df[feature_cols]
    y = df[target_col]

    if len(X) < 20: # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨
        logger.warning(f"âš ï¸ [ML Training] Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ {symbol} ({len(X)} Ø¹ÙŠÙ†Ø©).")
        return None, None

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

    # Ù…Ù‚ÙŠØ§Ø³ Ø§Ù„Ù…ÙŠØ²Ø§Øª
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    model = DecisionTreeClassifier(random_state=42, max_depth=5) # ÙŠÙ…ÙƒÙ† ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª
    model.fit(X_train_scaled, y_train)

    y_pred = model.predict(X_test_scaled)
    accuracy = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred, output_dict=True)

    metrics = {
        'accuracy': accuracy,
        'classification_report': report,
        'train_samples': len(X_train),
        'test_samples': len(X_test),
        'feature_columns': feature_cols
    }

    logger.info(f"âœ… [ML Training] ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ {symbol}. Ø§Ù„Ø¯Ù‚Ø©: {accuracy:.4f}")
    logger.debug(f"ğŸ“Š [ML Training] ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ Ù„Ù€ {symbol}:\n{json.dumps(metrics['classification_report'], indent=2)}")

    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù€ scaler ÙƒØ®Ø§ØµÙŠØ© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„ÙŠØªÙ… Ø­ÙØ¸Ù‡ Ù…Ø¹Ù‡
    model.scaler = scaler
    return model, metrics

def send_telegram_message_from_training(target_chat_id: str, text: str, parse_mode: str = 'Markdown') -> None:
    """Sends a message via Telegram Bot API specifically for training script."""
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {
        'chat_id': str(target_chat_id),
        'text': text,
        'parse_mode': parse_mode
    }
    try:
        response = requests.post(url, json=payload, timeout=10)
        response.raise_for_status()
        logger.info(f"âœ… [Telegram] ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù„Ù‰ {target_chat_id}.")
    except requests.exceptions.RequestException as e:
        logger.error(f"âŒ [Telegram] ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¥Ù„Ù‰ {target_chat_id}: {e}")

def run_training_for_all_symbols(chat_id_to_notify: int) -> None:
    """
    Main function to run the ML model training process for all symbols.
    Designed to be called from another script (e.g., main_bot.py).
    """
    logger.info("ğŸš€ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© ØªØ¯Ø±ÙŠØ¨ Ù†Ù…Ø§Ø°Ø¬ ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø© Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬...")
    send_telegram_message_from_training(chat_id_to_notify, "â³ Ø¬Ø§Ø±ÙŠ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬. Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ù‡Ø°Ø§ Ø¨Ø¹Ø¶ Ø§Ù„ÙˆÙ‚Øª...")

    try:
        # ØªÙ‡ÙŠØ¦Ø© Ø¹Ù…ÙŠÙ„ Binance ÙˆÙ‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        # Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ© Ù‚Ø¯ Ù„Ø§ ØªÙƒÙˆÙ† Ø¶Ø±ÙˆØ±ÙŠØ© Ø¥Ø°Ø§ ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¹Ù…ÙŠÙ„ ÙˆØ§Ù„ DB Ø¨Ø§Ù„ÙØ¹Ù„ ÙÙŠ main_bot.py
        # ÙˆÙ„ÙƒÙ† Ù†ØªØ±ÙƒÙ‡Ø§ Ù‡Ù†Ø§ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø§Ø³ØªÙ‚Ù„Ø§Ù„ÙŠØ© Ø¥Ø°Ø§ ØªÙ… Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø¨Ø´ÙƒÙ„ Ù…Ù†ÙØµÙ„.
        # ÙŠØ¬Ø¨ Ø£Ù† ØªØªØ£ÙƒØ¯ Ø£Ù† initialize_binance_client Ùˆ init_db Ù„Ø§ ØªØ³Ø¨Ø¨ Ù…Ø´Ø§ÙƒÙ„ Ø¹Ù†Ø¯ Ø§Ø³ØªØ¯Ø¹Ø§Ø¦Ù‡Ø§ Ø¹Ø¯Ø© Ù…Ø±Ø§Øª.
        initialize_binance_client()
        init_db()

        symbols_to_train = get_crypto_symbols()
        if not symbols_to_train:
            logger.critical("âŒ [Training Process] Ù„Ø§ ØªÙˆØ¬Ø¯ Ø±Ù…ÙˆØ² ØµØ§Ù„Ø­Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨. Ø®Ø±ÙˆØ¬.")
            send_telegram_message_from_training(chat_id_to_notify, "âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø±Ù…ÙˆØ² ØµØ§Ù„Ø­Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨. ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©.")
            return

        total_trained_models = 0
        total_skipped_models = 0
        training_results = []

        for symbol in symbols_to_train:
            logger.info(f"âœ¨ [Training Process] Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ {symbol}...")
            try:
                df_ml = prepare_data_for_ml(symbol, '5m', TRAINING_LOOKBACK_DAYS) # Ø§Ø³ØªØ®Ø¯Ø§Ù… 5m ÙƒØ¥Ø·Ø§Ø± Ø²Ù…Ù†ÙŠ Ù„Ù„ØªØ¯Ø±ÙŠØ¨
                if df_ml is None:
                    logger.warning(f"âš ï¸ [Training Process] ØªØ®Ø·ÙŠ ØªØ¯Ø±ÙŠØ¨ {symbol}: Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ©.")
                    total_skipped_models += 1
                    training_results.append(f"âŒ `{symbol}`: ØªÙ… Ø§Ù„ØªØ®Ø·ÙŠ (Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ©)")
                    continue

                model, metrics = train_ml_model(symbol, df_ml)
                if model and metrics:
                    if save_ml_model_to_db(symbol, model, metrics):
                        total_trained_models += 1
                        training_results.append(f"âœ… `{symbol}`: ØªÙ… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ù†Ø¬Ø§Ø­ (Ø¯Ù‚Ø©: {metrics['accuracy']:.2f})")
                    else:
                        logger.error(f"âŒ [Training Process] ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ {symbol} ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")
                        total_skipped_models += 1
                        training_results.append(f"âŒ `{symbol}`: ÙØ´Ù„ Ø§Ù„Ø­ÙØ¸ ÙÙŠ DB")
                else:
                    logger.warning(f"âš ï¸ [Training Process] ØªØ®Ø·ÙŠ ØªØ¯Ø±ÙŠØ¨ {symbol}: ÙØ´Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø£Ùˆ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù‚Ø§ÙŠÙŠØ³.")
                    total_skipped_models += 1
                    training_results.append(f"âŒ `{symbol}`: ÙØ´Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨")

            except Exception as e:
                logger.error(f"âŒ [Training Process] Ø®Ø·Ø£ ÙØ§Ø¯Ø­ Ø£Ø«Ù†Ø§Ø¡ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ {symbol}: {e}", exc_info=True)
                total_skipped_models += 1
                training_results.append(f"âŒ `{symbol}`: Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹")
            time.sleep(0.5) # ØªØ£Ø®ÙŠØ± Ø¨Ø³ÙŠØ· Ø¨ÙŠÙ† ØªØ¯Ø±ÙŠØ¨ ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬

        final_message = (
            f"ğŸ“Š *ØªÙ‚Ø±ÙŠØ± ØªØ¯Ø±ÙŠØ¨ Ù†Ù…Ø§Ø°Ø¬ ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø©:*\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"âœ… ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: *{total_trained_models}*\n"
            f"âŒ ØªÙ… ØªØ®Ø·ÙŠ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: *{total_skipped_models}*\n"
            f"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"Ø§Ù„ØªÙØ§ØµÙŠÙ„:\n" + "\n".join(training_results) +
            f"\nâ€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
            f"ğŸ•°ï¸ _Ø§ÙƒØªÙ…Ù„ ÙÙŠ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}_"
        )
        send_telegram_message_from_training(chat_id_to_notify, final_message)
        logger.info("âœ… [Training Process] Ø§ÙƒØªÙ…Ù„Øª Ø¹Ù…Ù„ÙŠØ© ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬.")

    except Exception as process_err:
        logger.critical(f"âŒ [Training Process] Ø­Ø¯Ø« Ø®Ø·Ø£ ÙØ§Ø¯Ø­ ÙÙŠ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {process_err}", exc_info=True)
        send_telegram_message_from_training(chat_id_to_notify, f"âŒ *Ø®Ø·Ø£ ÙØ§Ø¯Ø­ Ø£Ø«Ù†Ø§Ø¡ Ø¹Ù…Ù„ÙŠØ© ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬:*\n`{str(process_err)}`")

# Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙƒØªÙ„Ø© __name__ == "__main__" Ù‡Ù†Ø§ØŒ Ù„Ø£Ù†Ù†Ø§ Ù†Ø±ÙŠØ¯ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ run_training_for_all_symbols ÙƒÙˆØ¸ÙŠÙØ©.
